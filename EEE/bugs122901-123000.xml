<?xml version="1.0" encoding="UTF-8"?>
<infozilla-output>
  <Bug>
    <BugId amount="122901" />
    <CreationDate amount="2006-01-06 07:23:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Report" />
    <Version amount="unspecified" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="major" />
    <Summery>Exported data source is invalid</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="3">
        <Lines>
          <Line>1.New a sampledb named "ds" in report</Line>
          <Line>2.New a library named "LibA"</Line>
          <Line>3.Switch to outline view of report, right click the datasource and choose "Export", choose "LibA" as the target library</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Description:
Exported data source is invalid

Steps to reproduce:
1.New a sampledb named "ds" in report
2.New a library named "LibA"
3.Switch to outline view of report, right click the datasource and choose "Export", choose "LibA" as the target library

Expected result:
The datasource is exported into library and invaild

Actual result:
The exported datasource is invalid
Oda elements have this problem since some property definitions are retrieved from OdaData Manifest. When duplicates element properties, for ODA and extended elements, extension names and ids must be set before duplicating property values.

Verified in build 20060111</WithStack>
    <WithOutStack>Description:
Exported data source is invalid

Steps to reproduce:
1.New a sampledb named "ds" in report
2.New a library named "LibA"
3.Switch to outline view of report, right click the datasource and choose "Export", choose "LibA" as the target library

Expected result:
The datasource is exported into library and invaild

Actual result:
The exported datasource is invalid
Oda elements have this problem since some property definitions are retrieved from OdaData Manifest. When duplicates element properties, for ODA and extended elements, extension names and ids must be set before duplicating property values.

Verified in build 20060111</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122902" />
    <CreationDate amount="2006-01-06 07:25:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Data" />
    <Version amount="2.0.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="major" />
    <Summery>Parameters are not prompted at Runtime</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="3">
      <Enumeration lines="7">
        <Lines>
          <Line>1) Since DataSet can't access ReportParameters in desing time, Report should be able to ask DataSet parameters at runtime (and thoose parameters marked as "for prompt").</Line>
          <Line />
          <Line>or</Line>
          <Line />
          <Line>2) There should be one way to refer Report Parameters in Property Bindings, since query rewrite with String concatenation isn't a real life option.</Line>
          <Line>I am not sure whether I understand you. Can you tell me what is your expectation?</Line>
          <Line>I expect a query with parameters which user could interact with.</Line>
        </Lines>
      </Enumeration>
      <Enumeration lines="2">
        <Lines>
          <Line>1) define a JDBC parameter with static value in parameter page</Line>
          <Line>2) define a parameter binding in table/list/data, which uses the report parameter</Line>
        </Lines>
      </Enumeration>
      <Enumeration lines="4">
        <Lines>
          <Line>1. click the 'parameters' tab in the window 'Edit data set', and set a default value on the parameter i,e P_A</Line>
          <Line>2. new a report parameter, P_B</Line>
          <Line>3. drag the data set to the layout. Switch to select the table, and click the binding change the P_A's value to the 'Params["P_B"]'</Line>
          <Line>4. save and preview.</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="RESOLVED" />
    <resolution amount="INVALID" />
    <WithStack>As stated on JDBC docs, you should use PreparedStatements as long as you can, because databases could optimize query plans and pre-fetch caches, and speed access to information.

Due to bug 93780, is not possible to make a query with parameters, because runtime information could not be accessed until report is in runtime (what makes complete sense!).
To solve this problem, is suggested to use Property Binding, which is not a complete solution for DataSets, because there is no way to link report parameters to query parameters.

AFAIK, to make a query like

select * from myTable where customerId = ? (a runtime parameter)

using report binding will be

select * from myTable where customerId = 100 (in query)

and

"select * from myTable where customerId = "+params["CustId"]

what is completelly no optimizable by database, and goes completelly out of best practices for JDBC parametrized execution.

In simple queries (like the one used as example), this is practical. But what about a query with dozens of lines?

So, I suggest one of the following:

1) Since DataSet can't access ReportParameters in desing time, Report should be able to ask DataSet parameters at runtime (and thoose parameters marked as "for prompt").

or

2) There should be one way to refer Report Parameters in Property Bindings, since query rewrite with String concatenation isn't a real life option.
I am not sure whether I understand you. Can you tell me what is your expectation?
I expect a query with parameters which user could interact with.

So, if I make a query like

select month, sum(totalSales)
  from sales
 where year = ?
 group by month

Where I define a parameter "Year for Report", with default value 2005, should be prompted to the user at runtime (since I can't bind dataset parameter to a report parameter, the report runtime should deal with dataset parameters maked for prompting).

The property binding doesn't offer this option too (paremters prompted to the user at runtime), and if dataset parameters could be marked for prompting, there is no need for property binding for data set at all (as far as I can see).
Here I just clarify two things. 

There is no relationship between the pop up dialog of report parameter and property binding. If the value of report parameter aleady exists, the dialog may not pop up. But you can click a button of tool bar to let you input another value. So there is no problem for property binding to work with report parameter.

There is another way to use report parameter, which does not need you use property binding, but you can still report parameter. The approach is
1) define a JDBC parameter with static value in parameter page
2) define a parameter binding in table/list/data, which uses the report parameter

I think you may not clearly know how it can be used. You can refer to my attached file which is a demo.
Created attachment 32583
demo file
It is not a bug.
If you want to make a query like

select month, sum(totalSales)
  from sales
 where year = ?
 group by month

1. click the 'parameters' tab in the window 'Edit data set', and set a default value on the parameter i,e P_A
2. new a report parameter, P_B
3. drag the data set to the layout. Switch to select the table, and click the binding change the P_A's value to the 'Params["P_B"]'
4. save and preview.

You can change the parameter value in running time. You do not need to use the property binding.Thanks</WithStack>
    <WithOutStack>As stated on JDBC docs, you should use PreparedStatements as long as you can, because databases could optimize query plans and pre-fetch caches, and speed access to information.

Due to bug 93780, is not possible to make a query with parameters, because runtime information could not be accessed until report is in runtime (what makes complete sense!).
To solve this problem, is suggested to use Property Binding, which is not a complete solution for DataSets, because there is no way to link report parameters to query parameters.

AFAIK, to make a query like

select * from myTable where customerId = ? (a runtime parameter)

using report binding will be

select * from myTable where customerId = 100 (in query)

and

"select * from myTable where customerId = "+params["CustId"]

what is completelly no optimizable by database, and goes completelly out of best practices for JDBC parametrized execution.

In simple queries (like the one used as example), this is practical. But what about a query with dozens of lines?

So, I suggest one of the following:

1) Since DataSet can't access ReportParameters in desing time, Report should be able to ask DataSet parameters at runtime (and thoose parameters marked as "for prompt").

or

2) There should be one way to refer Report Parameters in Property Bindings, since query rewrite with String concatenation isn't a real life option.
I am not sure whether I understand you. Can you tell me what is your expectation?
I expect a query with parameters which user could interact with.

So, if I make a query like

select month, sum(totalSales)
  from sales
 where year = ?
 group by month

Where I define a parameter "Year for Report", with default value 2005, should be prompted to the user at runtime (since I can't bind dataset parameter to a report parameter, the report runtime should deal with dataset parameters maked for prompting).

The property binding doesn't offer this option too (paremters prompted to the user at runtime), and if dataset parameters could be marked for prompting, there is no need for property binding for data set at all (as far as I can see).
Here I just clarify two things. 

There is no relationship between the pop up dialog of report parameter and property binding. If the value of report parameter aleady exists, the dialog may not pop up. But you can click a button of tool bar to let you input another value. So there is no problem for property binding to work with report parameter.

There is another way to use report parameter, which does not need you use property binding, but you can still report parameter. The approach is
1) define a JDBC parameter with static value in parameter page
2) define a parameter binding in table/list/data, which uses the report parameter

I think you may not clearly know how it can be used. You can refer to my attached file which is a demo.
Created attachment 32583
demo file
It is not a bug.
If you want to make a query like

select month, sum(totalSales)
  from sales
 where year = ?
 group by month

1. click the 'parameters' tab in the window 'Edit data set', and set a default value on the parameter i,e P_A
2. new a report parameter, P_B
3. drag the data set to the layout. Switch to select the table, and click the binding change the P_A's value to the 'Params["P_B"]'
4. save and preview.

You can change the parameter value in running time. You do not need to use the property binding.Thanks</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122903" />
    <CreationDate amount="2006-01-06 07:29:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Report" />
    <Version amount="unspecified" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="major" />
    <Summery>Chart can't be displayed when exported from the report to a library</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="4">
        <Lines>
          <Line>1.New a sampledb and a dataset with table "CUSTOMERS" in report</Line>
          <Line>2.New a library named "LibA"</Line>
          <Line>3.New a chart named "chart" binding with the dataset, set "CUSTOMERNUMBER" as X series, "SALESREPEMPLOYEENUMBER" as Y series</Line>
          <Line>4.Switch to outline view of report, right click the chart and choose "Export", choose "LibA" as the target library</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Description:
Chart can't be displayed when exported from the report to a library

Steps to reproduce:
1.New a sampledb and a dataset with table "CUSTOMERS" in report
2.New a library named "LibA"
3.New a chart named "chart" binding with the dataset, set "CUSTOMERNUMBER" as X series, "SALESREPEMPLOYEENUMBER" as Y series
4.Switch to outline view of report, right click the chart and choose "Export", choose "LibA" as the target library

Expected result:
The chart is exported into library

Actual result:
In the library, the chart is displayed as a blank square
That's a report designer bug, the extended properties of the extended item are 
not copied into the library when clicking on export, so there is a null chart 
model there. Reassigning to designer team.

extract from the lib xml after export:

    &lt;components&gt;
        &lt;extended-item extensionName="Chart" name="fff" id="6"&gt;
            &lt;property name="height"&gt;2.979in&lt;/property&gt;
            &lt;property name="width"&gt;7.135in&lt;/property&gt;
            &lt;property name="dataSet"&gt;ц?░ц?ощ??&lt;/property&gt;
        &lt;/extended-item&gt;
    &lt;/components&gt;
Model's bug.
This bug is same as 122901.
Extended elements like Chart have this problem since some property definitions are retrieved from Chart extension instead of ROM. When duplicates element properties, for ODA and extended elements, extension names and ids must be set before duplicating property values.
Verified in build 20060111</WithStack>
    <WithOutStack>Description:
Chart can't be displayed when exported from the report to a library

Steps to reproduce:
1.New a sampledb and a dataset with table "CUSTOMERS" in report
2.New a library named "LibA"
3.New a chart named "chart" binding with the dataset, set "CUSTOMERNUMBER" as X series, "SALESREPEMPLOYEENUMBER" as Y series
4.Switch to outline view of report, right click the chart and choose "Export", choose "LibA" as the target library

Expected result:
The chart is exported into library

Actual result:
In the library, the chart is displayed as a blank square
That's a report designer bug, the extended properties of the extended item are 
not copied into the library when clicking on export, so there is a null chart 
model there. Reassigning to designer team.

extract from the lib xml after export:

    &lt;components&gt;
        &lt;extended-item extensionName="Chart" name="fff" id="6"&gt;
            &lt;property name="height"&gt;2.979in&lt;/property&gt;
            &lt;property name="width"&gt;7.135in&lt;/property&gt;
            &lt;property name="dataSet"&gt;ц?░ц?ощ??&lt;/property&gt;
        &lt;/extended-item&gt;
    &lt;/components&gt;
Model's bug.
This bug is same as 122901.
Extended elements like Chart have this problem since some property definitions are retrieved from Chart extension instead of ROM. When duplicates element properties, for ODA and extended elements, extension names and ids must be set before duplicating property values.
Verified in build 20060111</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122904" />
    <CreationDate amount="2006-01-06 07:47:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Report Viewer" />
    <Version amount="2.0.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="critical" />
    <Summery>After installing all required libs, PDF isn't shown</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="WORKSFORME" />
    <WithStack>After install of BIRT 2.0 RC, and installed all required libraries (javascript.js, Axis and iText), is possible to preview report as HTML, but not as PDF.

There no error, but page appear empty, and Acrobat Reader is not even loaded.
Did you copy the itext into the "org.eclipse.birt.report.engine.emitter.pdf/lib"? 
please make sure the itext be in the right place. re-open this bug if issue still exists.
There is no org.eclipse.birt.report.engine.emitter.pdf/lib in RCP Report Designer 2.0 RC. Probably this is the bug!

Look directory structure:

C:\pgm\birt2\plugins&gt;dir org.eclipse.birt.report.engine.*
 O volume na unidade C é Disco local
 O número de série do volume é 58B1-EF11

 Pasta de C:\pgm\birt2\plugins

05/01/2006  09:19       &lt;DIR&gt;          org.eclipse.birt.report.engine.emitter.fo
_2.0.0
05/01/2006  09:19       &lt;DIR&gt;          org.eclipse.birt.report.engine.emitter.ht
ml_2.0.0
05/01/2006  09:19       &lt;DIR&gt;          org.eclipse.birt.report.engine.pdf_2.0.0
               0 arquivo(s)              0 bytes
               3 pasta(s) 11.724.533.760 bytes disponíveis

And in ...pdf_2.0.0:

C:\pgm\birt2\plugins&gt;dir org.eclipse.birt.report.engine.pdf_2.0.0
 O volume na unidade C é Disco local
 O número de série do volume é 58B1-EF11

 Pasta de C:\pgm\birt2\plugins\org.eclipse.birt.report.engine.pdf_2.0.0

05/01/2006  09:19       &lt;DIR&gt;          .
05/01/2006  09:19       &lt;DIR&gt;          ..
31/12/2005  07:46                   48 .options
31/12/2005  07:46                1.407 about.html
31/12/2005  07:46              115.323 enginePdf.jar
06/01/2006  09:26       &lt;DIR&gt;          lib
31/12/2005  07:46                1.021 plugin.xml
               4 arquivo(s)        117.799 bytes
               3 pasta(s) 11.724.533.760 bytes disponíveis

and in lib:

C:\pgm\birt2\plugins&gt;dir org.eclipse.birt.report.engine.pdf_2.0.0\lib
 O volume na unidade C é Disco local
 O número de série do volume é 58B1-EF11

 Pasta de C:\pgm\birt2\plugins\org.eclipse.birt.report.engine.pdf_2.0.0\lib

06/01/2006  09:26       &lt;DIR&gt;          .
06/01/2006  09:26       &lt;DIR&gt;          ..
06/01/2006  09:25               13.426 itext-1.3.jar
               1 arquivo(s)         13.426 bytes
               2 pasta(s) 11.724.533.760 bytes disponíveis
Sorry, should be "org.eclipse.birt.report.engine.pdf/lib". Pleae try it again.
ignore my previous comment.
yes. It is caused by missing that plugin. In source code, this has been updated.

Wei,

Sounds like old plugin folder still there.
I discovered. I had a corrupt itext-1.3.jar. I downloaded itext-1.3.1.jar and doesn't work too. Then I renamed itext-1.3.1.jar to itext-1.3.jar, and know everything works fine.

Thanks.
Verified in build 20060109.</WithStack>
    <WithOutStack>After install of BIRT 2.0 RC, and installed all required libraries (javascript.js, Axis and iText), is possible to preview report as HTML, but not as PDF.

There no error, but page appear empty, and Acrobat Reader is not even loaded.
Did you copy the itext into the "org.eclipse.birt.report.engine.emitter.pdf/lib"? 
please make sure the itext be in the right place. re-open this bug if issue still exists.
There is no org.eclipse.birt.report.engine.emitter.pdf/lib in RCP Report Designer 2.0 RC. Probably this is the bug!

Look directory structure:

C:\pgm\birt2\plugins&gt;dir org.eclipse.birt.report.engine.*
 O volume na unidade C é Disco local
 O número de série do volume é 58B1-EF11

 Pasta de C:\pgm\birt2\plugins

05/01/2006  09:19       &lt;DIR&gt;          org.eclipse.birt.report.engine.emitter.fo
_2.0.0
05/01/2006  09:19       &lt;DIR&gt;          org.eclipse.birt.report.engine.emitter.ht
ml_2.0.0
05/01/2006  09:19       &lt;DIR&gt;          org.eclipse.birt.report.engine.pdf_2.0.0
               0 arquivo(s)              0 bytes
               3 pasta(s) 11.724.533.760 bytes disponíveis

And in ...pdf_2.0.0:

C:\pgm\birt2\plugins&gt;dir org.eclipse.birt.report.engine.pdf_2.0.0
 O volume na unidade C é Disco local
 O número de série do volume é 58B1-EF11

 Pasta de C:\pgm\birt2\plugins\org.eclipse.birt.report.engine.pdf_2.0.0

05/01/2006  09:19       &lt;DIR&gt;          .
05/01/2006  09:19       &lt;DIR&gt;          ..
31/12/2005  07:46                   48 .options
31/12/2005  07:46                1.407 about.html
31/12/2005  07:46              115.323 enginePdf.jar
06/01/2006  09:26       &lt;DIR&gt;          lib
31/12/2005  07:46                1.021 plugin.xml
               4 arquivo(s)        117.799 bytes
               3 pasta(s) 11.724.533.760 bytes disponíveis

and in lib:

C:\pgm\birt2\plugins&gt;dir org.eclipse.birt.report.engine.pdf_2.0.0\lib
 O volume na unidade C é Disco local
 O número de série do volume é 58B1-EF11

 Pasta de C:\pgm\birt2\plugins\org.eclipse.birt.report.engine.pdf_2.0.0\lib

06/01/2006  09:26       &lt;DIR&gt;          .
06/01/2006  09:26       &lt;DIR&gt;          ..
06/01/2006  09:25               13.426 itext-1.3.jar
               1 arquivo(s)         13.426 bytes
               2 pasta(s) 11.724.533.760 bytes disponíveis
Sorry, should be "org.eclipse.birt.report.engine.pdf/lib". Pleae try it again.
ignore my previous comment.
yes. It is caused by missing that plugin. In source code, this has been updated.

Wei,

Sounds like old plugin folder still there.
I discovered. I had a corrupt itext-1.3.jar. I downloaded itext-1.3.1.jar and doesn't work too. Then I renamed itext-1.3.1.jar to itext-1.3.jar, and know everything works fine.

Thanks.
Verified in build 20060109.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122905" />
    <CreationDate amount="2006-01-06 08:51:00 -0500" />
    <DupId amount="" />
    <classification amount="DataTools" />
    <Product amount="Data Tools" />
    <component amount="Connectivity" />
    <Version amount="unspecified" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="blocker" />
    <Summery>Get SQL model objects from connectivity layer for SQL Dev Tools</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>In SQL Dev Tools, we need to use the SQL model objects to provide content assist, load a Routine object into routine editor, and save it back to databse. These features are scheduled for M3.
I believe this functionality is now available by using the ConnectionInfo connection factory.  Please verify and close out.
Verified. Thanks Rob!
Closing bugs</WithStack>
    <WithOutStack>In SQL Dev Tools, we need to use the SQL model objects to provide content assist, load a Routine object into routine editor, and save it back to databse. These features are scheduled for M3.
I believe this functionality is now available by using the ConnectionInfo connection factory.  Please verify and close out.
Verified. Thanks Rob!
Closing bugs</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122906" />
    <CreationDate amount="2006-01-06 08:57:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="UI" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>[quick fix] add unimplemented method does not consider  name conflicts</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="17">
      <source_code type="package">
        <location start="49" end="66" />
        <code>package ibm.util;</code>
      </source_code>
      <source_code type="class">
        <location start="67" end="93" />
        <code>public class Properties {}</code>
      </source_code>
      <source_code type="package">
        <location start="95" end="112" />
        <code>package ibm.util;</code>
      </source_code>
      <source_code type="import">
        <location start="113" end="141" />
        <code>import java.util.Properties;</code>
      </source_code>
      <source_code type="functioncall">
        <location start="163" end="199" />
        <code>public void b(Properties p);</code>
      </source_code>
      <source_code type="functioncall">
        <location start="200" end="245" />
        <code>public void g(ibm.util.Properties p);</code>
      </source_code>
      <source_code type="package">
        <location start="249" end="266" />
        <code>package ibm.util;</code>
      </source_code>
      <source_code type="class">
        <location start="267" end="301" />
        <code>public class Test implements F {
}</code>
      </source_code>
      <source_code type="package">
        <location start="368" end="385" />
        <code>package ibm.util;</code>
      </source_code>
      <source_code type="import">
        <location start="386" end="414" />
        <code>import java.util.Properties;</code>
      </source_code>
      <source_code type="class">
        <location start="415" end="513" />
        <code>public class Test implements F {
	public void b(Properties p) {}
	public void g(Properties p) {}
}</code>
      </source_code>
      <source_code type="package">
        <location start="531" end="548" />
        <code>package ibm.util;</code>
      </source_code>
      <source_code type="import">
        <location start="549" end="577" />
        <code>import java.util.Properties;</code>
      </source_code>
      <source_code type="class">
        <location start="578" end="699" />
        <code>public class Test implements F {
        public void b(Properties p) {}
        public void g(ibm.util.Properties p) {}
}</code>
      </source_code>
      <source_code type="package">
        <location start="706" end="723" />
        <code>package ibm.util;</code>
      </source_code>
      <source_code type="import">
        <location start="724" end="751" />
        <code>import ibm.util.Properties;</code>
      </source_code>
      <source_code type="class">
        <location start="752" end="874" />
        <code>public class Test implements F {
        public void b(java.util.Properties p) {}
        public void g(Properties p) {}
}</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>Version: 3.2.0
Build id: I20060105-0800

Having:
package ibm.util;
public class Properties {}

package ibm.util;
import java.util.Properties;
public interface F {
        public void b(Properties p);
        public void g(ibm.util.Properties p);
}

package ibm.util;
public class Test implements F {
}

Then applying quick fix 'add unimplemented methods' results in:

package ibm.util;
import java.util.Properties;
public class Test implements F {
	public void b(Properties p) {}
	public void g(Properties p) {}
}

But should be:

package ibm.util;
import java.util.Properties;
public class Test implements F {
        public void b(Properties p) {}
        public void g(ibm.util.Properties p) {}
}

or:

package ibm.util;
import ibm.util.Properties;
public class Test implements F {
        public void b(java.util.Properties p) {}
        public void g(Properties p) {}
}
*** Bug 120357 has been marked as a duplicate of this bug. ***
fixed &gt; 20060105</WithStack>
    <WithOutStack>Version: 3.2.0
Build id: I20060105-0800

Having:
package ibm.util;
public class Properties {}

package ibm.util;
import java.util.Properties;
public interface F {
        public void b(Properties p);
        public void g(ibm.util.Properties p);
}

package ibm.util;
public class Test implements F {
}

Then applying quick fix 'add unimplemented methods' results in:

package ibm.util;
import java.util.Properties;
public class Test implements F {
	public void b(Properties p) {}
	public void g(Properties p) {}
}

But should be:

package ibm.util;
import java.util.Properties;
public class Test implements F {
        public void b(Properties p) {}
        public void g(ibm.util.Properties p) {}
}

or:

package ibm.util;
import ibm.util.Properties;
public class Test implements F {
        public void b(java.util.Properties p) {}
        public void g(Properties p) {}
}
*** Bug 120357 has been marked as a duplicate of this bug. ***
fixed &gt; 20060105</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122907" />
    <CreationDate amount="2006-01-06 09:27:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Report Viewer" />
    <Version amount="2.0.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="critical" />
    <Summery>Error "Some required parameter values are not set or set to incompatible data type"</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>Created a report with some Report Parameters.
The parameters are not filled with a default value, but they are marked as required.

Behaviour:

Fail to preview or print report with error "Some required parameter values are not set or set to incompatible data type".

Expected behaviour:

Engine ask for parameters before trying to process the report.
Created attachment 32584
Report where parameters, even required, are not asked if no default value is filled.
As far as I can see, Birt is assuming default values defined for data set. It's not the expected behaviour, from user point of view.

Parameters defined for the report should have precedence over parameters defined for dataset at runtime, and the fact that there is no default value defined for report parameters should override defaults defined for dataset.
Still not work with RC1.
Required parameters are not asked in first execution. Defaults defined for design-time in parameters for data-set are being assumed (and should not).

User is obligated to execute report twice to get desired results.
Seems to be a viewer problem. 
118790
This is almost same, but the problem here is the main report not asking parameters at first execution, and default from data-set being taken, leading to 2 executions to get result.

If this is a large report, could lead into two penalties over database, one completely useless.
issue related to 118790 has been resolved.

The major complain is the rule to determine the parameter's default value.

"As far as I can see, Birt is assuming default values defined for data set. It's
not the expected behaviour, from user point of view.

Parameters defined for the report should have precedence over parameters
defined for dataset at runtime, and the fact that there is no default value
defined for report parameters should override defaults defined for dataset."

Engine needs to take care of it.
Viewer asks the user for the paramters in the first exection and saves the paramter values in the ConfigVars. In the following execution, VIEWER uses the saved paramter to run the report. 

That causes the VIEWER never ask the user for paramters even the paramter has no default value.

In deployed enviorment, the VIEWER should never get the paramter values from ConfigVars.
There is a url parameter called "__designer=XXX" specify whether the web viewer is launched from designer or not. If from desginer, value in the test config will be loaded. If running viewer from standalone deployment, test config will be ignored.

In the test case, when viewing the 1st report in the 1st time, did you specify any thing? If so, that value will be used afterward. Parameter won't be asked in subsequent requests.
If my last comment is right, this bug consider fixed. Re-open it if there are still issues.
No, I didn't specified anything. But I'll make a try, and if necessary I'll reopen.

Tkx.
Verified in build 20060112.</WithStack>
    <WithOutStack>Created a report with some Report Parameters.
The parameters are not filled with a default value, but they are marked as required.

Behaviour:

Fail to preview or print report with error "Some required parameter values are not set or set to incompatible data type".

Expected behaviour:

Engine ask for parameters before trying to process the report.
Created attachment 32584
Report where parameters, even required, are not asked if no default value is filled.
As far as I can see, Birt is assuming default values defined for data set. It's not the expected behaviour, from user point of view.

Parameters defined for the report should have precedence over parameters defined for dataset at runtime, and the fact that there is no default value defined for report parameters should override defaults defined for dataset.
Still not work with RC1.
Required parameters are not asked in first execution. Defaults defined for design-time in parameters for data-set are being assumed (and should not).

User is obligated to execute report twice to get desired results.
Seems to be a viewer problem. 
118790
This is almost same, but the problem here is the main report not asking parameters at first execution, and default from data-set being taken, leading to 2 executions to get result.

If this is a large report, could lead into two penalties over database, one completely useless.
issue related to 118790 has been resolved.

The major complain is the rule to determine the parameter's default value.

"As far as I can see, Birt is assuming default values defined for data set. It's
not the expected behaviour, from user point of view.

Parameters defined for the report should have precedence over parameters
defined for dataset at runtime, and the fact that there is no default value
defined for report parameters should override defaults defined for dataset."

Engine needs to take care of it.
Viewer asks the user for the paramters in the first exection and saves the paramter values in the ConfigVars. In the following execution, VIEWER uses the saved paramter to run the report. 

That causes the VIEWER never ask the user for paramters even the paramter has no default value.

In deployed enviorment, the VIEWER should never get the paramter values from ConfigVars.
There is a url parameter called "__designer=XXX" specify whether the web viewer is launched from designer or not. If from desginer, value in the test config will be loaded. If running viewer from standalone deployment, test config will be ignored.

In the test case, when viewing the 1st report in the 1st time, did you specify any thing? If so, that value will be used afterward. Parameter won't be asked in subsequent requests.
If my last comment is right, this bug consider fixed. Re-open it if there are still issues.
No, I didn't specified anything. But I'll make a try, and if necessary I'll reopen.

Tkx.
Verified in build 20060112.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122908" />
    <CreationDate amount="2006-01-06 09:30:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="Debug" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>pref pages missing context help</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="VERIFIED" />
    <resolution amount="FIXED" />
    <WithStack>These pref pages needs help added:

* Launching
* Perspectives
* View Management
Created attachment 32606
patch for docs xml plugin

this patch adds the context ids to the doc mapping in contexts_Debugger.xml
this fix only provides the context help for Perspectives and View Management due to ongoing work to the Launching page. Help will be provided for the Launching page when it is done.

please verify Darin.
reopen to re-assign
ping
Applied (with some wording changes)
Verified.</WithStack>
    <WithOutStack>These pref pages needs help added:

* Launching
* Perspectives
* View Management
Created attachment 32606
patch for docs xml plugin

this patch adds the context ids to the doc mapping in contexts_Debugger.xml
this fix only provides the context help for Perspectives and View Management due to ongoing work to the Launching page. Help will be provided for the Launching page when it is done.

please verify Darin.
reopen to re-assign
ping
Applied (with some wording changes)
Verified.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122909" />
    <CreationDate amount="2006-01-06 09:33:00 -0500" />
    <DupId amount="" />
    <classification amount="WebTools" />
    <Product amount="WTP Source Editing" />
    <component amount="wst.sse" />
    <Version amount="unspecified" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>[api][ui] Need to provide extension point to associate new (hover) info for DTDs, Schemas, and TLDs</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="WONTFIX" />
    <WithStack>I believe we have basics in place, but not sure how close it is to platform 
quality API (and suspect can not fit into WTP 1.5 schedule), but wanted to open this bug so we would not lose track of it. 

Besides "new" information associated with Nodes, Attributes, etc., we need to 
be sure to remember to include machanism to "retrieve" NL versions.
Amy, no huge rush, but can you assess the steps and efforts to acheive this?

CC-ing Craig since he may have more insight (and was the initial contributor).

Clients can currently contribute their own hover info DTDs/schemas via the org.eclipse.wst.xml.core.annotationFiles extension point.  How the extension point currently works is, clients specify definition file that contains the hover info and the public id/system id to associated with it.  The NL version info is specified in the definition file.
So what needs to be done is:
-evaluate the current extension point (should we keep it so that clients specify definition file + public/system id?  can clients specify anything other than public/system id?)
-evaulate the structure of the definition file (should nl location be specified in definition file or extension point?  it would be nice if we had a dtd/schema for clients to validate their definition file against)
-make sure nl versions are picked up (there are currently issues with nl fragments)

Also, Craig/David, I believe the original intent of the definition file was that clients could specify more info than just hover info (like icons to use when representing elements) Does that still sound like something we want to include in the definition file?  Or will that be a separate item?
I think other things, like icons, should be seperate, but, fine if part of a "family" of extension points, that could be seperate file or not [but not manditory]. 

I think Craig and Kihup have also mentioned need to add "extra" content assist and validation info to content model ... well, that was actually my suggested implementation ... but, I'm adding Kihup in case he can add those requirements, and we'll (re) assess if (eventually) fits in with this effort. 

Amy, you did not mention TLD's ... I think that's our current biggest "unknown"? 


I'll have to investigate TLDs, but I was thinking it would use a similar if not same extension point.  Actually, I thought Nitin already implemented or at least already thought about how extra TLD info was going to be handled.  But maybe that didn't include hover info.

cc-ing Nitin for input.
We don't support using annotationFiles for TLDs.  TLDs have a predefined "description" tag meant to be used by tooling for exactly this purpose.  Oh, and we already display any icons declared in the TLD within the content model.

As Craig/Kihup have been rumored to say, what's missing are enhancements to the content model itself so that a content model drawn from one file can be supplemented with more specific definitions and descriptions, but without modifying that file.  The Struts tag library is an ideal example TLD case for this as it almost completely duplicates the HTML content model.  Unfortunately the required content model information is not part of any TLD, and tools would be working with a .tld that's best shipped without modification.  I'd thought that providing a way to connect a DTD or schema file for a specific TLD (perhaps using its internally declared URI [which amounts to a web-app-scoped "public" ID] or just including the entire schema in a custom processing instruction) would be a straightforward solution, but that really only addresses supplementing the content model...and there's talk of doing more?  Do Schemas and DTDs need such supplemental information?

I think it very important that a user developing a Schema/TLD/DTD would be able to supply this information without writing plugins and still do it in a portable/shareable way (BeanInfo classes would be an example here).  After all, we do allow users to create those file types and being able to supply this kind of information to *their* users could be handy.
Okay, I think we're all agreeing on the same thing but using different words.

So basically, just focusing on hover info, we need a public way for clients to provide hover info/documentation in addition to any that may already be in the dtd, schema, tld.  And this hover info/documentation is to be displayed in our editors (and any clients of ours)

I think public/system id/uri is good enough to use to associate the extra info with the dtd/schema/tld. As for the definition file.  Clients associate the XPath of the element or attribute to the documention.  That sounds good enough for DTD/Schema/TLD too, unless I'm missing something.
reassigning to inbox
Nitin, is this something that is still needed, is it something that may have already gotten in and this bug was just never updated?  I leave the fate of this bug in your capable hands :)
Still handy, given how little parent-child element information is available in TLDs, but no plans to work it.  I'm open to high-quality contributions, but I'm going to resolve this unless/until some appears wanting to work on this.</WithStack>
    <WithOutStack>I believe we have basics in place, but not sure how close it is to platform 
quality API (and suspect can not fit into WTP 1.5 schedule), but wanted to open this bug so we would not lose track of it. 

Besides "new" information associated with Nodes, Attributes, etc., we need to 
be sure to remember to include machanism to "retrieve" NL versions.
Amy, no huge rush, but can you assess the steps and efforts to acheive this?

CC-ing Craig since he may have more insight (and was the initial contributor).

Clients can currently contribute their own hover info DTDs/schemas via the org.eclipse.wst.xml.core.annotationFiles extension point.  How the extension point currently works is, clients specify definition file that contains the hover info and the public id/system id to associated with it.  The NL version info is specified in the definition file.
So what needs to be done is:
-evaluate the current extension point (should we keep it so that clients specify definition file + public/system id?  can clients specify anything other than public/system id?)
-evaulate the structure of the definition file (should nl location be specified in definition file or extension point?  it would be nice if we had a dtd/schema for clients to validate their definition file against)
-make sure nl versions are picked up (there are currently issues with nl fragments)

Also, Craig/David, I believe the original intent of the definition file was that clients could specify more info than just hover info (like icons to use when representing elements) Does that still sound like something we want to include in the definition file?  Or will that be a separate item?
I think other things, like icons, should be seperate, but, fine if part of a "family" of extension points, that could be seperate file or not [but not manditory]. 

I think Craig and Kihup have also mentioned need to add "extra" content assist and validation info to content model ... well, that was actually my suggested implementation ... but, I'm adding Kihup in case he can add those requirements, and we'll (re) assess if (eventually) fits in with this effort. 

Amy, you did not mention TLD's ... I think that's our current biggest "unknown"? 


I'll have to investigate TLDs, but I was thinking it would use a similar if not same extension point.  Actually, I thought Nitin already implemented or at least already thought about how extra TLD info was going to be handled.  But maybe that didn't include hover info.

cc-ing Nitin for input.
We don't support using annotationFiles for TLDs.  TLDs have a predefined "description" tag meant to be used by tooling for exactly this purpose.  Oh, and we already display any icons declared in the TLD within the content model.

As Craig/Kihup have been rumored to say, what's missing are enhancements to the content model itself so that a content model drawn from one file can be supplemented with more specific definitions and descriptions, but without modifying that file.  The Struts tag library is an ideal example TLD case for this as it almost completely duplicates the HTML content model.  Unfortunately the required content model information is not part of any TLD, and tools would be working with a .tld that's best shipped without modification.  I'd thought that providing a way to connect a DTD or schema file for a specific TLD (perhaps using its internally declared URI [which amounts to a web-app-scoped "public" ID] or just including the entire schema in a custom processing instruction) would be a straightforward solution, but that really only addresses supplementing the content model...and there's talk of doing more?  Do Schemas and DTDs need such supplemental information?

I think it very important that a user developing a Schema/TLD/DTD would be able to supply this information without writing plugins and still do it in a portable/shareable way (BeanInfo classes would be an example here).  After all, we do allow users to create those file types and being able to supply this kind of information to *their* users could be handy.
Okay, I think we're all agreeing on the same thing but using different words.

So basically, just focusing on hover info, we need a public way for clients to provide hover info/documentation in addition to any that may already be in the dtd, schema, tld.  And this hover info/documentation is to be displayed in our editors (and any clients of ours)

I think public/system id/uri is good enough to use to associate the extra info with the dtd/schema/tld. As for the definition file.  Clients associate the XPath of the element or attribute to the documention.  That sounds good enough for DTD/Schema/TLD too, unless I'm missing something.
reassigning to inbox
Nitin, is this something that is still needed, is it something that may have already gotten in and this bug was just never updated?  I leave the fate of this bug in your capable hands :)
Still handy, given how little parent-child element information is available in TLDs, but no plans to work it.  I'm open to high-quality contributions, but I'm going to resolve this unless/until some appears wanting to work on this.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122910" />
    <CreationDate amount="2006-01-06 09:38:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="UI" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>[CommonNavigator] API types should specify subclassing / implementation contract</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>build I20060105

Many/most of the common navigator API classes do not specify whether they can be subclassed.  Likewise for whether interfaces can be implemented by clients.  We generally try to state this explicitly.  Otherwise the assumption is that the client can do anything, which constrains the kind of API changes we can make in the future (i.e. we need to be more conservative about maintaining compatibility).

It's also helpful to indicate methods that must (re)implemented by subclasses, or are likely to be overridden.

For some examples, see WorkbenchPart, IViewSite, LabelProvider, etc.

The majority of the warnings from the core plugin (org.eclipse.ui.navigator) have been fixed. The remaining warnings are in the DND and Link with Editor support which will be fixed shortly. 

I think that all of the API types have their contract explicitly specified. I am leaving this defect open and will do a complete review on Friday to ensure this is the case. 
Fixed and released to HEAD.</WithStack>
    <WithOutStack>build I20060105

Many/most of the common navigator API classes do not specify whether they can be subclassed.  Likewise for whether interfaces can be implemented by clients.  We generally try to state this explicitly.  Otherwise the assumption is that the client can do anything, which constrains the kind of API changes we can make in the future (i.e. we need to be more conservative about maintaining compatibility).

It's also helpful to indicate methods that must (re)implemented by subclasses, or are likely to be overridden.

For some examples, see WorkbenchPart, IViewSite, LabelProvider, etc.

The majority of the warnings from the core plugin (org.eclipse.ui.navigator) have been fixed. The remaining warnings are in the DND and Link with Editor support which will be fixed shortly. 

I think that all of the API types have their contract explicitly specified. I am leaving this defect open and will do a complete review on Friday to ensure this is the case. 
Fixed and released to HEAD.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122911" />
    <CreationDate amount="2006-01-06 09:51:00 -0500" />
    <DupId amount="" />
    <classification amount="RT" />
    <Product amount="Equinox" />
    <component amount="Framework" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Linux" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Equinox OSGi on a servlet. Console does not shutdown.</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>I'm activating the Equinox anvironment in a servlet context.
When the servlet context is destroyed the framework is shutdown BUT the console remains active (there is nothing in the EclipseStarter shutdown sequence that tells the console to disconnect).

Regards,
Sandro
The console is currently enabled primarily for experimentation
A better means of managing the framework when runnning in the servlet environment is needed.

In an environment where you need things to cleanup properly you'll need an alternate means of managing the framework and then you should remove (or set false) the "enableConsole" init-param.

That being said it would definitely be nice to have someway to shutdown the console manually.

This is true.  I have never been too happy that the console is included in the base framework (but it does make it easy to use).  It could easily be implemented as a separate bundle.  If we did this then the console would not be active until the "console" bundle was installed and started.  The console would then be shutdown when the "console" bundle is stopped.

Perhaps in a server env you would want to use such a "console" bundle instead of the built-in console supplied by the framework.  As Simon points out there should be a better way to manage the OSGi environment besides the console for the server env.
Created attachment 32698
Patched Knopflerfish http-console

As an alternative to using the raw OSGi console...
Knopflerfish has an HttpConsole that might be more appropriate for servlet oriented management (or at least provide some inspiration for building one).
(see https://www.knopflerfish.org/svn/knopflerfish.org/trunk/osgi/bundles/http/httpconsole/readme.html for some docs).

The attachment is my packaging that I can confirm works. I had to make a slight alteration so that it uses relative URLs. If you're interested see patched-src/Activator.java (included in the bundle)

Let me know what you think.
I think it's a good idea. I played around with it and now try to update eclipse features. Maybe this kind of management interface could be extended to support eclipse updating. But I can hardly believe there is another pros against a pure osgi console.

But one thing raises up again: how to control a bundle`s properties? Maybe each bundle must have a single bundle-specific config.ini to configure.

martin


The idea of separating out the console is nice.  We should see if it can be done somehow more easily when we have the new simple configurator. 
I really like of separating out the console -- definitely willing to help. That said, I wonder if that should be handled separately.

The immediate problem here is that the console thread lives on after EclipseStarter.shutdown has been called.

EclipseStarter has a "startConsole" method, would it be reasonable to have an analagous "stopConsole" method called (as Sandro's suggested) during "shutdown"?

Seems reasonable to me.  This would be a private method called by shutdown, right Simon?

We would have to add a method on FrameworkConsole to shutdown the console thread that can be called by EclipseStarter.shutdown.
Yep. A little re-working of the FrameworkConsole would have to happen, but nothing terribly tricky.

If I was to do a patch how careful do I have to be about the FrameworkConsole contract. (e.g. I can see an unwritten assumption that the console class has particular constructors and is Runnable -- to this I'd be adding calling shutdown if the method is present.)

In practice has anyone ever written an alternate console or is the reflection just there to allow us to do the Frameworkonsole in an extension bundle? 
reflection is used to allow for an extesion bundle to contain the console.  Adding a new method should be fine.  We simple will not do anything if the shudown method cannot be found.
Created attachment 46403
Adds shutdown support for the console

This patch adds shutdown support for the console.
The shutdown support can stop the thread if the console uses a non-blocking read for I/O (e.g. osgi.console.blockOnReady). For regular blocking usage the shutdown() call will allow the thread to be cleaned up without emitting errors after the user provides input to unblock the read() call.

One thing to note is that if "osgi.console.blockOnReady" is used input is not echoed back to the console until &lt;enter&gt; is pressed. It seems that the "echo" occurs only if the thread is blocking on read() even though the input is not available until &lt;enter&gt; is pressed.
*** Bug 179047 has been marked as a duplicate of this bug. ***
Investigate Simon's patch for M7.
Created attachment 63806
patch

Here is an updated patch against HEAD.

I had to modify the patch a bit because there was deadlock in getSocketStream and disconnect.  I also had to add code to ensure the ConsoleSocketGetter thread was shutdown.

Simon, please review.
+1 - Looks good and works for my tests.
Created attachment 64126
patch

update patch against head since bug 182569 was release.
Patch released to HEAD.</WithStack>
    <WithOutStack>I'm activating the Equinox anvironment in a servlet context.
When the servlet context is destroyed the framework is shutdown BUT the console remains active (there is nothing in the EclipseStarter shutdown sequence that tells the console to disconnect).

Regards,
Sandro
The console is currently enabled primarily for experimentation
A better means of managing the framework when runnning in the servlet environment is needed.

In an environment where you need things to cleanup properly you'll need an alternate means of managing the framework and then you should remove (or set false) the "enableConsole" init-param.

That being said it would definitely be nice to have someway to shutdown the console manually.

This is true.  I have never been too happy that the console is included in the base framework (but it does make it easy to use).  It could easily be implemented as a separate bundle.  If we did this then the console would not be active until the "console" bundle was installed and started.  The console would then be shutdown when the "console" bundle is stopped.

Perhaps in a server env you would want to use such a "console" bundle instead of the built-in console supplied by the framework.  As Simon points out there should be a better way to manage the OSGi environment besides the console for the server env.
Created attachment 32698
Patched Knopflerfish http-console

As an alternative to using the raw OSGi console...
Knopflerfish has an HttpConsole that might be more appropriate for servlet oriented management (or at least provide some inspiration for building one).
(see https://www.knopflerfish.org/svn/knopflerfish.org/trunk/osgi/bundles/http/httpconsole/readme.html for some docs).

The attachment is my packaging that I can confirm works. I had to make a slight alteration so that it uses relative URLs. If you're interested see patched-src/Activator.java (included in the bundle)

Let me know what you think.
I think it's a good idea. I played around with it and now try to update eclipse features. Maybe this kind of management interface could be extended to support eclipse updating. But I can hardly believe there is another pros against a pure osgi console.

But one thing raises up again: how to control a bundle`s properties? Maybe each bundle must have a single bundle-specific config.ini to configure.

martin


The idea of separating out the console is nice.  We should see if it can be done somehow more easily when we have the new simple configurator. 
I really like of separating out the console -- definitely willing to help. That said, I wonder if that should be handled separately.

The immediate problem here is that the console thread lives on after EclipseStarter.shutdown has been called.

EclipseStarter has a "startConsole" method, would it be reasonable to have an analagous "stopConsole" method called (as Sandro's suggested) during "shutdown"?

Seems reasonable to me.  This would be a private method called by shutdown, right Simon?

We would have to add a method on FrameworkConsole to shutdown the console thread that can be called by EclipseStarter.shutdown.
Yep. A little re-working of the FrameworkConsole would have to happen, but nothing terribly tricky.

If I was to do a patch how careful do I have to be about the FrameworkConsole contract. (e.g. I can see an unwritten assumption that the console class has particular constructors and is Runnable -- to this I'd be adding calling shutdown if the method is present.)

In practice has anyone ever written an alternate console or is the reflection just there to allow us to do the Frameworkonsole in an extension bundle? 
reflection is used to allow for an extesion bundle to contain the console.  Adding a new method should be fine.  We simple will not do anything if the shudown method cannot be found.
Created attachment 46403
Adds shutdown support for the console

This patch adds shutdown support for the console.
The shutdown support can stop the thread if the console uses a non-blocking read for I/O (e.g. osgi.console.blockOnReady). For regular blocking usage the shutdown() call will allow the thread to be cleaned up without emitting errors after the user provides input to unblock the read() call.

One thing to note is that if "osgi.console.blockOnReady" is used input is not echoed back to the console until &lt;enter&gt; is pressed. It seems that the "echo" occurs only if the thread is blocking on read() even though the input is not available until &lt;enter&gt; is pressed.
*** Bug 179047 has been marked as a duplicate of this bug. ***
Investigate Simon's patch for M7.
Created attachment 63806
patch

Here is an updated patch against HEAD.

I had to modify the patch a bit because there was deadlock in getSocketStream and disconnect.  I also had to add code to ensure the ConsoleSocketGetter thread was shutdown.

Simon, please review.
+1 - Looks good and works for my tests.
Created attachment 64126
patch

update patch against head since bug 182569 was release.
Patch released to HEAD.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122912" />
    <CreationDate amount="2006-01-06 09:59:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="Text" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="major" />
    <Summery>NPE in classfile editor</Summery>
    <Patches amount="0" />
    <Stacktraces amount="1">
      <Stacktrace timestamp="1437330631507">
        <Exception>java.lang.NullPointerException</Exception>
        <Reason />
        <Frames>
          <Frame depth="0">org.eclipse.core.filebuffers.FileBuffers.normalizeLocation(FileBuffers.java:103)</Frame>
          <Frame depth="1">org.eclipse.core.filebuffers.FileBuffers.getWorkspaceFileAtLocation(FileBuffers.java:64)</Frame>
          <Frame depth="2">org.eclipse.core.internal.filebuffers.TextFileBufferManager.getLineDelimiterPreference(TextFileBufferManager.java:632)</Frame>
          <Frame depth="3">org.eclipse.core.internal.filebuffers.TextFileBufferManager.createEmptyDocument(TextFileBufferManager.java:297)</Frame>
          <Frame depth="4">org.eclipse.jdt.internal.ui.javaeditor.ClassFileDocumentProvider.createEmptyDocument(ClassFileDocumentProvider.java:237)</Frame>
          <Frame depth="5">org.eclipse.ui.editors.text.StorageDocumentProvider.createDocument(StorageDocumentProvider.java:227)</Frame>
          <Frame depth="6">org.eclipse.jdt.internal.ui.javaeditor.ClassFileDocumentProvider.createDocument(ClassFileDocumentProvider.java:247)</Frame>
          <Frame depth="7">org.eclipse.jdt.internal.ui.javaeditor.ClassFileDocumentProvider.createElementInfo(ClassFileDocumentProvider.java:275)</Frame>
          <Frame depth="8">org.eclipse.ui.texteditor.AbstractDocumentProvider.connect(AbstractDocumentProvider.java:398)</Frame>
          <Frame depth="9">org.eclipse.ui.texteditor.AbstractTextEditor.doSetInput(AbstractTextEditor.java:3022)</Frame>
          <Frame depth="10">org.eclipse.ui.texteditor.StatusTextEditor.doSetInput(StatusTextEditor.java:173)</Frame>
          <Frame depth="11">org.eclipse.ui.texteditor.AbstractDecoratedTextEditor.doSetInput(AbstractDecoratedTextEditor.java:1490)</Frame>
          <Frame depth="12">org.eclipse.jdt.internal.ui.javaeditor.JavaEditor.internalDoSetInput(JavaEditor.java:2211)</Frame>
          <Frame depth="13">org.eclipse.jdt.internal.ui.javaeditor.JavaEditor.doSetInput(JavaEditor.java:2184)</Frame>
          <Frame depth="14">org.eclipse.jdt.internal.ui.javaeditor.ClassFileEditor.doSetInput(ClassFileEditor.java:627)</Frame>
          <Frame depth="15">org.eclipse.ui.texteditor.AbstractTextEditor$17.run(AbstractTextEditor.java:2374)</Frame>
          <Frame depth="16">org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:360)</Frame>
          <Frame depth="17">org.eclipse.jface.operation.ModalContext.run(ModalContext.java:305)</Frame>
          <Frame depth="18">org.eclipse.jface.window.ApplicationWindow$1.run(ApplicationWindow.java:631)</Frame>
        </Frames>
      </Stacktrace>
    </Stacktraces>
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="WORKSFORME" />
    <WithStack>20060106 HEAD

- open 'accessibility_de.class' for rt.jar

java.lang.NullPointerException
	at org.eclipse.core.filebuffers.FileBuffers.normalizeLocation(FileBuffers.java:103)
	at org.eclipse.core.filebuffers.FileBuffers.getWorkspaceFileAtLocation(FileBuffers.java:64)
	at org.eclipse.core.internal.filebuffers.TextFileBufferManager.getLineDelimiterPreference(TextFileBufferManager.java:632)
	at org.eclipse.core.internal.filebuffers.TextFileBufferManager.createEmptyDocument(TextFileBufferManager.java:297)
	at org.eclipse.jdt.internal.ui.javaeditor.ClassFileDocumentProvider.createEmptyDocument(ClassFileDocumentProvider.java:237)
	at org.eclipse.ui.editors.text.StorageDocumentProvider.createDocument(StorageDocumentProvider.java:227)
	at org.eclipse.jdt.internal.ui.javaeditor.ClassFileDocumentProvider.createDocument(ClassFileDocumentProvider.java:247)
	at org.eclipse.jdt.internal.ui.javaeditor.ClassFileDocumentProvider.createElementInfo(ClassFileDocumentProvider.java:275)
	at org.eclipse.ui.texteditor.AbstractDocumentProvider.connect(AbstractDocumentProvider.java:398)
	at org.eclipse.ui.texteditor.AbstractTextEditor.doSetInput(AbstractTextEditor.java:3022)
	at org.eclipse.ui.texteditor.StatusTextEditor.doSetInput(StatusTextEditor.java:173)
	at org.eclipse.ui.texteditor.AbstractDecoratedTextEditor.doSetInput(AbstractDecoratedTextEditor.java:1490)
	at org.eclipse.jdt.internal.ui.javaeditor.JavaEditor.internalDoSetInput(JavaEditor.java:2211)
	at org.eclipse.jdt.internal.ui.javaeditor.JavaEditor.doSetInput(JavaEditor.java:2184)
	at org.eclipse.jdt.internal.ui.javaeditor.ClassFileEditor.doSetInput(ClassFileEditor.java:627)
	at org.eclipse.ui.texteditor.AbstractTextEditor$17.run(AbstractTextEditor.java:2374)
	at org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:360)
	at org.eclipse.jface.operation.ModalContext.run(ModalContext.java:305)
	at org.eclipse.jface.window.ApplicationWindow$1.run(ApplicationWindow.java:631)
&gt;20060106 HEAD
Should read: "20060106 HEAD of JDT UI".
You need HEAD i.e. also Platform Text, especially org.eclipse.core.filebuffers. This is part of yesterdays plug-in export and hence should work.
Sorry, you are right. Just realized now. My fault.</WithStack>
    <WithOutStack>20060106 HEAD

- open 'accessibility_de.class' for rt.jar


&gt;20060106 HEAD
Should read: "20060106 HEAD of JDT UI".
You need HEAD i.e. also Platform Text, especially org.eclipse.core.filebuffers. This is part of yesterdays plug-in export and hence should work.
Sorry, you are right. Just realized now. My fault.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122913" />
    <CreationDate amount="2006-01-06 10:01:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="Ant" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>documentCreation extension point has been deprecated</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="VERIFIED" />
    <resolution amount="FIXED" />
    <WithStack>N20060106-0010

Platform Text has deprecated the org.eclipse.core.filebuffers.documentCreation extension point. See its doc for details.
Created attachment 32585
Fix to remove deprecation
I kinda hoped this might be coming...thanks Dani.
Comment on attachment 32585
Fix to remove deprecation

Wait with this patch. A simpler one is comming soon.
Created attachment 32608
Fix to remove deprecation - needs Platform Text from HEAD
Committed changes from Dani:
plugin.xml removed declaration of org.eclipse.core.filebuffers.documentCreation extension

deleted AntDocumentFactory and PartiallySynchronizedDocument
delected unneeded method in AntEditorDocumentProvider.
.
and to verified.</WithStack>
    <WithOutStack>N20060106-0010

Platform Text has deprecated the org.eclipse.core.filebuffers.documentCreation extension point. See its doc for details.
Created attachment 32585
Fix to remove deprecation
I kinda hoped this might be coming...thanks Dani.
Comment on attachment 32585
Fix to remove deprecation

Wait with this patch. A simpler one is comming soon.
Created attachment 32608
Fix to remove deprecation - needs Platform Text from HEAD
Committed changes from Dani:
plugin.xml removed declaration of org.eclipse.core.filebuffers.documentCreation extension

deleted AntDocumentFactory and PartiallySynchronizedDocument
delected unneeded method in AntEditorDocumentProvider.
.
and to verified.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122914" />
    <CreationDate amount="2006-01-06 10:11:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="Core" />
    <Version amount="3.1.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P5" />
    <bug_severity amount="normal" />
    <Summery>[formatter] Formating java file breaks NLS (//$NON-NLS-1$) comments</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="NEW" />
    <resolution amount="" />
    <WithStack>the pb : 
when long lines with //$NON-NLS-1$ comment in the gets formatted this comment can go to the next line a therefore brings the famous warning (Non-externalized string literal; it should be followed by //$NON-NLS-&lt;n&gt;$) everywhere.

proposed solution :  
There should be a property in the formater profile for comments not to break NLS comments from the line they are on.
Could you please provide a test case? This is supposed to be handled.
Created attachment 32586
Seb's  formated pref file for this bug

just create a new java class and add the following line
displayNamelbl.setText(SignalingMessages.getString("AitPropertiesCompositeControlProvider.0")); // Generated //$NON-NLS-1$

(this is only one line)

import the attached pref and do Ctrl+Shif+F and you'll see the //$NON-NLS-1$ go to the next line.
What happens if you remove // Generated ?
it works perfectly, so indeed this is a bug (side effect) of the // generated comment.
shall I rename the bug, create a new one or leave this one (I'd rather)

SeB.
Leave this one open. This is a bug on our side.
Looking at the code this should also be supported. We simply check if the line comment contains //$NON-NLS-.
I'll investigate, but not immediately.
This is a bug in the comment formatter.
If you disable comment formatting for now, it should work.
I'll work later on the comment formatter.
The comment formatter should not format line comment that contains NLS tags.
Since 3.3M5, you can disable the line comment formatting from other comment formatting (block or javadoc).
Ownership has changed for the formatter, but I surely will not have enough time to fix your bug during the 3.5 development process, hence set its priority to P5.
Please provide a patch if you definitely need the bug to be fixed in this version and I'll have a look at it...
TIA</WithStack>
    <WithOutStack>the pb : 
when long lines with //$NON-NLS-1$ comment in the gets formatted this comment can go to the next line a therefore brings the famous warning (Non-externalized string literal; it should be followed by //$NON-NLS-&lt;n&gt;$) everywhere.

proposed solution :  
There should be a property in the formater profile for comments not to break NLS comments from the line they are on.
Could you please provide a test case? This is supposed to be handled.
Created attachment 32586
Seb's  formated pref file for this bug

just create a new java class and add the following line
displayNamelbl.setText(SignalingMessages.getString("AitPropertiesCompositeControlProvider.0")); // Generated //$NON-NLS-1$

(this is only one line)

import the attached pref and do Ctrl+Shif+F and you'll see the //$NON-NLS-1$ go to the next line.
What happens if you remove // Generated ?
it works perfectly, so indeed this is a bug (side effect) of the // generated comment.
shall I rename the bug, create a new one or leave this one (I'd rather)

SeB.
Leave this one open. This is a bug on our side.
Looking at the code this should also be supported. We simply check if the line comment contains //$NON-NLS-.
I'll investigate, but not immediately.
This is a bug in the comment formatter.
If you disable comment formatting for now, it should work.
I'll work later on the comment formatter.
The comment formatter should not format line comment that contains NLS tags.
Since 3.3M5, you can disable the line comment formatting from other comment formatting (block or javadoc).
Ownership has changed for the formatter, but I surely will not have enough time to fix your bug during the 3.5 development process, hence set its priority to P5.
Please provide a patch if you definitely need the bug to be fixed in this version and I'll have a look at it...
TIA</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122915" />
    <CreationDate amount="2006-01-06 10:15:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="Core" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>DefaultScope.getNode not accessible in strict mode</Summery>
    <Patches amount="0" />
    <Stacktraces amount="4">
      <Stacktrace timestamp="1437330631538">
        <Exception>org.osgi.framework.BundleException</Exception>
        <Reason>Exception in test.importer.Activator.start() of bundle test.importer.</Reason>
        <Frames>
          <Frame depth="0">org.eclipse.osgi.framework.internal.core.BundleContextImpl.startActivator(BundleContextImpl.java:1013)</Frame>
          <Frame depth="1">org.eclipse.osgi.framework.internal.core.BundleContextImpl.start(BundleContextImpl.java:969)</Frame>
          <Frame depth="2">org.eclipse.osgi.framework.internal.core.BundleHost.startWorker(BundleHost.java:316)</Frame>
          <Frame depth="3">org.eclipse.osgi.framework.internal.core.AbstractBundle.start(AbstractBundle.java:255)</Frame>
          <Frame depth="4">org.eclipse.osgi.framework.internal.core.FrameworkCommandProvider._start(FrameworkCommandProvider.java:232)</Frame>
          <Frame depth="5">sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</Frame>
          <Frame depth="6">sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)</Frame>
          <Frame depth="7">sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)</Frame>
          <Frame depth="8">java.lang.reflect.Method.invoke(Method.java:585)</Frame>
          <Frame depth="9">org.eclipse.osgi.framework.internal.core.FrameworkCommandInterpreter.execute(FrameworkCommandInterpreter.java:145)</Frame>
          <Frame depth="10">org.eclipse.osgi.framework.internal.core.FrameworkConsole.docommand(FrameworkConsole.java:293)</Frame>
          <Frame depth="11">org.eclipse.osgi.framework.internal.core.FrameworkConsole.console(FrameworkConsole.java:278)</Frame>
          <Frame depth="12">org.eclipse.osgi.framework.internal.core.FrameworkConsole.run(FrameworkConsole.java:213)</Frame>
          <Frame depth="13">java.lang.Thread.run(Thread.java:595)</Frame>
        </Frames>
      </Stacktrace>
      <Cause timestamp="1437330631538">
        <Exception>java.lang.NoClassDefFoundError</Exception>
        <Reason>test/api/basetypes/BaseType</Reason>
        <Frames>
          <Frame depth="0">test.importer.Activator.start(Activator.java:11)</Frame>
          <Frame depth="1">org.eclipse.osgi.framework.internal.core.BundleContextImpl$2.run(BundleContextImpl.java:994)</Frame>
          <Frame depth="2">java.security.AccessController.doPrivileged(Native Method)</Frame>
          <Frame depth="3">org.eclipse.osgi.framework.internal.core.BundleContextImpl.startActivator(BundleContextImpl.java:988)</Frame>
        </Frames>
      </Cause>
      <Stacktrace timestamp="1437330631538">
        <Exception>java.lang.NoClassDefFoundError</Exception>
        <Reason>test/api/basetypes/BaseType</Reason>
        <Frames>
          <Frame depth="0">test.importer.Activator.start(Activator.java:11)</Frame>
          <Frame depth="1">org.eclipse.osgi.framework.internal.core.BundleContextImpl$2.run(BundleContextImpl.java:994)</Frame>
          <Frame depth="2">java.security.AccessController.doPrivileged(Native Method)</Frame>
          <Frame depth="3">org.eclipse.osgi.framework.internal.core.BundleContextImpl.startActivator(BundleContextImpl.java:988)</Frame>
          <Frame depth="4">org.eclipse.osgi.framework.internal.core.BundleContextImpl.start(BundleContextImpl.java:969)</Frame>
          <Frame depth="5">org.eclipse.osgi.framework.internal.core.BundleHost.startWorker(BundleHost.java:316)</Frame>
          <Frame depth="6">org.eclipse.osgi.framework.internal.core.AbstractBundle.start(AbstractBundle.java:255)</Frame>
          <Frame depth="7">org.eclipse.osgi.framework.internal.core.FrameworkCommandProvider._start(FrameworkCommandProvider.java:232)</Frame>
          <Frame depth="8">sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</Frame>
          <Frame depth="9">sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)</Frame>
          <Frame depth="10">sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)</Frame>
          <Frame depth="11">java.lang.reflect.Method.invoke(Method.java:585)</Frame>
          <Frame depth="12">org.eclipse.osgi.framework.internal.core.FrameworkCommandInterpreter.execute(FrameworkCommandInterpreter.java:145)</Frame>
          <Frame depth="13">org.eclipse.osgi.framework.internal.core.FrameworkConsole.docommand(FrameworkConsole.java:293)</Frame>
          <Frame depth="14">org.eclipse.osgi.framework.internal.core.FrameworkConsole.console(FrameworkConsole.java:278)</Frame>
          <Frame depth="15">org.eclipse.osgi.framework.internal.core.FrameworkConsole.run(FrameworkConsole.java:213)</Frame>
          <Frame depth="16">java.lang.Thread.run(Thread.java:595)</Frame>
        </Frames>
      </Stacktrace>
      <Stacktrace timestamp="1437330631538">
        <Exception>java.lang.NoClassDefFoundError</Exception>
        <Reason>test/api/basetypes/BaseType</Reason>
        <Frames>
          <Frame depth="0">test.importer.Activator.start(Activator.java:11)</Frame>
          <Frame depth="1">org.eclipse.osgi.framework.internal.core.BundleContextImpl$2.run(BundleContextImpl.java:994)</Frame>
          <Frame depth="2">java.security.AccessController.doPrivileged(Native Method)</Frame>
          <Frame depth="3">org.eclipse.osgi.framework.internal.core.BundleContextImpl.startActivator(BundleContextImpl.java:988)</Frame>
          <Frame depth="4">org.eclipse.osgi.framework.internal.core.BundleContextImpl.start(BundleContextImpl.java:969)</Frame>
          <Frame depth="5">org.eclipse.osgi.framework.internal.core.BundleHost.startWorker(BundleHost.java:316)</Frame>
          <Frame depth="6">org.eclipse.osgi.framework.internal.core.AbstractBundle.start(AbstractBundle.java:255)</Frame>
          <Frame depth="7">org.eclipse.osgi.framework.internal.core.FrameworkCommandProvider._start(FrameworkCommandProvider.java:232)</Frame>
          <Frame depth="8">sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</Frame>
          <Frame depth="9">sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)</Frame>
          <Frame depth="10">sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)</Frame>
          <Frame depth="11">java.lang.reflect.Method.invoke(Method.java:585)</Frame>
          <Frame depth="12">org.eclipse.osgi.framework.internal.core.FrameworkCommandInterpreter.execute(FrameworkCommandInterpreter.java:145)</Frame>
          <Frame depth="13">org.eclipse.osgi.framework.internal.core.FrameworkConsole.docommand(FrameworkConsole.java:293)</Frame>
          <Frame depth="14">org.eclipse.osgi.framework.internal.core.FrameworkConsole.console(FrameworkConsole.java:278)</Frame>
          <Frame depth="15">org.eclipse.osgi.framework.internal.core.FrameworkConsole.run(FrameworkConsole.java:213)</Frame>
          <Frame depth="16">java.lang.Thread.run(Thread.java:595)</Frame>
        </Frames>
      </Stacktrace>
    </Stacktraces>
    <SourceCodeRegions amount="9">
      <source_code type="functioncall">
        <location start="610" end="659" />
        <code>.getDefault().getBundle().getSymbolicName());</code>
      </source_code>
      <source_code type="assignment">
        <location start="681" end="724" />
        <code>IScopeContext context = new DefaultScope();</code>
      </source_code>
      <source_code type="functioncall">
        <location start="784" end="833" />
        <code>.getDefault().getBundle().getSymbolicName());</code>
      </source_code>
      <source_code type="functioncall">
        <location start="1588" end="1601" />
        <code>void foo();</code>
      </source_code>
      <source_code type="class">
        <location start="1604" end="1654" />
        <code>abstract class A implements I {
  void foo() {};
}</code>
      </source_code>
      <source_code type="class">
        <location start="1655" end="1676" />
        <code>class B extends A {
}</code>
      </source_code>
      <source_code type="assignment">
        <location start="1761" end="1775" />
        <code>I b = new B();</code>
      </source_code>
      <source_code type="functioncall">
        <location start="1776" end="1784" />
        <code>b.foo();</code>
      </source_code>
      <source_code type="functioncall">
        <location start="1809" end="1823" />
        <code>new B().foo();</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="1">
      <Enumeration lines="3">
        <Lines>
          <Line>1. we keep current behavior, have users adjust their code. In essence, it looks good as the resulting code will be clearer anyway. The compiler diagnosis is indicating a scenario where the bytecode needs to be modified(as described in comment 12), and you'd better want the original source to be fixed.</Line>
          <Line>2. we remove support for inheriting restrictions (or make it optional). We will revert to being a bit too permissive, but this is back to strict 3.1.0 behavior.</Line>
          <Line>3. we still inherit restrictions, but make the inheritance smarter to notice that some definitions are overriding/implementing unrestricted ones (method verifier).</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="NEW" />
    <resolution amount="" />
    <WithStack>20050106

When you are running in strict mode all methods from AbstractScope are not accessible due to the access restrictions in org.eclipse.equinox.preferences.

As a result you cannot call DefaultScope#getNode() without an access restriction violation.
Adding Maxime as it appears that some changes to the compiler rules have surfaced this. It doesn't appear to affect our builds but it will mean that we cannot compile our preference initializers in the workbench.
Dropping to normal as Maxime has told me an easy workaround

the code

IEclipsePreferences node = new DefaultScope().getNode(WorkbenchPlugin
				.getDefault().getBundle().getSymbolicName());

can be written as 

IScopeContext context = new DefaultScope();
IEclipsePreferences node = context.getNode(WorkbenchPlugin
				.getDefault().getBundle().getSymbolicName());

Isn't this a bug in the compiler's implementation of access restrctions?  Clearly the method "String getNode(String)" is accessible on class DefaultScope via IScopeContext.  Moving to Equinox where the preference plugin lives.
(In reply to comment #3)
&gt; Isn't this a bug in the compiler's implementation of access restrctions? 
&gt; Clearly the method "String getNode(String)" is accessible on class DefaultScope
&gt; via IScopeContext.
The fact that we complain upon restricted inherited methods is new with bug 76266. Prior bug 76266, client code could get access to methods of restricted classes by subclassing those classes.




I talked this over with Olivier and Kent and I believe we agree this is a compiler issue.

 Here is a summary:

interface I {
  void foo();
}
abstract class A implements I {
  void foo() {};
}
class B extends A {
}

where I and B are API and A is internal.

When running in strict mode this works: 
I b = new B();
b.foo();

and this doesn't work:
new B().foo();
The compiler binds new B().foo() to A#foo() (which you can check with hovering).
A is internal, so are its methods. The interface method is irrelevant here, as never considered by the compiler (not needed to bind).

When indirecting through the interface, then the compiler will ignore A#foo(), and thus stop complaining. 

Now I understand this is unhappy for client code, though it forces the code to not make decisions upon internal material. 

Kent: are you suggesting overriding a non-restricted method should grant it as non-restricted either ? i.e. method verifier issue ?
*** Bug 123737 has been marked as a duplicate of this bug. ***
I think the difficulty is we don't have a good definition of what an access restriction means.   According to Eclipse API rules, public and protected members in supertypes of an API type are automatically API regardless of whether the supertype is in an API package.  Changing any of those members in the supertype would be a non binary-compatible change to the API of the public class.  It sounds like access restrictions don't follow this model.
I think JohnA is on the right path.

Who can define what strict mode means?

In straight Java terms, public/protected inherited methods are visible to any client if the receiver type B (not the declaring type A) is visible.

But what does this mean in terms of access restrictions &amp; strict mode????
Tom or Jeff, do you know the strict OSGi behaviour here?  Where A is in a package that is not exported, and subclass B is in an exported package.  References to B#foo where foo is declared on A...  I presume the code in comment #2 is not currently causing us runtime errors, just compile errors.
I need to investgate.  But I believe it should work.  CC'ing BJ because OSGi had a similar issue, but I think it was slightly different.


Yes, this does sound like the issue we researched in the OSGi build. Using the example code in comment #5, if a bundle imports the packages containing I and B but does not import the package containing A, the code of the form "new B().foo()" can result in a verifier error at runtime when the verifier cannot find A since the code "new B().foo()" will generate a constant pool reference to "A.foo()" (assuming you just use normal javac to compile). Modifying the code to "( (I) new B() ).foo()" solves the unsuccessful attempt to load A since the constant pool now refers to "I.foo()".

The change we made was to our bundle builder tool to examine the method refs in the constant pool and add the import for the package containing A.

Since the compiler is now respecting runtime class visibility, these issues are surfacing at compile time. I see two solutions: (1) the package containing A must be imported to the compiler can see "A.foo()" or (2) the compiler should look further and see that foo() is visible on B through some superclass or interface which is visible via an already imported package and generate the appropriate bytecodes (e.g. invokeinterface) to avoid the reference to "A.foo()" (not sure if (2) is strictly kosher :-)
So assuming the JDT access restrictions are intending to reflect the OSGi behaviour, it sounds like the compiler is doing the right thing here. 

In this case, I would suggest fixing DefaultScope to 1) add implements IScopeContext, and 2) Override any public methods inherited from AbstractScope and just put super invocations in the method bodies.  This actually makes the API clearer for the javadoc reader anyway.  We have a number of examples of this approach in the platform already: Job does this with methods inherited from the non-API supertype InternalJob, and IncrementalProjectBuilder from InternalBuilder, for example.
Created attachment 33014
testcase bundles

Wait lets not be too hasty.  This is a complicated problem that is not very easy to explain or diagnose.  I believe the code outlined in this bug report actually works at runtime.  Attached is a simple testcase to demonstrate the different problems which can occur because of accessiblity problems.

In the testcase the Activator class of the test.importer bundle performs the two tests.  

In the first test it constructs and calls a method directly on the constructed object "new Concrete1Api().method1();".  Where method1 is a public method inherited from internal class BaseApi which implements method1 from public API interface Test1Api.  This is basically the case outlined in comment 5.  The package test.internal.api is not accessible from test.importer bundle and therefore the jdt compiler is complaining about accessibility problems.  Note that the project has compiler settings to make this a warning.  But this code runs just fine at runtime.

The second test is more like the problem which was surfaced within OSGi.  In this case the class test.api.Test2Api defines a method which takes a parameter of type test.api.basetypes.BaseType.  And test.api.concrete.Concrete2Api implements test.api.test2Api and there is a test.api.concrete.ConcreteType class which implements test.api.basetypes.BaseType.  The test.importer bundle does not have access to the test.api.basetypes, but does have access to the test.api.concrete package. In the second test the test.importer bundle calls "new Concrete2Api().method1(new ConcreteType());"
This line of code actually fails at runtime but does not get any compiler error from JDT.

So it appears to me JDT is too strict in the first case but not strict enough in the second case.

To run the testcase import the zip into your workspace and start eclipse with "-console" and start the test.importer bundle.

osgi&gt; start test.importer
When running in -verbose mode, here is the console output:

osgi&gt; start test.importer
[Loaded test.importer.Activator from file:/d:/test.importer/bin/]
[Loaded test.importer.Test1 from file:/d:/test.importer/bin/]
[Loaded test.api.Test1Api from file:/d:/test.exporter/bin/]
[Loaded test.internal.api.BaseApi from file:/d:/test.exporter/bin/]
[Loaded test.api.concrete.Concrete1Api from file:/d:/test.exporter/bin/]
[Loaded test.importer.Test2 from file:/d:/test.importer/bin/]
org.osgi.framework.BundleException: Exception in test.importer.Activator.start() of bundle test.importer.
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.startActivator(BundleContextImpl.java:1013)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.start(BundleContextImpl.java:969)
	at org.eclipse.osgi.framework.internal.core.BundleHost.startWorker(BundleHost.java:316)
	at org.eclipse.osgi.framework.internal.core.AbstractBundle.start(AbstractBundle.java:255)
	at org.eclipse.osgi.framework.internal.core.FrameworkCommandProvider._start(FrameworkCommandProvider.java:232)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.eclipse.osgi.framework.internal.core.FrameworkCommandInterpreter.execute(FrameworkCommandInterpreter.java:145)
	at org.eclipse.osgi.framework.internal.core.FrameworkConsole.docommand(FrameworkConsole.java:293)
	at org.eclipse.osgi.framework.internal.core.FrameworkConsole.console(FrameworkConsole.java:278)
	at org.eclipse.osgi.framework.internal.core.FrameworkConsole.run(FrameworkConsole.java:213)
	at java.lang.Thread.run(Thread.java:595)
Caused by: java.lang.NoClassDefFoundError: test/api/basetypes/BaseType
	at test.importer.Activator.start(Activator.java:11)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl$2.run(BundleContextImpl.java:994)
	at java.security.AccessController.doPrivileged(Native Method)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.startActivator(BundleContextImpl.java:988)
	... 13 more
[Loaded java.lang.Class$MethodArray from D:\jdk1.5.0\jre\lib\rt.jar]
Nested Exception:
java.lang.NoClassDefFoundError: test/api/basetypes/BaseType
	at test.importer.Activator.start(Activator.java:11)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl$2.run(BundleContextImpl.java:994)
	at java.security.AccessController.doPrivileged(Native Method)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.startActivator(BundleContextImpl.java:988)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.start(BundleContextImpl.java:969)
	at org.eclipse.osgi.framework.internal.core.BundleHost.startWorker(BundleHost.java:316)
	at org.eclipse.osgi.framework.internal.core.AbstractBundle.start(AbstractBundle.java:255)
	at org.eclipse.osgi.framework.internal.core.FrameworkCommandProvider._start(FrameworkCommandProvider.java:232)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.eclipse.osgi.framework.internal.core.FrameworkCommandInterpreter.execute(FrameworkCommandInterpreter.java:145)
	at org.eclipse.osgi.framework.internal.core.FrameworkConsole.docommand(FrameworkConsole.java:293)
	at org.eclipse.osgi.framework.internal.core.FrameworkConsole.console(FrameworkConsole.java:278)
	at org.eclipse.osgi.framework.internal.core.FrameworkConsole.run(FrameworkConsole.java:213)
	at java.lang.Thread.run(Thread.java:595)
Nested Exception:
java.lang.NoClassDefFoundError: test/api/basetypes/BaseType
	at test.importer.Activator.start(Activator.java:11)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl$2.run(BundleContextImpl.java:994)
	at java.security.AccessController.doPrivileged(Native Method)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.startActivator(BundleContextImpl.java:988)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.start(BundleContextImpl.java:969)
	at org.eclipse.osgi.framework.internal.core.BundleHost.startWorker(BundleHost.java:316)
	at org.eclipse.osgi.framework.internal.core.AbstractBundle.start(AbstractBundle.java:255)
	at org.eclipse.osgi.framework.internal.core.FrameworkCommandProvider._start(FrameworkCommandProvider.java:232)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.eclipse.osgi.framework.internal.core.FrameworkCommandInterpreter.execute(FrameworkCommandInterpreter.java:145)
	at org.eclipse.osgi.framework.internal.core.FrameworkConsole.docommand(FrameworkConsole.java:293)
	at org.eclipse.osgi.framework.internal.core.FrameworkConsole.console(FrameworkConsole.java:278)
	at org.eclipse.osgi.framework.internal.core.FrameworkConsole.run(FrameworkConsole.java:213)
	at java.lang.Thread.run(Thread.java:595)
OSGi semantics are not described in Java language specification, and as such 
are not implemented in a Java compiler. OSGi is hiding some types at runtime, this is all the magic which is involved there I believe. Note that a compiler needs to load all types involved in a type hierarchy (for instance) to perform static verifications, which some runtime may not care about due to lazy loading or solve differently when dealing with cooperating bundle classloaders. 

The OSGi behavior would best be emulated by discarding the corresponding classfile from the compile time classpath. Access restrictions are NOT emulating this. A restricted type remains on the classpath, and can be bound to. 
However when doing so however the compiler will report it. The fact OSGi behavior is emulated using restrictions doesn't mean restrictions have to follow OSGi specific semantics. Restrictions were designed to enforce clean separation between API and non-API code.

There is no way for internal types to be ignored when conducting name lookups, unless we change the lookup semantics (and say for instance that a restricted method isn't considered any longer). 

Note that in bug 98127, we are considering a change in access restrictions, which will better allow emulating OSGi runtime behavior, but this change is located in a different area of the compiler, and could be implemented based on standard compiler API (e.g. see JSR-199). Whereas the change implied here would require a true change in compiler lookup semantics which isn't a pluggable semantics even considering JSR-199. So, if we moved into that space, we would break the law.

I can see 3 options for 3.2:
1. we keep current behavior, have users adjust their code. In essence, it looks good as the resulting code will be clearer anyway. The compiler diagnosis is indicating a scenario where the bytecode needs to be modified(as described in comment 12), and you'd better want the original source to be fixed.
2. we remove support for inheriting restrictions (or make it optional). We will revert to being a bit too permissive, but this is back to strict 3.1.0 behavior.
3. we still inherit restrictions, but make the inheritance smarter to notice that some definitions are overriding/implementing unrestricted ones (method verifier). 

   Unclear if we could efficiently handle the case where the unrestricted method is only indirectly overriden/implemented (i.e. if the super method is also restricted, but need to look further up in hierarchy).
   e.g.
     interface I#foo()   // API
     class A implements I, defines #foo()  // internal
     class B extends A, defines #foo()  // internal
     class C extends B // API
   Now, depending on our algorith, this could be handled when recursively verifying A before B, and thus noting that A#foo() isn't restricted, thus it would get propagated to B#foo() when comparing it with A#foo(). But I suspect this property isn't guaranteed inside binary types (i.e. they do not get verified at all, only sources get verified, so B#foo() would still look like it is internal).

My preference is (1). I could agree to (2) to reach consensus. I am seeing (3) as future work (&gt;3.2), but if considering this in the future, then we may rather want to go for (2) now, i.e. revert to original behavior before we reconsider our solution there.

Hmmm, +1 for #1 with an option for #3 at a later date?
fyi: I have released code into HEAD for DefaultScope (and the other sub-classes of AbstractScope) that:
1). adds "implements IScopeContext"
2). implements #getNode which just called the super implementation

Kent - pls comment on feasibility of #3.
We cannot guarantee that types are verified in order of their hierarchy.

So whenever we're verifying an API type, that would mean every inherited method which matches a current method (ignoring all the issues with pseudo-overridden methods with generics), would need to be checked to see if one is or is not an API method.

Its possible but far from efficient.
*** Bug 142985 has been marked as a duplicate of this bug. ***
*** Bug 146394 has been marked as a duplicate of this bug. ***
*** Bug 180629 has been marked as a duplicate of this bug. ***
From the equinox mailing list.  This is still an issue for many, is there an outlook for a fix?

Hi,

The PDE bug that disallow exported subclasses to extend from
non-exported internal classes is getting on my nerve. The internal
superclass is something I insist of not exporting, since it is
something we don't want to support, and users are demanding that we do
so because otherwise their code doesn't compile in PDE.

What does the Equinox community recommend? Do the wrong thing and
export the internal classes as a compile-time work-around, or what? I
don't use Eclipse, and don't have a problem myself, and it annoys the
crap out of me to give into these kinds of demands, when the tooling
is crappy...

Any ideas of what one should do?

(Mind you this is not a problem in Equinox, only the PDE.)


Cheers
Niclas
If this bug is not going to be resolved, then mark it as "WON'T FIX" with whatever excuse there is. At least I can tell our users to stop using PDE for the projects in question, with a pointer to why... 

My original report in https://bugs.eclipse.org/bugs/show_bug.cgi?id=180629 looks a lot simpler than the full discussion on this issue, but maybe that is just artificially...

Thanks.
CC'ing Chris for his awareness.  This (non-PDE) bug is creating some unhappy PDE users.
Another cross reference: in bug 148844 (and others) the impact of 
inaccessible classes on overloading resolution is discussed and in
bug 148844 comment 35 I suggested to develop an OSGi mode for the
compiler which would need to work in a way similar to what has been 
discussed here as the &gt;3.2 solution.

Is anybody planning to make the compiler more OSGi aware (optionally)?
I could offer some help but certainly won't start working on this 
before a conceptual agreement has been reached.</WithStack>
    <WithOutStack>20050106

When you are running in strict mode all methods from AbstractScope are not accessible due to the access restrictions in org.eclipse.equinox.preferences.

As a result you cannot call DefaultScope#getNode() without an access restriction violation.
Adding Maxime as it appears that some changes to the compiler rules have surfaced this. It doesn't appear to affect our builds but it will mean that we cannot compile our preference initializers in the workbench.
Dropping to normal as Maxime has told me an easy workaround

the code

IEclipsePreferences node = new DefaultScope().getNode(WorkbenchPlugin
				.getDefault().getBundle().getSymbolicName());

can be written as 

IScopeContext context = new DefaultScope();
IEclipsePreferences node = context.getNode(WorkbenchPlugin
				.getDefault().getBundle().getSymbolicName());

Isn't this a bug in the compiler's implementation of access restrctions?  Clearly the method "String getNode(String)" is accessible on class DefaultScope via IScopeContext.  Moving to Equinox where the preference plugin lives.
(In reply to comment #3)
&gt; Isn't this a bug in the compiler's implementation of access restrctions? 
&gt; Clearly the method "String getNode(String)" is accessible on class DefaultScope
&gt; via IScopeContext.
The fact that we complain upon restricted inherited methods is new with bug 76266. Prior bug 76266, client code could get access to methods of restricted classes by subclassing those classes.




I talked this over with Olivier and Kent and I believe we agree this is a compiler issue.

 Here is a summary:

interface I {
  void foo();
}
abstract class A implements I {
  void foo() {};
}
class B extends A {
}

where I and B are API and A is internal.

When running in strict mode this works: 
I b = new B();
b.foo();

and this doesn't work:
new B().foo();
The compiler binds new B().foo() to A#foo() (which you can check with hovering).
A is internal, so are its methods. The interface method is irrelevant here, as never considered by the compiler (not needed to bind).

When indirecting through the interface, then the compiler will ignore A#foo(), and thus stop complaining. 

Now I understand this is unhappy for client code, though it forces the code to not make decisions upon internal material. 

Kent: are you suggesting overriding a non-restricted method should grant it as non-restricted either ? i.e. method verifier issue ?
*** Bug 123737 has been marked as a duplicate of this bug. ***
I think the difficulty is we don't have a good definition of what an access restriction means.   According to Eclipse API rules, public and protected members in supertypes of an API type are automatically API regardless of whether the supertype is in an API package.  Changing any of those members in the supertype would be a non binary-compatible change to the API of the public class.  It sounds like access restrictions don't follow this model.
I think JohnA is on the right path.

Who can define what strict mode means?

In straight Java terms, public/protected inherited methods are visible to any client if the receiver type B (not the declaring type A) is visible.

But what does this mean in terms of access restrictions &amp; strict mode????
Tom or Jeff, do you know the strict OSGi behaviour here?  Where A is in a package that is not exported, and subclass B is in an exported package.  References to B#foo where foo is declared on A...  I presume the code in comment #2 is not currently causing us runtime errors, just compile errors.
I need to investgate.  But I believe it should work.  CC'ing BJ because OSGi had a similar issue, but I think it was slightly different.


Yes, this does sound like the issue we researched in the OSGi build. Using the example code in comment #5, if a bundle imports the packages containing I and B but does not import the package containing A, the code of the form "new B().foo()" can result in a verifier error at runtime when the verifier cannot find A since the code "new B().foo()" will generate a constant pool reference to "A.foo()" (assuming you just use normal javac to compile). Modifying the code to "( (I) new B() ).foo()" solves the unsuccessful attempt to load A since the constant pool now refers to "I.foo()".

The change we made was to our bundle builder tool to examine the method refs in the constant pool and add the import for the package containing A.

Since the compiler is now respecting runtime class visibility, these issues are surfacing at compile time. I see two solutions: (1) the package containing A must be imported to the compiler can see "A.foo()" or (2) the compiler should look further and see that foo() is visible on B through some superclass or interface which is visible via an already imported package and generate the appropriate bytecodes (e.g. invokeinterface) to avoid the reference to "A.foo()" (not sure if (2) is strictly kosher :-)
So assuming the JDT access restrictions are intending to reflect the OSGi behaviour, it sounds like the compiler is doing the right thing here. 

In this case, I would suggest fixing DefaultScope to 1) add implements IScopeContext, and 2) Override any public methods inherited from AbstractScope and just put super invocations in the method bodies.  This actually makes the API clearer for the javadoc reader anyway.  We have a number of examples of this approach in the platform already: Job does this with methods inherited from the non-API supertype InternalJob, and IncrementalProjectBuilder from InternalBuilder, for example.
Created attachment 33014
testcase bundles

Wait lets not be too hasty.  This is a complicated problem that is not very easy to explain or diagnose.  I believe the code outlined in this bug report actually works at runtime.  Attached is a simple testcase to demonstrate the different problems which can occur because of accessiblity problems.

In the testcase the Activator class of the test.importer bundle performs the two tests.  

In the first test it constructs and calls a method directly on the constructed object "new Concrete1Api().method1();".  Where method1 is a public method inherited from internal class BaseApi which implements method1 from public API interface Test1Api.  This is basically the case outlined in comment 5.  The package test.internal.api is not accessible from test.importer bundle and therefore the jdt compiler is complaining about accessibility problems.  Note that the project has compiler settings to make this a warning.  But this code runs just fine at runtime.

The second test is more like the problem which was surfaced within OSGi.  In this case the class test.api.Test2Api defines a method which takes a parameter of type test.api.basetypes.BaseType.  And test.api.concrete.Concrete2Api implements test.api.test2Api and there is a test.api.concrete.ConcreteType class which implements test.api.basetypes.BaseType.  The test.importer bundle does not have access to the test.api.basetypes, but does have access to the test.api.concrete package. In the second test the test.importer bundle calls "new Concrete2Api().method1(new ConcreteType());"
This line of code actually fails at runtime but does not get any compiler error from JDT.

So it appears to me JDT is too strict in the first case but not strict enough in the second case.

To run the testcase import the zip into your workspace and start eclipse with "-console" and start the test.importer bundle.

osgi&gt; start test.importer
When running in -verbose mode, here is the console output:

osgi&gt; start test.importer
[Loaded test.importer.Activator from file:/d:/test.importer/bin/]
[Loaded test.importer.Test1 from file:/d:/test.importer/bin/]
[Loaded test.api.Test1Api from file:/d:/test.exporter/bin/]
[Loaded test.internal.api.BaseApi from file:/d:/test.exporter/bin/]
[Loaded test.api.concrete.Concrete1Api from file:/d:/test.exporter/bin/]
[Loaded test.importer.Test2 from file:/d:/test.importer/bin/]
	... 13 more
[Loaded java.lang.Class$MethodArray from D:\jdk1.5.0\jre\lib\rt.jar]
Nested Exception:
java.lang.NoClassDefFoundError: test/api/basetypes/BaseType
	at test.importer.Activator.start(Activator.java:11)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl$2.run(BundleContextImpl.java:994)
	at java.security.AccessController.doPrivileged(Native Method)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.startActivator(BundleContextImpl.java:988)
	at org.eclipse.osgi.framework.internal.core.BundleContextImpl.start(BundleContextImpl.java:969)
	at org.eclipse.osgi.framework.internal.core.BundleHost.startWorker(BundleHost.java:316)
	at org.eclipse.osgi.framework.internal.core.AbstractBundle.start(AbstractBundle.java:255)
	at org.eclipse.osgi.framework.internal.core.FrameworkCommandProvider._start(FrameworkCommandProvider.java:232)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.eclipse.osgi.framework.internal.core.FrameworkCommandInterpreter.execute(FrameworkCommandInterpreter.java:145)
	at org.eclipse.osgi.framework.internal.core.FrameworkConsole.docommand(FrameworkConsole.java:293)
	at org.eclipse.osgi.framework.internal.core.FrameworkConsole.console(FrameworkConsole.java:278)
	at org.eclipse.osgi.framework.internal.core.FrameworkConsole.run(FrameworkConsole.java:213)
	at java.lang.Thread.run(Thread.java:595)
Nested Exception:

OSGi semantics are not described in Java language specification, and as such 
are not implemented in a Java compiler. OSGi is hiding some types at runtime, this is all the magic which is involved there I believe. Note that a compiler needs to load all types involved in a type hierarchy (for instance) to perform static verifications, which some runtime may not care about due to lazy loading or solve differently when dealing with cooperating bundle classloaders. 

The OSGi behavior would best be emulated by discarding the corresponding classfile from the compile time classpath. Access restrictions are NOT emulating this. A restricted type remains on the classpath, and can be bound to. 
However when doing so however the compiler will report it. The fact OSGi behavior is emulated using restrictions doesn't mean restrictions have to follow OSGi specific semantics. Restrictions were designed to enforce clean separation between API and non-API code.

There is no way for internal types to be ignored when conducting name lookups, unless we change the lookup semantics (and say for instance that a restricted method isn't considered any longer). 

Note that in bug 98127, we are considering a change in access restrictions, which will better allow emulating OSGi runtime behavior, but this change is located in a different area of the compiler, and could be implemented based on standard compiler API (e.g. see JSR-199). Whereas the change implied here would require a true change in compiler lookup semantics which isn't a pluggable semantics even considering JSR-199. So, if we moved into that space, we would break the law.

I can see 3 options for 3.2:
1. we keep current behavior, have users adjust their code. In essence, it looks good as the resulting code will be clearer anyway. The compiler diagnosis is indicating a scenario where the bytecode needs to be modified(as described in comment 12), and you'd better want the original source to be fixed.
2. we remove support for inheriting restrictions (or make it optional). We will revert to being a bit too permissive, but this is back to strict 3.1.0 behavior.
3. we still inherit restrictions, but make the inheritance smarter to notice that some definitions are overriding/implementing unrestricted ones (method verifier). 

   Unclear if we could efficiently handle the case where the unrestricted method is only indirectly overriden/implemented (i.e. if the super method is also restricted, but need to look further up in hierarchy).
   e.g.
     interface I#foo()   // API
     class A implements I, defines #foo()  // internal
     class B extends A, defines #foo()  // internal
     class C extends B // API
   Now, depending on our algorith, this could be handled when recursively verifying A before B, and thus noting that A#foo() isn't restricted, thus it would get propagated to B#foo() when comparing it with A#foo(). But I suspect this property isn't guaranteed inside binary types (i.e. they do not get verified at all, only sources get verified, so B#foo() would still look like it is internal).

My preference is (1). I could agree to (2) to reach consensus. I am seeing (3) as future work (&gt;3.2), but if considering this in the future, then we may rather want to go for (2) now, i.e. revert to original behavior before we reconsider our solution there.

Hmmm, +1 for #1 with an option for #3 at a later date?
fyi: I have released code into HEAD for DefaultScope (and the other sub-classes of AbstractScope) that:
1). adds "implements IScopeContext"
2). implements #getNode which just called the super implementation

Kent - pls comment on feasibility of #3.
We cannot guarantee that types are verified in order of their hierarchy.

So whenever we're verifying an API type, that would mean every inherited method which matches a current method (ignoring all the issues with pseudo-overridden methods with generics), would need to be checked to see if one is or is not an API method.

Its possible but far from efficient.
*** Bug 142985 has been marked as a duplicate of this bug. ***
*** Bug 146394 has been marked as a duplicate of this bug. ***
*** Bug 180629 has been marked as a duplicate of this bug. ***
From the equinox mailing list.  This is still an issue for many, is there an outlook for a fix?

Hi,

The PDE bug that disallow exported subclasses to extend from
non-exported internal classes is getting on my nerve. The internal
superclass is something I insist of not exporting, since it is
something we don't want to support, and users are demanding that we do
so because otherwise their code doesn't compile in PDE.

What does the Equinox community recommend? Do the wrong thing and
export the internal classes as a compile-time work-around, or what? I
don't use Eclipse, and don't have a problem myself, and it annoys the
crap out of me to give into these kinds of demands, when the tooling
is crappy...

Any ideas of what one should do?

(Mind you this is not a problem in Equinox, only the PDE.)


Cheers
Niclas
If this bug is not going to be resolved, then mark it as "WON'T FIX" with whatever excuse there is. At least I can tell our users to stop using PDE for the projects in question, with a pointer to why... 

My original report in https://bugs.eclipse.org/bugs/show_bug.cgi?id=180629 looks a lot simpler than the full discussion on this issue, but maybe that is just artificially...

Thanks.
CC'ing Chris for his awareness.  This (non-PDE) bug is creating some unhappy PDE users.
Another cross reference: in bug 148844 (and others) the impact of 
inaccessible classes on overloading resolution is discussed and in
bug 148844 comment 35 I suggested to develop an OSGi mode for the
compiler which would need to work in a way similar to what has been 
discussed here as the &gt;3.2 solution.

Is anybody planning to make the compiler more OSGi aware (optionally)?
I could offer some help but certainly won't start working on this 
before a conceptual agreement has been reached.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122916" />
    <CreationDate amount="2006-01-06 10:15:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="UI" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Improve code template variable naming</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="1">
      <source_code type="multicomment">
        <location start="510" end="522" />
        <code>/**
 * 
 */</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>Build: I20060105

There are two preferences for what appears at the start of a file:

Java &gt; Editor &gt; Templates &gt; "filecomment"
Java &gt; Code Style &gt; Code Templates &gt; Code &gt; New Java files

This is fine - the first is just for the initial comment, and the second provides a template for other parts of the file as well.  However, it would be nice to link these two to avoid having to update the file comment in two places.  If I update the "New java files" template to be:

${filecomment}
${package_declaration}

/**
 * 
 */
${type_declaration}

It does *not* pick up the value of the filecomment template when I create a new file.  This leads to the error prone condition of having to specify the file comment template in two places.
Java &gt; Editor &gt; Templates &gt; "filecomment" is gone since 3.0. You probably still have this because you use an old workspace. Simply remove it from the template list.
Created attachment 32611
Screen shot of editing code style

Even when I remove the "filecomment" template, it still appears in the list of variables on the code style preference page.  If it is gone, why is it still a variable option (that seems to insert nothing)?
Of course. The 'filecomment' code template is
Code Templates &gt; Comments &gt; File
How could a new user understand that association? (I didn't)  It must be even more confusing when the strings in "Code Templates &gt; Comments &gt; Files" get translated but the variable name is still called "filecomment". The description of the variable is recursive which doesn't give any clues:

filecomment - Content of code template "filecomment"

Perhaps it should be:

filecomment - Content of the Comments &gt; Files code template

Or maybe the name of the variable it represents should appear somewhere on the screen next to the place where it is defined:

+ Comments
   + Files ("filecomment" variable)
   + Types ("typecomment" variable)
etc...


Martin, this makes sense to me.
fixed &gt; 20060109</WithStack>
    <WithOutStack>Build: I20060105

There are two preferences for what appears at the start of a file:

Java &gt; Editor &gt; Templates &gt; "filecomment"
Java &gt; Code Style &gt; Code Templates &gt; Code &gt; New Java files

This is fine - the first is just for the initial comment, and the second provides a template for other parts of the file as well.  However, it would be nice to link these two to avoid having to update the file comment in two places.  If I update the "New java files" template to be:

${filecomment}
${package_declaration}

/**
 * 
 */
${type_declaration}

It does *not* pick up the value of the filecomment template when I create a new file.  This leads to the error prone condition of having to specify the file comment template in two places.
Java &gt; Editor &gt; Templates &gt; "filecomment" is gone since 3.0. You probably still have this because you use an old workspace. Simply remove it from the template list.
Created attachment 32611
Screen shot of editing code style

Even when I remove the "filecomment" template, it still appears in the list of variables on the code style preference page.  If it is gone, why is it still a variable option (that seems to insert nothing)?
Of course. The 'filecomment' code template is
Code Templates &gt; Comments &gt; File
How could a new user understand that association? (I didn't)  It must be even more confusing when the strings in "Code Templates &gt; Comments &gt; Files" get translated but the variable name is still called "filecomment". The description of the variable is recursive which doesn't give any clues:

filecomment - Content of code template "filecomment"

Perhaps it should be:

filecomment - Content of the Comments &gt; Files code template

Or maybe the name of the variable it represents should appear somewhere on the screen next to the place where it is defined:

+ Comments
   + Files ("filecomment" variable)
   + Types ("typecomment" variable)
etc...


Martin, this makes sense to me.
fixed &gt; 20060109</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122917" />
    <CreationDate amount="2006-01-06 10:22:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="CVS" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P2" />
    <bug_severity amount="normal" />
    <Summery>[Model Sync] Make Work in Progress update real</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="6">
        <Lines>
          <Line>- add option to show dialog or go directly to sync view</Line>
          <Line>- improve scope prompting (bug 119921, bug 119935)</Line>
          <Line>- ability to include model actions (merge, overwrite, mark as merged) (bug 119516)</Line>
          <Line>- A dialog that prompts if merge validation fails. The options should be Continue, Preview, Cancel.</Line>
          <Line>- test cases</Line>
          <Line>I have logged bug 123156 for the validation prompt. I have made the update real even though some of the features mentioned above are not in place. Update can still be done bu tthe workflow will be improved once we address the remaining issues.</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>We need to make the work in progress update real. There are a few things that need to happen before this can be done.

- add option to show dialog or go directly to sync view
- improve scope prompting (bug 119921, bug 119935)
- ability to include model actions (merge, overwrite, mark as merged) (bug 119516)
- A dialog that prompts if merge validation fails. The options should be Continue, Preview, Cancel.
- test cases
I have logged bug 123156 for the validation prompt. I have made the update real even though some of the features mentioned above are not in place. Update can still be done bu tthe workflow will be improved once we address the remaining issues.</WithStack>
    <WithOutStack>We need to make the work in progress update real. There are a few things that need to happen before this can be done.

- add option to show dialog or go directly to sync view
- improve scope prompting (bug 119921, bug 119935)
- ability to include model actions (merge, overwrite, mark as merged) (bug 119516)
- A dialog that prompts if merge validation fails. The options should be Continue, Preview, Cancel.
- test cases
I have logged bug 123156 for the validation prompt. I have made the update real even though some of the features mentioned above are not in place. Update can still be done bu tthe workflow will be improved once we address the remaining issues.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122918" />
    <CreationDate amount="2006-01-06 10:24:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse Foundation" />
    <Product amount="Community" />
    <component amount="Website" />
    <Version amount="unspecified" />
    <rep_platform amount="PC" />
    <op_sys amount="Linux" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Committers' Developer Resources moved to the Wiki</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="WORKSFORME" />
    <WithStack>One of the static leftnavs has a Committers link that points to http://dev.eclipse.org/

The original intention of dev.eclipse.org was to be a Development Resources section; however, the content got stale over time because it was hard to access and update.

I have moved those pages to the Wiki - http://wiki.eclipse.org/index.php/Development_Resources - where the committer community as a whole can provide and update the content.

Requesting to change the Committers link to "Development Resources", and the URL to http://wiki.eclipse.org/index.php/Development_Resources

D.
Except for my constant campaign to remove the four left menu items (bug 118282), I think this is a good idea.  I like the wiki Development_Resources much better than the old static pages.
(In reply to comment #1)
&gt; Except for my constant campaign to remove the four left menu items

10-4. Closing this as the link will eventually disappear. Regardless, I've set up redirects for the old pages, so if we decide to put the link to "Committers", I think it should read "Development Resources".  It's linked from the Wiki home page, so it's not imperative.

D.


Moving to Community/Website</WithStack>
    <WithOutStack>One of the static leftnavs has a Committers link that points to http://dev.eclipse.org/

The original intention of dev.eclipse.org was to be a Development Resources section; however, the content got stale over time because it was hard to access and update.

I have moved those pages to the Wiki - http://wiki.eclipse.org/index.php/Development_Resources - where the committer community as a whole can provide and update the content.

Requesting to change the Committers link to "Development Resources", and the URL to http://wiki.eclipse.org/index.php/Development_Resources

D.
Except for my constant campaign to remove the four left menu items (bug 118282), I think this is a good idea.  I like the wiki Development_Resources much better than the old static pages.
(In reply to comment #1)
&gt; Except for my constant campaign to remove the four left menu items

10-4. Closing this as the link will eventually disappear. Regardless, I've set up redirects for the old pages, so if we decide to put the link to "Committers", I think it should read "Development Resources".  It's linked from the Wiki home page, so it's not imperative.

D.


Moving to Community/Website</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122919" />
    <CreationDate amount="2006-01-06 10:39:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="Team" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>[Doc] Document use of sync-aware decoration context</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>We need to document the use of the sync-aware decoration context
Javadoc updated</WithStack>
    <WithOutStack>We need to document the use of the sync-aware decoration context
Javadoc updated</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122920" />
    <CreationDate amount="2006-01-06 10:46:00 -0500" />
    <DupId amount="" />
    <classification amount="Modeling" />
    <Product amount="GMF-Tooling" />
    <component amount="Core" />
    <Version amount="1.0" />
    <rep_platform amount="All" />
    <op_sys amount="All" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Include JavaDoc in GMF Documentation</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>There are no JavaDocs generated and included as part of the GMF documentation build.
Build modified to include generated JavaDoc for tooling and runtime APIs.  Available in last night's build.
[target cleanup] 1.0 M4 was the original target milestone for this bug
[GMF Restructure] Bug 319140 : product GMF and component
Docs was the original product and component for this bug</WithStack>
    <WithOutStack>There are no JavaDocs generated and included as part of the GMF documentation build.
Build modified to include generated JavaDoc for tooling and runtime APIs.  Available in last night's build.
[target cleanup] 1.0 M4 was the original target milestone for this bug
[GMF Restructure] Bug 319140 : product GMF and component
Docs was the original product and component for this bug</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122921" />
    <CreationDate amount="2006-01-06 10:49:00 -0500" />
    <DupId amount="" />
    <classification amount="Modeling" />
    <Product amount="GMF-Tooling" />
    <component amount="Core" />
    <Version amount="1.0" />
    <rep_platform amount="All" />
    <op_sys amount="All" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Include Extension-Point docs in GMF Documentation</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>There are no extension-point reference docs generated and included as part of the GMF documentation build.
Modified the build to include generated HTML documentation of project extension-points.  Available in last night's build. 
[target cleanup] 1.0 M4 was the original target milestone for this bug
[GMF Restructure] Bug 319140 : product GMF and component
Docs was the original product and component for this bug</WithStack>
    <WithOutStack>There are no extension-point reference docs generated and included as part of the GMF documentation build.
Modified the build to include generated HTML documentation of project extension-points.  Available in last night's build. 
[target cleanup] 1.0 M4 was the original target milestone for this bug
[GMF Restructure] Bug 319140 : product GMF and component
Docs was the original product and component for this bug</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122922" />
    <CreationDate amount="2006-01-06 10:53:00 -0500" />
    <DupId amount="" />
    <classification amount="WebTools" />
    <Product amount="WTP Webservices" />
    <component amount="jst.ws" />
    <Version amount="1.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="major" />
    <Summery>Problems with page 3 defaulting logic for serviceRuntime/clientRuntime</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>When running BUJAVA, TDJAVA, CJAVA with an initial selection in a project that is bound to a server runtime not supported by the preferred Web service runtime, page 3 will come up with validation errors in the banner like this:

" XXX server does not support the YYY Web service runtime".

The reason for the problem is that the serviceRuntime/clientRuntime defaulting algorithm is not taking into consideration the server runtime that the initial selection's project is bound to, resulting in the selection of a Web service runtime that does not support the most appropriate server for the project.
This is a regression compared to behaviour before the introdiction of facets and templates. This problem will begin to occur as new Web service runtimes are extended into the platform.
Created attachment 33373
apply to org.eclipse.jst.ws.consumption

patch 1 of 3
Created attachment 33374
apply to org.eclipse.jst.ws.consumption.ui

patch 2 of 3
Created attachment 33375
apply to org.eclipse.jst.ws.creation.ui

patch 3 of 3
The attached patches are ready to be committed. The change consists of choosing , whenever possible, a default service/client runtime that supports the server runtime to which the initial selection's project is bound.
Entwined with bug 121071, so also targetting to 1.0.1.
Some of the fix for 121071 lands in the same code as the fix for 122922 and so
the two fixes should be committed together. I will attach patches to 121071 which will contain fixes for both 121071 and 122922.

Patch reviewed, committed and released to M101 as v20060202_1914.  Will release to HEAD once this week's integration build is declared.
Verified
OK</WithStack>
    <WithOutStack>When running BUJAVA, TDJAVA, CJAVA with an initial selection in a project that is bound to a server runtime not supported by the preferred Web service runtime, page 3 will come up with validation errors in the banner like this:

" XXX server does not support the YYY Web service runtime".

The reason for the problem is that the serviceRuntime/clientRuntime defaulting algorithm is not taking into consideration the server runtime that the initial selection's project is bound to, resulting in the selection of a Web service runtime that does not support the most appropriate server for the project.
This is a regression compared to behaviour before the introdiction of facets and templates. This problem will begin to occur as new Web service runtimes are extended into the platform.
Created attachment 33373
apply to org.eclipse.jst.ws.consumption

patch 1 of 3
Created attachment 33374
apply to org.eclipse.jst.ws.consumption.ui

patch 2 of 3
Created attachment 33375
apply to org.eclipse.jst.ws.creation.ui

patch 3 of 3
The attached patches are ready to be committed. The change consists of choosing , whenever possible, a default service/client runtime that supports the server runtime to which the initial selection's project is bound.
Entwined with bug 121071, so also targetting to 1.0.1.
Some of the fix for 121071 lands in the same code as the fix for 122922 and so
the two fixes should be committed together. I will attach patches to 121071 which will contain fixes for both 121071 and 122922.

Patch reviewed, committed and released to M101 as v20060202_1914.  Will release to HEAD once this week's integration build is declared.
Verified
OK</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122923" />
    <CreationDate amount="2006-01-06 11:13:00 -0500" />
    <DupId amount="" />
    <classification amount="WebTools" />
    <Product amount="WTP ServerTools" />
    <component amount="wst.server" />
    <Version amount="unspecified" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="enhancement" />
    <Summery>API request for log file information of server instance</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="WONTFIX" />
    <WithStack>In TPTP integration of WTP, there is a feature which allows user to import server log file(s) for problem determination analysis. In order to enhance the usability of such feature, we need API(s) from IServer to query for all log file(s) available of a server instance as well as its location/path to facilitate the import process.
It wouldn't hurt if the Server view itself made the logs openable using the external file support, too.
This bug has gone nowhere, and I believe the main reason is that it's going the wrong way around. There are no server adapters in WTP that provide log file information, and hence no point in creating a common public API for it. Likewise, there has been no request to add log info to any of the WTP server adapters, nor server adapters developed elsewhere requesting public API to make this support common at the WTP level.

Since this bug has been sitting dormant for over a year and there are no plans for WTP to do anything, I am closing it. If this is still an issue, please start with one or more specific server adapters to request this capability. Once it has been implemented and proven once, and if there is a likelihood that it'll be used by other server adapters, we can make a common public interface in WTP.
Closing bug.</WithStack>
    <WithOutStack>In TPTP integration of WTP, there is a feature which allows user to import server log file(s) for problem determination analysis. In order to enhance the usability of such feature, we need API(s) from IServer to query for all log file(s) available of a server instance as well as its location/path to facilitate the import process.
It wouldn't hurt if the Server view itself made the logs openable using the external file support, too.
This bug has gone nowhere, and I believe the main reason is that it's going the wrong way around. There are no server adapters in WTP that provide log file information, and hence no point in creating a common public API for it. Likewise, there has been no request to add log info to any of the WTP server adapters, nor server adapters developed elsewhere requesting public API to make this support common at the WTP level.

Since this bug has been sitting dormant for over a year and there are no plans for WTP to do anything, I am closing it. If this is still an issue, please start with one or more specific server adapters to request this capability. Once it has been implemented and proven once, and if there is a likelihood that it'll be used by other server adapters, we can make a common public interface in WTP.
Closing bug.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122924" />
    <CreationDate amount="2006-01-06 11:15:00 -0500" />
    <DupId amount="" />
    <classification amount="DataTools" />
    <Product amount="Data Tools" />
    <component amount="SQLDevTools" />
    <Version amount="unspecified" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Update build.properties, manifests, about.html for M3_I010606</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Perform minor updates for Jan 6, 2006 iteration build
Updates complete; iteration posted
Verified complete.</WithStack>
    <WithOutStack>Perform minor updates for Jan 6, 2006 iteration build
Updates complete; iteration posted
Verified complete.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122925" />
    <CreationDate amount="2006-01-06 11:15:00 -0500" />
    <DupId amount="96339" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="SWT" />
    <Version amount="3.1.1" />
    <rep_platform amount="Macintosh" />
    <op_sys amount="Mac OS X - Carbon (unsup.)" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Remapping "Next Editor" then using new mapping crashes Eclipse</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="DUPLICATE" />
    <WithStack>Hi,

I remapped the "Next Editor" key shortcut to ^Tab (Control+Tab) and now when I hold Control and press Tab more than once, Eclipse crashes.  If I don't remap "Next Editor" and hold Apple and press F6 more than once, Eclipse does *not* crash.
- are there related entries in the .log file?
  the log file is &lt;workspace location&gt;/.metadata/.log

- please attachd the VM dump
  normally the dumps can be found in the Eclipse install location
Please reopen after attaching requested information.
Sorry for the delay.

.log says nothing and I cannot find the VM dump file.  Could you tell me where in the Eclipse install directory I should be able to find the VM dump?
By the way, if I map "Next Editor" to something else (I tried Control+`) and I hold Control and cycle through editor windows, Eclipse does not crash.
I could not reproduce this problem with Eclipse 3.2M4, that is mapping "Next Editor" to Control-Tab works fine.

With Eclipse 3.1.1 I got the attached crash dump.
Created attachment 32682
Java dump from crash in native
Created attachment 32683
Native crash dump


*** This bug has been marked as a duplicate of 96339 ***
Changing OS from Mac OS to Mac OS X as per bug 185991</WithStack>
    <WithOutStack>Hi,

I remapped the "Next Editor" key shortcut to ^Tab (Control+Tab) and now when I hold Control and press Tab more than once, Eclipse crashes.  If I don't remap "Next Editor" and hold Apple and press F6 more than once, Eclipse does *not* crash.
- are there related entries in the .log file?
  the log file is &lt;workspace location&gt;/.metadata/.log

- please attachd the VM dump
  normally the dumps can be found in the Eclipse install location
Please reopen after attaching requested information.
Sorry for the delay.

.log says nothing and I cannot find the VM dump file.  Could you tell me where in the Eclipse install directory I should be able to find the VM dump?
By the way, if I map "Next Editor" to something else (I tried Control+`) and I hold Control and cycle through editor windows, Eclipse does not crash.
I could not reproduce this problem with Eclipse 3.2M4, that is mapping "Next Editor" to Control-Tab works fine.

With Eclipse 3.1.1 I got the attached crash dump.
Created attachment 32682
Java dump from crash in native
Created attachment 32683
Native crash dump


*** This bug has been marked as a duplicate of 96339 ***
Changing OS from Mac OS to Mac OS X as per bug 185991</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122926" />
    <CreationDate amount="2006-01-06 11:17:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="SWT" />
    <Version amount="3.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Text cannot be disabled/enabled properly</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="WORKSFORME" />
    <WithStack>If the Text widget is set to disable initially, visually it is set to invisible. Now if it is enabled, the widget will not be displayed. Only when the widget is repainted (switch to another application that covers it and then switch back), it will show the correct state.
Same happens when disabling the Text widget.
I will need more to go on than this.
Please reopen this bug report with a stand alone snippet or a set of steps that shows the problem.  Thanks.
Not an eclipse problem.</WithStack>
    <WithOutStack>If the Text widget is set to disable initially, visually it is set to invisible. Now if it is enabled, the widget will not be displayed. Only when the widget is repainted (switch to another application that covers it and then switch back), it will show the correct state.
Same happens when disabling the Text widget.
I will need more to go on than this.
Please reopen this bug report with a stand alone snippet or a set of steps that shows the problem.  Thanks.
Not an eclipse problem.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122927" />
    <CreationDate amount="2006-01-06 11:21:00 -0500" />
    <DupId amount="151529" />
    <classification amount="Mylyn" />
    <Product amount="Mylyn" />
    <component amount="UI" />
    <Version amount="0.4" />
    <rep_platform amount="Macintosh" />
    <op_sys amount="Mac OS X - Carbon (unsup.)" />
    <priority amount="P4" />
    <bug_severity amount="normal" />
    <Summery>[mac] Mylar Editor: missing rectangle around Documentation text</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="DUPLICATE" />
    <WithStack>On Mac OS X, there is no rectangle around the text field. 
It's Mylar 0.4.6.1 in Eclipse 3.2M4
See attachment
Created attachment 32590
Picture not showing the rectangle
Thanks Gerd.  It might have to do with Font sizes.  I will have to find a Mac for us to test on...
I didn't notice it myself, but it seems to be a more general problem (deeper in the platform)
Thanks for noting this Gerd.  Since this is a duplicate of bug 151529 I'll mark it as such.

*** This bug has been marked as a duplicate of 151529 ***</WithStack>
    <WithOutStack>On Mac OS X, there is no rectangle around the text field. 
It's Mylar 0.4.6.1 in Eclipse 3.2M4
See attachment
Created attachment 32590
Picture not showing the rectangle
Thanks Gerd.  It might have to do with Font sizes.  I will have to find a Mac for us to test on...
I didn't notice it myself, but it seems to be a more general problem (deeper in the platform)
Thanks for noting this Gerd.  Since this is a duplicate of bug 151529 I'll mark it as such.

*** This bug has been marked as a duplicate of 151529 ***</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122928" />
    <CreationDate amount="2006-01-06 11:24:00 -0500" />
    <DupId amount="" />
    <classification amount="Mylyn" />
    <Product amount="Mylyn" />
    <component amount="UI" />
    <Version amount="0.4" />
    <rep_platform amount="Macintosh" />
    <op_sys amount="Mac OS X - Carbon (unsup.)" />
    <priority amount="P4" />
    <bug_severity amount="normal" />
    <Summery>[mac] task editor triangle looks ugly when it has focus</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="1">
      <source_code type="functioncall">
        <location start="255" end="367" />
        <code>The issue here is that SWT is not rendering the native MacOS widget for: new Button(this, SWT.ARROW | SWT.DOWN);</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>This is Mylar 0.4.6.1 in Eclipse 3.2M4
see attachment
Created attachment 32592
Picture showing triangle when it has focus
We've made considerably improvements for 0.4.8 (but unfortuantely still don't have a Mac test box).  Let me know if it looks better.
The issue here is that SWT is not rendering the native MacOS widget for: new Button(this, SWT.ARROW | SWT.DOWN);
I checked again wth Eclipse 3.3 and Mylyn 2.0.0.

The bug ist fixed in the way that I can't select the triangle any more. This is a good thing on the Mac.

Environment:
Mac OS X 10.4.10 Build 8R218

java version "1.5.0_07"
Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_07-164)
Java HotSpot(TM) Client VM (build 1.5.0_07-87, mixed mode, sharing)

Reopening to mark as resolved as per message from webmaster: http://dev.eclipse.org/mhonarc/lists/eclipse.org-committers/msg00778.html.
Marking resolved.</WithStack>
    <WithOutStack>This is Mylar 0.4.6.1 in Eclipse 3.2M4
see attachment
Created attachment 32592
Picture showing triangle when it has focus
We've made considerably improvements for 0.4.8 (but unfortuantely still don't have a Mac test box).  Let me know if it looks better.
The issue here is that SWT is not rendering the native MacOS widget for: new Button(this, SWT.ARROW | SWT.DOWN);
I checked again wth Eclipse 3.3 and Mylyn 2.0.0.

The bug ist fixed in the way that I can't select the triangle any more. This is a good thing on the Mac.

Environment:
Mac OS X 10.4.10 Build 8R218

java version "1.5.0_07"
Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_07-164)
Java HotSpot(TM) Client VM (build 1.5.0_07-87, mixed mode, sharing)

Reopening to mark as resolved as per message from webmaster: http://dev.eclipse.org/mhonarc/lists/eclipse.org-committers/msg00778.html.
Marking resolved.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122929" />
    <CreationDate amount="2006-01-06 11:26:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="Core" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Performance issue when setting breakpoint in interface method.</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="WORKSFORME" />
    <WithStack>Version: 3.2.0
Build id: I20060105-0800

Set a breakpoint in ICompletionProposal#apply(IDocument) and debug eclipse. Eclipse is very slow while the breakpoint is enabled.
We don't support breakpoints in interfaces (or abstract methods). The action is allowing a breakpoint to be created as interface methods in source are not being reported as abstract. We attempt to install a method breakpoint in this case which slows down the VM (a know problem/limitation of methods breakpoints which turns on tracing in the target VM).

I think that interface methods should be reported as abstract by JCORE, even when not explicit in source. Moving to JCORE for comment.
Darin,

In "I think that interface methods should be reported as abstract by JCORE, even
when not explicit in source. Moving to JCORE for comment.", are you talking about methods from source or class files ?
Closing as REMIND.
Darin,
Please let me know what you meant in your last comment.
This is working now. Closing.
Reopen to close as INVALID.
Closing as WORKSFORME as this is not an issue anymore.</WithStack>
    <WithOutStack>Version: 3.2.0
Build id: I20060105-0800

Set a breakpoint in ICompletionProposal#apply(IDocument) and debug eclipse. Eclipse is very slow while the breakpoint is enabled.
We don't support breakpoints in interfaces (or abstract methods). The action is allowing a breakpoint to be created as interface methods in source are not being reported as abstract. We attempt to install a method breakpoint in this case which slows down the VM (a know problem/limitation of methods breakpoints which turns on tracing in the target VM).

I think that interface methods should be reported as abstract by JCORE, even when not explicit in source. Moving to JCORE for comment.
Darin,

In "I think that interface methods should be reported as abstract by JCORE, even
when not explicit in source. Moving to JCORE for comment.", are you talking about methods from source or class files ?
Closing as REMIND.
Darin,
Please let me know what you meant in your last comment.
This is working now. Closing.
Reopen to close as INVALID.
Closing as WORKSFORME as this is not an issue anymore.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122930" />
    <CreationDate amount="2006-01-06 11:28:00 -0500" />
    <DupId amount="108191" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="Update  (deprecated - use RT&gt;Equinox&gt;p2)" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Linux" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Error when downloading features/plugins to a read-only instance of Eclipse</Summery>
    <Patches amount="0" />
    <Stacktraces amount="1">
      <Stacktrace timestamp="1437330631554">
        <Exception>java.lang.ClassCastException</Exception>
        <Reason />
        <Frames>
          <Frame depth="0">org.eclipse.update.internal.core.SiteFileContentConsumer.abort(SiteFileContentConsumer.java:209)</Frame>
          <Frame depth="1">org.eclipse.update.internal.core.FeatureExecutableContentConsumer.abort(FeatureExecutableContentConsumer.java:160)</Frame>
          <Frame depth="2">org.eclipse.update.core.Feature.install(Feature.java:538)</Frame>
          <Frame depth="3">org.eclipse.update.internal.core.SiteFile.install(SiteFile.java:74)</Frame>
          <Frame depth="4">org.eclipse.update.internal.core.ConfiguredSite.install(ConfiguredSite.java:122)</Frame>
          <Frame depth="5">org.eclipse.update.internal.core.ConfiguredSite.install(ConfiguredSite.java:86)</Frame>
          <Frame depth="6">org.eclipse.update.internal.operations.InstallOperation.execute(InstallOperation.java:72)</Frame>
          <Frame depth="7">org.eclipse.update.internal.operations.BatchInstallOperation.execute(BatchInstallOperation.java:84)</Frame>
          <Frame depth="8">org.eclipse.update.internal.ui.wizards.InstallWizard2.install(InstallWizard2.java:373)</Frame>
          <Frame depth="9">org.eclipse.update.internal.ui.wizards.InstallWizard2.access$1(InstallWizard2.java:370)</Frame>
          <Frame depth="10">org.eclipse.update.internal.ui.wizards.InstallWizard2$1.run(InstallWizard2.java:464)</Frame>
          <Frame depth="11">org.eclipse.core.internal.jobs.Worker.run(Worker.java:58)</Frame>
        </Frames>
      </Stacktrace>
    </Stacktraces>
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="8">
        <Lines>
          <Line>- connect an launch Eclipse under my usual user id;</Line>
          <Line>- select an update site and a feature that is new for the considered instance</Line>
          <Line>of Eclipse;</Line>
          <Line>- accept the terms of the license agreement;</Line>
          <Line>- do not change the Install Location, click Finish;</Line>
          <Line>- once the download is complete and presented with the feature verification (here</Line>
          <Line>I am using an unsigned feature), click Install;</Line>
          <Line>- get an error:</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="RESOLVED" />
    <resolution amount="DUPLICATE" />
    <WithStack>Using build I20051215-1506 under Linux.
Having installed Eclipse into /opt/eclipse_32_M4/eclipse, under root, without
granting write access to it to my usual user id.
The following steps lead to an error (stack trace below):
- connect an launch Eclipse under my usual user id;
- select an update site and a feature that is new for the considered instance
  of Eclipse;
- accept the terms of the license agreement;
- do not change the Install Location, click Finish;
- once the download is complete and presented with the feature verification (here
  I am using an unsigned feature), click Install;
- get an error:

Error 2006-01-06 17:26:26.920 An internal error occurred during: "Update Manager".
java.lang.ClassCastException
at org.eclipse.update.internal.core.SiteFileContentConsumer.abort(SiteFileContentConsumer.java:209)
at org.eclipse.update.internal.core.FeatureExecutableContentConsumer.abort(FeatureExecutableContentConsumer.java:160)
at org.eclipse.update.core.Feature.install(Feature.java:538)
at org.eclipse.update.internal.core.SiteFile.install(SiteFile.java:74)
at org.eclipse.update.internal.core.ConfiguredSite.install(ConfiguredSite.java:122)
at org.eclipse.update.internal.core.ConfiguredSite.install(ConfiguredSite.java:86)
at org.eclipse.update.internal.operations.InstallOperation.execute(InstallOperation.java:72)
at org.eclipse.update.internal.operations.BatchInstallOperation.execute(BatchInstallOperation.java:84)
at org.eclipse.update.internal.ui.wizards.InstallWizard2.install(InstallWizard2.java:373)
at org.eclipse.update.internal.ui.wizards.InstallWizard2.access$1(InstallWizard2.java:370)
at org.eclipse.update.internal.ui.wizards.InstallWizard2$1.run(InstallWizard2.java:464)
at org.eclipse.core.internal.jobs.Worker.run(Worker.java:58)

Adding write access to the directory solves the problem.

Note also that along the Change Install Location path, things are quite
better because Eclipse detects that the installation location is read only, 
and provides a neat message to tell the user so.
From the stacktrace, this looks to me the same problem as in https://bugs.eclipse.org/bugs/show_bug.cgi?id=108191
(In reply to comment #1)
&gt; From the stacktrace, this looks to me the same problem as in
&gt; https://bugs.eclipse.org/bugs/show_bug.cgi?id=108191

Agree. Should have searched more thoroughly.


*** This bug has been marked as a duplicate of 108191 ***</WithStack>
    <WithOutStack>Using build I20051215-1506 under Linux.
Having installed Eclipse into /opt/eclipse_32_M4/eclipse, under root, without
granting write access to it to my usual user id.
The following steps lead to an error (stack trace below):
- connect an launch Eclipse under my usual user id;
- select an update site and a feature that is new for the considered instance
  of Eclipse;
- accept the terms of the license agreement;
- do not change the Install Location, click Finish;
- once the download is complete and presented with the feature verification (here
  I am using an unsigned feature), click Install;
- get an error:

Error 2006-01-06 17:26:26.920 An internal error occurred during: "Update Manager".


Adding write access to the directory solves the problem.

Note also that along the Change Install Location path, things are quite
better because Eclipse detects that the installation location is read only, 
and provides a neat message to tell the user so.
From the stacktrace, this looks to me the same problem as in https://bugs.eclipse.org/bugs/show_bug.cgi?id=108191
(In reply to comment #1)
&gt; From the stacktrace, this looks to me the same problem as in
&gt; https://bugs.eclipse.org/bugs/show_bug.cgi?id=108191

Agree. Should have searched more thoroughly.


*** This bug has been marked as a duplicate of 108191 ***</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122931" />
    <CreationDate amount="2006-01-06 11:32:00 -0500" />
    <DupId amount="" />
    <classification amount="Mylyn" />
    <Product amount="Mylyn" />
    <component amount="UI" />
    <Version amount="0.4" />
    <rep_platform amount="Macintosh" />
    <op_sys amount="Mac OS X - Carbon (unsup.)" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Mylar Tasks view: Dropdown starts with selected priority on Mac OS X</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>If a task in the Mylar Tasks view has priority P3 and I edit it, the drop down box starts with P3 on Macs and with P1 on Windows.
Mylar 0.4.6.1 is necessary to see this.
Eclipse 3.2M4
See attachment
Created attachment 32596
Drop down starting with selected priority
Created attachment 32597
After adjustment
This will probably be resolved in 0.5.0 since we've moved to a new widged for icon-based priorities, but will still need to be verified on Mac OS.
This is also an issue with Eclipse drop down menus (same thing happens in Eclipse Tasks view).  Marking for later.
I checked again wit Eclipse 3.3, Mylyn 2.0.0:

This bug is irrelevant now, since there isn't a drop down box in the task view any more.

There is a drop down box in the task editor which works as expected without the bug described here. So the deeper problem is fixed.

Environment:
Mac OS X 10.4.10

java version "1.5.0_07"
Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_07-164)
Java HotSpot(TM) Client VM (build 1.5.0_07-87, mixed mode, sharing)

Thanks for the pointer Gerd.
Resolved as per comment#5.</WithStack>
    <WithOutStack>If a task in the Mylar Tasks view has priority P3 and I edit it, the drop down box starts with P3 on Macs and with P1 on Windows.
Mylar 0.4.6.1 is necessary to see this.
Eclipse 3.2M4
See attachment
Created attachment 32596
Drop down starting with selected priority
Created attachment 32597
After adjustment
This will probably be resolved in 0.5.0 since we've moved to a new widged for icon-based priorities, but will still need to be verified on Mac OS.
This is also an issue with Eclipse drop down menus (same thing happens in Eclipse Tasks view).  Marking for later.
I checked again wit Eclipse 3.3, Mylyn 2.0.0:

This bug is irrelevant now, since there isn't a drop down box in the task view any more.

There is a drop down box in the task editor which works as expected without the bug described here. So the deeper problem is fixed.

Environment:
Mac OS X 10.4.10

java version "1.5.0_07"
Java(TM) 2 Runtime Environment, Standard Edition (build 1.5.0_07-164)
Java HotSpot(TM) Client VM (build 1.5.0_07-87, mixed mode, sharing)

Thanks for the pointer Gerd.
Resolved as per comment#5.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122932" />
    <CreationDate amount="2006-01-06 11:40:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse Foundation" />
    <Product amount="z_Archived" />
    <component amount="TPTP.monitoring" />
    <Version amount="unspecified" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>New statistical launch configurations inherit previous agent settings</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>When creating a new Statistical Launch configuration, the initialization values of the Agent specific variables in the Launch Configuration automatically inherit the values of the previous Launch Configuration.

For instance, a second configuration of a Windows System Agent will inherit variable values such as Remote Hostname, Username and Password from the first configuration. This is incorrect, as a new configuration should intialize to the default values only.
Fix checked into 4.2 HEAD.
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithStack>
    <WithOutStack>When creating a new Statistical Launch configuration, the initialization values of the Agent specific variables in the Launch Configuration automatically inherit the values of the previous Launch Configuration.

For instance, a second configuration of a Windows System Agent will inherit variable values such as Remote Hostname, Username and Password from the first configuration. This is incorrect, as a new configuration should intialize to the default values only.
Fix checked into 4.2 HEAD.
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122933" />
    <CreationDate amount="2006-01-06 11:40:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="User Assistance" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="enhancement" />
    <Summery>[Browser] Open Browser Components for subclassing</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="WONTFIX" />
    <WithStack>We have a need to subclass some of these components to add some more love to them.   We can reuse a lot of the code found within these, instead of copying the code.

Specifically,
http://dev.eclipse.org/viewcvs/index.cgi/org.eclipse.ui.browser/META-INF/MANIFEST.MF?rev=1.5&amp;content-type=text/vnd.viewcvs-markup
These classes shouldn't be masked from us by being internal.

If this could get in before M5, I'll love you :)
Promoting internal code into API is a decision that cannot be taken lightly. Once we introduce APIs, they typically stay forever (even when deprecated) so we must have a strong use case. Which classes in particular do you see as candidates for APIs?

Note that embedded browser can fail on some plaforms - you should not count on browser editor or browser view to be universally supported. 
Ok, maybe the word subclass was too strong. Basically what is needed is a way to add/remove listeners to the browser viewer/editor as well as perhaps buttons to the toolbar. The basic premise is that we would like not to reproduce the entirety of what has already been developed for the browser viewer/editor, but merely augment it's functionality a bit.

Does that make sense :)?
Punting to UA for consideration.
Chris, is there still a demand for this? I would be hesitant to expose this code.
I'm also not in favor of opening these components up for subclassing. If there are specific extensions you need then a separate bug can be opened but I'm going to close this one out since we are not planning on supporting subclassing.</WithStack>
    <WithOutStack>We have a need to subclass some of these components to add some more love to them.   We can reuse a lot of the code found within these, instead of copying the code.

Specifically,
http://dev.eclipse.org/viewcvs/index.cgi/org.eclipse.ui.browser/META-INF/MANIFEST.MF?rev=1.5&amp;content-type=text/vnd.viewcvs-markup
These classes shouldn't be masked from us by being internal.

If this could get in before M5, I'll love you :)
Promoting internal code into API is a decision that cannot be taken lightly. Once we introduce APIs, they typically stay forever (even when deprecated) so we must have a strong use case. Which classes in particular do you see as candidates for APIs?

Note that embedded browser can fail on some plaforms - you should not count on browser editor or browser view to be universally supported. 
Ok, maybe the word subclass was too strong. Basically what is needed is a way to add/remove listeners to the browser viewer/editor as well as perhaps buttons to the toolbar. The basic premise is that we would like not to reproduce the entirety of what has already been developed for the browser viewer/editor, but merely augment it's functionality a bit.

Does that make sense :)?
Punting to UA for consideration.
Chris, is there still a demand for this? I would be hesitant to expose this code.
I'm also not in favor of opening these components up for subclassing. If there are specific extensions you need then a separate bug can be opened but I'm going to close this one out since we are not planning on supporting subclassing.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122934" />
    <CreationDate amount="2006-01-06 11:54:00 -0500" />
    <DupId amount="" />
    <classification amount="WebTools" />
    <Product amount="WTP Java EE Tools" />
    <component amount="jst.j2ee" />
    <Version amount="1.0.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="critical" />
    <Summery>Deadlock in ModuleStructuralModel</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>The synchronized block is creating a deadlock situation
Dropped to build
Ok</WithStack>
    <WithOutStack>The synchronized block is creating a deadlock situation
Dropped to build
Ok</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122935" />
    <CreationDate amount="2006-01-06 11:55:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="Runtime" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>IProgressMonitor has moved and there don't appear to be dependencies</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="VERIFIED" />
    <resolution amount="INVALID" />
    <WithStack>There's a few reports of people running in Eclipse 3.2M4 that have plugins that depend on org.eclipse.core.resources and use IProgressMonitor, and get ClassNotFound errors when running because it's been refactored into org.eclipse.equinox.common.

It would be good if org.eclipse.core.resources re-exported the dependency on org.eclipse.equinox.common so that it's not necessary for people to update their plugin dependencies.

If this has already happened, then perhaps this ought to be redirected to PDE/Export, since running the plugin in 3.2M4 appears to fail.

http://www.eclipsezone.com/forums/click.jspa?searchID=55366&amp;messageID=91977643
http://www.eclipsezone.com/forums/click.jspa?searchID=55369&amp;messageID=91979620
The resources plugin never re-exported org.eclipse.core.runtime before (where IProgressMonitor previously lived), so it shouldn't be necessary to start now.  Plugins that used IProgressMonitor prior to 3.2 M4 must already have a dependency on org.eclipse.core.runtime, which does re-export its dependency on org.eclipse.equinox.common.  These plugins will continue to run fine in 3.2 M4.

In the forum question, the user is creating a standalone java application... there is nothing we can do to the plugin dependency lists that would help in this case, since plugin dependencies aren't consulting in a stand-alone application.
Sorry, I meant org.eclipse.core.runtime, not resources.
org.eclipse.core.runtime does re-export org.eclipse.equinox.common in 3.2 M4.  Ok to close?
Yeah, mark it as invalid then.
Ok.  We're aware of the pain that the runtime refactoring has caused for standalone applications, but on the other hand they benefit from the size reduction. Standalone SWT/JFace applications no longer need the big runtime jar file on their classpath (Equinox common is under 70KB).  I'm sure there will be an entry in the porting guide before 3.2 goes out with some help for users of the API to adapt. 
Plus, whenever anyone else raises this bug, they'll see that it is only a problem for non-Platform apps :-)</WithStack>
    <WithOutStack>There's a few reports of people running in Eclipse 3.2M4 that have plugins that depend on org.eclipse.core.resources and use IProgressMonitor, and get ClassNotFound errors when running because it's been refactored into org.eclipse.equinox.common.

It would be good if org.eclipse.core.resources re-exported the dependency on org.eclipse.equinox.common so that it's not necessary for people to update their plugin dependencies.

If this has already happened, then perhaps this ought to be redirected to PDE/Export, since running the plugin in 3.2M4 appears to fail.

http://www.eclipsezone.com/forums/click.jspa?searchID=55366&amp;messageID=91977643
http://www.eclipsezone.com/forums/click.jspa?searchID=55369&amp;messageID=91979620
The resources plugin never re-exported org.eclipse.core.runtime before (where IProgressMonitor previously lived), so it shouldn't be necessary to start now.  Plugins that used IProgressMonitor prior to 3.2 M4 must already have a dependency on org.eclipse.core.runtime, which does re-export its dependency on org.eclipse.equinox.common.  These plugins will continue to run fine in 3.2 M4.

In the forum question, the user is creating a standalone java application... there is nothing we can do to the plugin dependency lists that would help in this case, since plugin dependencies aren't consulting in a stand-alone application.
Sorry, I meant org.eclipse.core.runtime, not resources.
org.eclipse.core.runtime does re-export org.eclipse.equinox.common in 3.2 M4.  Ok to close?
Yeah, mark it as invalid then.
Ok.  We're aware of the pain that the runtime refactoring has caused for standalone applications, but on the other hand they benefit from the size reduction. Standalone SWT/JFace applications no longer need the big runtime jar file on their classpath (Equinox common is under 70KB).  I'm sure there will be an entry in the porting guide before 3.2 goes out with some help for users of the API to adapt. 
Plus, whenever anyone else raises this bug, they'll see that it is only a problem for non-Platform apps :-)</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122936" />
    <CreationDate amount="2006-01-06 12:15:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="Resources" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>IResource isLocal and setLocal should be deprecated</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>Build: I20050103

There is a skeleton of support in the IResource API for the notion of "non-local" resources.  A non-local resource is one with no contents in the local file system. I.e., it exists in the resource tree but not on disk.  In practice this is just a flag on the resource info, and setLocal just flips that flag.  There is no mechanism for fetching contents of non-local resources into the local file system.

To give some history, in the initial technology preview of Eclipse (prior to open sourcing), IResource was much more tightly coupled to a corresponding entity in a code repository.  The idea was that the resource tree structure could be fetched from the repository without contents for quick browsing, and the individual file contents could be lazily fetched from the repository as needed.  This approach was abanded prior to the 1.0 release, but some vestiges remain in the API.

In Eclipse 3.2 it is possible to create resources that are stored diretly in other file systems.  This will likely confuse API clients who notice the old "local" and "non-local" terminology.  All of this old API should be deprecated to make it clear that these concepts are not part of the new flexible workspace API.  A partial list:

IResource.setLocal
IResource.isLocal
IFolder.create(boolean, boolean, IProgressMonitor)

Existing behaviour must continue to be supported for API compatibility, but should be deprecated to discourage future use.
Done.</WithStack>
    <WithOutStack>Build: I20050103

There is a skeleton of support in the IResource API for the notion of "non-local" resources.  A non-local resource is one with no contents in the local file system. I.e., it exists in the resource tree but not on disk.  In practice this is just a flag on the resource info, and setLocal just flips that flag.  There is no mechanism for fetching contents of non-local resources into the local file system.

To give some history, in the initial technology preview of Eclipse (prior to open sourcing), IResource was much more tightly coupled to a corresponding entity in a code repository.  The idea was that the resource tree structure could be fetched from the repository without contents for quick browsing, and the individual file contents could be lazily fetched from the repository as needed.  This approach was abanded prior to the 1.0 release, but some vestiges remain in the API.

In Eclipse 3.2 it is possible to create resources that are stored diretly in other file systems.  This will likely confuse API clients who notice the old "local" and "non-local" terminology.  All of this old API should be deprecated to make it clear that these concepts are not part of the new flexible workspace API.  A partial list:

IResource.setLocal
IResource.isLocal
IFolder.create(boolean, boolean, IProgressMonitor)

Existing behaviour must continue to be supported for API compatibility, but should be deprecated to discourage future use.
Done.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122937" />
    <CreationDate amount="2006-01-06 12:26:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="UI" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>[WorkingSets] WindowWorkingSet is breaks existing code for working sets</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="2">
        <Lines>
          <Line>- Storing and restoring working set references by name is not working anymore. Window working sets need special treatment as their name is not a key.</Line>
          <Line>- A empty window working set has to be considered to contain everything.</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="NEW" />
    <resolution amount="" />
    <WithStack>20060106

I started upding the search pages (File/Java-search) to work with the new window working set. The search dialogs allow to specify a working set as scope. As the default working set selection dialog is used, users clan now also choose the window working set as scope.

The existing code in file and Java search had to be updated:
- Storing and restoring working set references by name is not working anymore. Window working sets need special treatment as their name is not a key.
- A empty window working set has to be considered to contain everything.

Especially the second issue makes existing, unchanged code look buggy.
Maybe a fix would be to let it return the IWorkspaceRoot? Or dynamically return all IProject's in the workspace?

As the working set selection dialog has now been changed for everybody, also old, unchanged clients suddenly get in contact with the window-working set.
I think it would be less breaking if the working set selection dialog stays unchanged but is marked as deprecated so that clients are forced to update and implement the special treatment of window working set.
Will try and formulate a response ASAP.  
I'm not going to have time to address this for 3.2.</WithStack>
    <WithOutStack>20060106

I started upding the search pages (File/Java-search) to work with the new window working set. The search dialogs allow to specify a working set as scope. As the default working set selection dialog is used, users clan now also choose the window working set as scope.

The existing code in file and Java search had to be updated:
- Storing and restoring working set references by name is not working anymore. Window working sets need special treatment as their name is not a key.
- A empty window working set has to be considered to contain everything.

Especially the second issue makes existing, unchanged code look buggy.
Maybe a fix would be to let it return the IWorkspaceRoot? Or dynamically return all IProject's in the workspace?

As the working set selection dialog has now been changed for everybody, also old, unchanged clients suddenly get in contact with the window-working set.
I think it would be less breaking if the working set selection dialog stays unchanged but is marked as deprecated so that clients are forced to update and implement the special treatment of window working set.
Will try and formulate a response ASAP.  
I'm not going to have time to address this for 3.2.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122938" />
    <CreationDate amount="2006-01-06 12:49:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="PDE" />
    <component amount="UI" />
    <Version amount="3.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>documentCreation extension point has been deprecated</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="4">
        <Lines>
          <Line>1. copy the document provider creation from</Line>
          <Line>PDEPlugin.getTextFileDocumentProvider() to where this method is called</Line>
          <Line>2. reject all changes in PDEPlugin</Line>
          <Line>patch released and plays well.  thanks.</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>Platform Text form HEAD.

Platform Text has deprecated the org.eclipse.core.filebuffers.documentCreation
extension point. See its doc for details.
Created attachment 32607
Fix to remove deprecation

This patch also introduces a shared text file document provider. I did some testing and it seems to work fine. If you do not like this you can simply remove that part from the patch by
1. copy the document provider creation from
   PDEPlugin.getTextFileDocumentProvider() to where this method is called
2. reject all changes in PDEPlugin
patch released and plays well.  thanks.</WithStack>
    <WithOutStack>Platform Text form HEAD.

Platform Text has deprecated the org.eclipse.core.filebuffers.documentCreation
extension point. See its doc for details.
Created attachment 32607
Fix to remove deprecation

This patch also introduces a shared text file document provider. I did some testing and it seems to work fine. If you do not like this you can simply remove that part from the patch by
1. copy the document provider creation from
   PDEPlugin.getTextFileDocumentProvider() to where this method is called
2. reject all changes in PDEPlugin
patch released and plays well.  thanks.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122939" />
    <CreationDate amount="2006-01-06 13:05:00 -0500" />
    <DupId amount="" />
    <classification amount="Tools" />
    <Product amount="TPTP Common Logging" />
    <component amount="Platform.Agents.Logging" />
    <Version amount="4.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P1" />
    <bug_severity amount="normal" />
    <Summery>Port logging agent to Itanium/Windows</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Needed to complete the TPTP solution on that platform.
This is done as part of Randy's IPF build
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithStack>
    <WithOutStack>Needed to complete the TPTP solution on that platform.
This is done as part of Randy's IPF build
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122940" />
    <CreationDate amount="2006-01-06 13:11:00 -0500" />
    <DupId amount="" />
    <classification amount="Tools" />
    <Product amount="TPTP Common Logging" />
    <component amount="Platform.Agents.Logging" />
    <Version amount="4.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Linux" />
    <priority amount="P1" />
    <bug_severity amount="normal" />
    <Summery>Port logging agent to Itanium/Linux</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Needed to complete the TPTP solution on that platform.
Deferred from 4.2 plan as per PMC approval on March 29th.
Reassigning to Karla
Work was already done.  Just a test effort remains
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithStack>
    <WithOutStack>Needed to complete the TPTP solution on that platform.
Deferred from 4.2 plan as per PMC approval on March 29th.
Reassigning to Karla
Work was already done.  Just a test effort remains
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122941" />
    <CreationDate amount="2006-01-06 13:36:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Report Designer" />
    <Version amount="2.0.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="major" />
    <Summery>Group interval range resets to 1</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="11">
        <Lines>
          <Line>1. Create a group based on orders.orderNumber.</Line>
          <Line>2. Specify an interval range of 100.</Line>
          <Line>3. Do not check "Use fixed base value for interval"</Line>
          <Line>4. Preview the report.</Line>
          <Line>Report groups on every order number.</Line>
          <Line>5. Open the group editor.</Line>
          <Line>The interval range is set to 1.</Line>
          <Line>The interval can be saved correctly now.</Line>
          <Line>*** Bug 123062 has been marked as a duplicate of this bug. ***</Line>
          <Line>*** Bug 123062 has been marked as a duplicate of this bug. ***</Line>
          <Line>Verified in build 20060110.</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>1. Create a group based on orders.orderNumber.
2. Specify an interval range of 100.
3. Do not check "Use fixed base value for interval"
4. Preview the report.
Report groups on every order number.
5. Open the group editor.
The interval range is set to 1.
The interval can be saved correctly now.
*** Bug 123062 has been marked as a duplicate of this bug. ***
*** Bug 123062 has been marked as a duplicate of this bug. ***
Verified in build 20060110.</WithStack>
    <WithOutStack>1. Create a group based on orders.orderNumber.
2. Specify an interval range of 100.
3. Do not check "Use fixed base value for interval"
4. Preview the report.
Report groups on every order number.
5. Open the group editor.
The interval range is set to 1.
The interval can be saved correctly now.
*** Bug 123062 has been marked as a duplicate of this bug. ***
*** Bug 123062 has been marked as a duplicate of this bug. ***
Verified in build 20060110.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122942" />
    <CreationDate amount="2006-01-06 13:38:00 -0500" />
    <DupId amount="" />
    <classification amount="Tools" />
    <Product amount="TPTP Common Logging" />
    <component amount="Platform.Agents.Logging" />
    <Version amount="4.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P1" />
    <bug_severity amount="normal" />
    <Summery>Port logging agent to EM64T/Windows</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Needed to complete the TPTP solution on that platform.
This is done as part of Randy's EM64T build.
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithStack>
    <WithOutStack>Needed to complete the TPTP solution on that platform.
This is done as part of Randy's EM64T build.
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122943" />
    <CreationDate amount="2006-01-06 13:39:00 -0500" />
    <DupId amount="" />
    <classification amount="Tools" />
    <Product amount="TPTP Common Logging" />
    <component amount="Platform.Agents.Logging" />
    <Version amount="4.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Linux" />
    <priority amount="P1" />
    <bug_severity amount="normal" />
    <Summery>Port logging agent to EM64T/Linux</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Needed to complete the TPTP solution on that platform.
Deferred from 4.2 plan as per PMC approval on March 29th.
Reassigning to Karla
Work was already completed.  Just a test effort remains
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithStack>
    <WithOutStack>Needed to complete the TPTP solution on that platform.
Deferred from 4.2 plan as per PMC approval on March 29th.
Reassigning to Karla
Work was already completed.  Just a test effort remains
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122944" />
    <CreationDate amount="2006-01-06 13:40:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Report Engine" />
    <Version amount="2.0.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="major" />
    <Summery>Group base interval value ignored</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="3">
      <source_code type="singlecomment">
        <location start="700" end="716" />
        <code>// inter-range</code>
      </source_code>
      <source_code type="functioncall">
        <location start="716" end="774" />
        <code>groupDefn.setIntervalRange( handle.getIntervalRange( ) );</code>
      </source_code>
      <source_code type="singlecomment">
        <location start="775" end="826" />
        <code>// inter-start-value-----this code must be added.</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>See attached report.

The group's base value for interval is set to 10200. The report displays order numbers less than 10200. 

Expected result: Report displays orders 10200 and above.
Created attachment 32612
report design
It occurred to me that the interval base value is not designed to filter rows. So I tested with a interval base value of 10000. The first order number is 10100. 

Result: First group value is 10100.
Expected result: First group value is 10000.
This is an engine bug, for the interval base value didn't set in the groupDefinition. The modified code is ReportQueryBuilder.java
protected IGroupDefinition handleGroup( GroupDesign group,
				GroupHandle handle )
{
        ......
	// inter-range
	groupDefn.setIntervalRange( handle.getIntervalRange( ) );
	// inter-start-value-----this code must be added.
	groupDefn.setIntervalStart( handle.getIntervalBase( ) )		
       ......
}
fixed
Verified, 20060116</WithStack>
    <WithOutStack>See attached report.

The group's base value for interval is set to 10200. The report displays order numbers less than 10200. 

Expected result: Report displays orders 10200 and above.
Created attachment 32612
report design
It occurred to me that the interval base value is not designed to filter rows. So I tested with a interval base value of 10000. The first order number is 10100. 

Result: First group value is 10100.
Expected result: First group value is 10000.
This is an engine bug, for the interval base value didn't set in the groupDefinition. The modified code is ReportQueryBuilder.java
protected IGroupDefinition handleGroup( GroupDesign group,
				GroupHandle handle )
{
        ......
	// inter-range
	groupDefn.setIntervalRange( handle.getIntervalRange( ) );
	// inter-start-value-----this code must be added.
	groupDefn.setIntervalStart( handle.getIntervalBase( ) )		
       ......
}
fixed
Verified, 20060116</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122945" />
    <CreationDate amount="2006-01-06 13:45:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="Resources" />
    <Version amount="3.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="enhancement" />
    <Summery>[LinkedResources] support creating links in the workspace</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="3">
      <Enumeration lines="5">
        <Lines>
          <Line>1. We have gui projects where we code views for our own framework (gui elements). To work with them in the visual editor we have change the framework jars in the classpath so that the views can be displayed. So we defined another project named guidesign where we link the source folder of our gui projects and configure the claspath as mentioned above. The problem is that the path is stored as an absolute path. =&gt; All developers are forced to use the same location of the view (e.g. c:\ccstore\myviewforcomponent1.0\...). =&gt; For a following release we have a different view location (e.g. c:\ccstore\myviewforcomponent2.0\...). All design projects have to be changed.</Line>
          <Line>2. We would like to use the clearcase remote client. Having the server process installed on a unix machine the view will have an additional path element named vobs (c:\ccstore\myviewforcomponent1.0\vobs\...). In this scenario it is not possible to work with remote views and local views at the same time in a project.</Line>
          <Line>These are limitations we would not have if the linked resource would be a relative path in the workspace.</Line>
          <Line>*** Bug 29023 has been marked as a duplicate of this bug. ***</Line>
          <Line>Hi, is there a plan to implement this enhancement? We had to make a cumbersome workaround to avoid storing the absolute paths in the .project, so it would be very much appreciated. Thanks.</Line>
        </Lines>
      </Enumeration>
      <Enumeration lines="7">
        <Lines>
          <Line>- create a java project named test1</Line>
          <Line>- create a java project named test2</Line>
          <Line>- open properties dialog of the java project test2</Line>
          <Line>- create a new source folder (java build path - Source - add folder) and</Line>
          <Line>click create new folder - advanced, activate checkbox "link to folder in</Line>
          <Line>file system" and select the source folder of project test1.</Line>
          <Line>- open the .project file of the project test2 and see the absolute path.</Line>
        </Lines>
      </Enumeration>
      <Enumeration lines="6">
        <Lines>
          <Line>- unzip the 2 zip files,</Line>
          <Line>- import the Linked Folder into your workspace,</Line>
          <Line>- create an 'Eclipse Application' Laucher running the application 'org.eclipse.ui.ide.workbench'</Line>
          <Line>- Set the location of the Workspace data of this Launcher to &lt;Full path of the Linked Folder Runtime Environment&gt;</Line>
          <Line>- add to the program arguments of that laucher: -dev &lt;Full path of Linked Folder project&gt;/cls</Line>
          <Line>- Run and try to create a Linked Folder within test2, with 'test/a' as value</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="ASSIGNED" />
    <resolution amount="" />
    <WithStack>When you create a new file/folder you have the option to 'link to a folder in the file system'. It would be very usefull to have a 'link to a resource in the workspace' options.

This would be very usefull when you want to share resources between 2 or more projects like:

ProjectA/FolderA
ProjectB/FolderB (linked to FolderA)

you can have this behaviour now but the physical location of the file is stored in the .project file, so it is useless for a team working with CVS.
(Each user has to manually fix the .project file marking the file as an outgoing change).
(In reply to comment #0)
&gt; When you create a new file/folder you have the option to 'link to a folder in
&gt; the file system'. It would be very usefull to have a 'link to a resource in the
&gt; workspace' options.

This option would be very useful.
At least it would be great, if the path to the linked resource could be stored as a relative path.

This seems equivalent to defining a path variable that points to the workspace location (see Preferences &gt; General &gt; Workspace &gt; Linked Resoruces), and then make all your linked resources relative to that variable (Click the "Variables" button when creating a linked resource).
*** Bug 144643 has been marked as a duplicate of this bug. ***
I would like to comment on #2. I don't think that this is equivalent because the path variable can point to the physical workspace root and not the ligical (resources) workspace root.
Description of the duplicated BUG 144643 may help 
- create a java project named test1                                      
- create a java project named test2                                      
- open properties dialog of the java project test2                       
- create a new source folder (java build path - Source - add folder) and 
click create new folder - advanced, activate checkbox "link to folder in 
file system" and select the source folder of project test1.              
- open the .project file of the project test2 and see the absolute path. 

This causes problem in merging changes from one project to another


The problem with the variable that you need to redefine it when you change
views of clearcase for example.
We would like to define a linked folder in the same way as a classpath
reference to another workspace project can be defined.
Example:
We have two projects in a workspace project_a and project_b.
When creating a linked folder we would like to be able to choose either
browse workspace (for relative path) or the entire hard drive (absolute
path).

*** Bug 72940 has been marked as a duplicate of this bug. ***
Ok, Let's see if I follow this thing correctly:

When one creates a linked folder, through, for example, the 'new folder' action within a 'Navigation' view, it triggers:

- org.eclipse.ui.dialogs.WizardNewFolderMainPage#validateLinkedResource()
which delegates the path validation to its linkedResourceGroup (an CreateLinkedResourceGroup widget dedicated to the specification of a linked file or folder target)

- org.eclipse.ui.internal.ide.dialogs.CreateLinkedResourceGroup#validateLinkLocation()
validates its path through the workspace.
The WORKSPACE! It must have all the informations we need, right ? Like the absolute path of any project, candidate for the root of the linked 'relative path' folder we want to create.

- org.eclipse.core.internal.resources.Workspace#validateLinkLocation()
delegates the validation process to its LocationValidator (which implements the various path, URI, and name validation methods in the workspace API)

- org.eclipse.core.internal.resources.LocationValidator#validateLinkLocation()
tries to resolve the path through its PathVariableManager (which manages a collection of path variables and resolves paths containing a variable reference... and allows only a variable reference to appear as the first segment of a relative path)

- org.eclipse.core.internal.resources.PathVariableManager#resolvePath()
returns the path (like '../arelativepath') as is, since the first segment ('..') is not absolute and does not correspond to any classpath variables.

So, then the LocationValidator finds out that the path returned is not absolute and returns a IResourceStatus.VARIABLE_NOT_DEFINED_WARNING message...

Now, what if the PathVariableManager was able to interpret a ${project_path:another_project} variable like the ones we find in the launcher configurations ?
That means the PathVariableManager would also allow for ${project_path:} variable to be a correct first segment, instantly replacing that variable with the absolute path of the specified project, allowing a relative path to be defined, relative to that absolute project path.
The user would enter ${project_path:another_project}/../arelativepath

If you fear for any side effect, maybe you could implement that new behaviour one level above the PathVariableManager, in the LocationValidator#validateLinkLocation() method.

Any comment ? (Before I start overriding org.eclipse.core.internal.resources.PathVariableManager in my eclipse3.2 / 3.3M1 and see what happens ;) )
The best solution is likely to adopt the full-blown variable support used by the launch configuration dialog. This is defined in the org.eclipse.core.variables plugin.  This would likely also require StringVariableSelectionDialog to be pushed down from org.eclipse.debug.ui into org.eclipse.ui.ide. The implementation in org.eclipse.core.resources would then consult IStringVariableManager in org.eclipse.core.variables rather than the existing PathVariableManager. Of course, for backwards compability those variables would still need to be supported.
Is there a way to include that evolution (described in comment #8) within the proposed items of http://www.eclipse.org/eclipse/development/eclipse_project_plan_3_3.html ?

For example, could you consider that it is one of the evolutions necessary to solve bug #154097 ? ("Managing and sharing settings")

It really comes down to solve the current impossibility to **share** an eclipse project without having to redefine something (here: 'Linked path variables') in order to make that shared project work...
Created attachment 48706
Linked Folder Patch Project

Plugin overriding PathVariableManager and IPathVariableManager in order to link a folder of a 'test1' project from 'test2' project
Should be used with an 'Eclipse application' Laucher using a runtime workspace included in a second zipped attachment.
Created attachment 48707
Linked Folder Patch Runtime Environment

Runtime Environment for an 'Eclipse Application' launcher using the Linked Folder Patch Project attached in this page.
See instructions comment #10
Just playing around, I have created a very small plugin project 'Linked Folder Patch Project' associated with a runtime environment in which 2 projects test and test2 have been created.

test contains a folder 'a' with a file testa.txt
You can create a linked folder within test2, called 'a', linked to 'test/a': it will be resolved as &lt;OS absolute path of test&gt;/a.

Just :
- unzip the 2 zip files, 
- import the Linked Folder into your workspace, 
- create an 'Eclipse Application' Laucher running the application 'org.eclipse.ui.ide.workbench'
- Set the location of the Workspace data of this Launcher to &lt;Full path of the Linked Folder Runtime Environment&gt;
- add to the program arguments of that laucher: -dev &lt;Full path of Linked Folder project&gt;/cls
- Run and try to create a Linked Folder within test2, with 'test/a' as value

It it just a quick test where I replace the first segment of the linked path ('test') with its full OSSystemPath.

Obviously, the correct linked path should be {project:test}/a, hence the proposition of "the full-blown variable support used by the launch configuration dialog" described in comment #8.

However, with my quick patch, I was not able to refer to a relative path **sibling to** my project directory, like test/../anotherdirectory: 
I must go back up one level (../) then add the sibling directory (anotherdirectory)
But when LocationValidator tries to validate the IPath("test/../anotherdirectory"), that IPath is actually valued as "anotherdirectory", because when that Path is build, the canonicalize() function of org.eclipse.core.runtime.Path removes all occurrences of ".." segments from this path... So only "anotherdirectory" is resolved by the (modified) PathVariableManager... which obviously fails (the project 'test' is not there anymore to be replaced by its full OS path)

I suppose the org.eclipse.core.variables plugin does support that scenario (I have not look it up yet)

The point of that quick fix is to provide other curious eclipse users with a small project allowing them to experiment with this issue.
*** Bug 164064 has been marked as a duplicate of this bug. ***
*** Bug 182103 has been marked as a duplicate of this bug. ***
(In reply to comment #5)
&gt; The problem with the variable that you need to redefine it when you change
&gt; views of clearcase for example.
&gt; We would like to define a linked folder in the same way as a classpath
&gt; reference to another workspace project can be defined.
The comment Sherif Zaki made was driven by a PMR opened against RSA6 by our company. We still wait for the fix. We have 2 special situations where we need this:
1. We have gui projects where we code views for our own framework (gui elements). To work with them in the visual editor we have change the framework jars in the classpath so that the views can be displayed. So we defined another project named guidesign where we link the source folder of our gui projects and configure the claspath as mentioned above. The problem is that the path is stored as an absolute path. =&gt; All developers are forced to use the same location of the view (e.g. c:\ccstore\myviewforcomponent1.0\...). =&gt; For a following release we have a different view location (e.g. c:\ccstore\myviewforcomponent2.0\...). All design projects have to be changed.
2. We would like to use the clearcase remote client. Having the server process installed on a unix machine the view will have an additional path element named vobs (c:\ccstore\myviewforcomponent1.0\vobs\...). In this scenario it is not possible to work with remote views and local views at the same time in a project. 
These are limitations we would not have if the linked resource would be a relative path in the workspace. 
*** Bug 29023 has been marked as a duplicate of this bug. ***
Hi, is there a plan to implement this enhancement? We had to make a cumbersome workaround to avoid storing the absolute paths in the .project, so it would be very much appreciated. Thanks.</WithStack>
    <WithOutStack>When you create a new file/folder you have the option to 'link to a folder in the file system'. It would be very usefull to have a 'link to a resource in the workspace' options.

This would be very usefull when you want to share resources between 2 or more projects like:

ProjectA/FolderA
ProjectB/FolderB (linked to FolderA)

you can have this behaviour now but the physical location of the file is stored in the .project file, so it is useless for a team working with CVS.
(Each user has to manually fix the .project file marking the file as an outgoing change).
(In reply to comment #0)
&gt; When you create a new file/folder you have the option to 'link to a folder in
&gt; the file system'. It would be very usefull to have a 'link to a resource in the
&gt; workspace' options.

This option would be very useful.
At least it would be great, if the path to the linked resource could be stored as a relative path.

This seems equivalent to defining a path variable that points to the workspace location (see Preferences &gt; General &gt; Workspace &gt; Linked Resoruces), and then make all your linked resources relative to that variable (Click the "Variables" button when creating a linked resource).
*** Bug 144643 has been marked as a duplicate of this bug. ***
I would like to comment on #2. I don't think that this is equivalent because the path variable can point to the physical workspace root and not the ligical (resources) workspace root.
Description of the duplicated BUG 144643 may help 
- create a java project named test1                                      
- create a java project named test2                                      
- open properties dialog of the java project test2                       
- create a new source folder (java build path - Source - add folder) and 
click create new folder - advanced, activate checkbox "link to folder in 
file system" and select the source folder of project test1.              
- open the .project file of the project test2 and see the absolute path. 

This causes problem in merging changes from one project to another


The problem with the variable that you need to redefine it when you change
views of clearcase for example.
We would like to define a linked folder in the same way as a classpath
reference to another workspace project can be defined.
Example:
We have two projects in a workspace project_a and project_b.
When creating a linked folder we would like to be able to choose either
browse workspace (for relative path) or the entire hard drive (absolute
path).

*** Bug 72940 has been marked as a duplicate of this bug. ***
Ok, Let's see if I follow this thing correctly:

When one creates a linked folder, through, for example, the 'new folder' action within a 'Navigation' view, it triggers:

- org.eclipse.ui.dialogs.WizardNewFolderMainPage#validateLinkedResource()
which delegates the path validation to its linkedResourceGroup (an CreateLinkedResourceGroup widget dedicated to the specification of a linked file or folder target)

- org.eclipse.ui.internal.ide.dialogs.CreateLinkedResourceGroup#validateLinkLocation()
validates its path through the workspace.
The WORKSPACE! It must have all the informations we need, right ? Like the absolute path of any project, candidate for the root of the linked 'relative path' folder we want to create.

- org.eclipse.core.internal.resources.Workspace#validateLinkLocation()
delegates the validation process to its LocationValidator (which implements the various path, URI, and name validation methods in the workspace API)

- org.eclipse.core.internal.resources.LocationValidator#validateLinkLocation()
tries to resolve the path through its PathVariableManager (which manages a collection of path variables and resolves paths containing a variable reference... and allows only a variable reference to appear as the first segment of a relative path)

- org.eclipse.core.internal.resources.PathVariableManager#resolvePath()
returns the path (like '../arelativepath') as is, since the first segment ('..') is not absolute and does not correspond to any classpath variables.

So, then the LocationValidator finds out that the path returned is not absolute and returns a IResourceStatus.VARIABLE_NOT_DEFINED_WARNING message...

Now, what if the PathVariableManager was able to interpret a ${project_path:another_project} variable like the ones we find in the launcher configurations ?
That means the PathVariableManager would also allow for ${project_path:} variable to be a correct first segment, instantly replacing that variable with the absolute path of the specified project, allowing a relative path to be defined, relative to that absolute project path.
The user would enter ${project_path:another_project}/../arelativepath

If you fear for any side effect, maybe you could implement that new behaviour one level above the PathVariableManager, in the LocationValidator#validateLinkLocation() method.

Any comment ? (Before I start overriding org.eclipse.core.internal.resources.PathVariableManager in my eclipse3.2 / 3.3M1 and see what happens ;) )
The best solution is likely to adopt the full-blown variable support used by the launch configuration dialog. This is defined in the org.eclipse.core.variables plugin.  This would likely also require StringVariableSelectionDialog to be pushed down from org.eclipse.debug.ui into org.eclipse.ui.ide. The implementation in org.eclipse.core.resources would then consult IStringVariableManager in org.eclipse.core.variables rather than the existing PathVariableManager. Of course, for backwards compability those variables would still need to be supported.
Is there a way to include that evolution (described in comment #8) within the proposed items of http://www.eclipse.org/eclipse/development/eclipse_project_plan_3_3.html ?

For example, could you consider that it is one of the evolutions necessary to solve bug #154097 ? ("Managing and sharing settings")

It really comes down to solve the current impossibility to **share** an eclipse project without having to redefine something (here: 'Linked path variables') in order to make that shared project work...
Created attachment 48706
Linked Folder Patch Project

Plugin overriding PathVariableManager and IPathVariableManager in order to link a folder of a 'test1' project from 'test2' project
Should be used with an 'Eclipse application' Laucher using a runtime workspace included in a second zipped attachment.
Created attachment 48707
Linked Folder Patch Runtime Environment

Runtime Environment for an 'Eclipse Application' launcher using the Linked Folder Patch Project attached in this page.
See instructions comment #10
Just playing around, I have created a very small plugin project 'Linked Folder Patch Project' associated with a runtime environment in which 2 projects test and test2 have been created.

test contains a folder 'a' with a file testa.txt
You can create a linked folder within test2, called 'a', linked to 'test/a': it will be resolved as &lt;OS absolute path of test&gt;/a.

Just :
- unzip the 2 zip files, 
- import the Linked Folder into your workspace, 
- create an 'Eclipse Application' Laucher running the application 'org.eclipse.ui.ide.workbench'
- Set the location of the Workspace data of this Launcher to &lt;Full path of the Linked Folder Runtime Environment&gt;
- add to the program arguments of that laucher: -dev &lt;Full path of Linked Folder project&gt;/cls
- Run and try to create a Linked Folder within test2, with 'test/a' as value

It it just a quick test where I replace the first segment of the linked path ('test') with its full OSSystemPath.

Obviously, the correct linked path should be {project:test}/a, hence the proposition of "the full-blown variable support used by the launch configuration dialog" described in comment #8.

However, with my quick patch, I was not able to refer to a relative path **sibling to** my project directory, like test/../anotherdirectory: 
I must go back up one level (../) then add the sibling directory (anotherdirectory)
But when LocationValidator tries to validate the IPath("test/../anotherdirectory"), that IPath is actually valued as "anotherdirectory", because when that Path is build, the canonicalize() function of org.eclipse.core.runtime.Path removes all occurrences of ".." segments from this path... So only "anotherdirectory" is resolved by the (modified) PathVariableManager... which obviously fails (the project 'test' is not there anymore to be replaced by its full OS path)

I suppose the org.eclipse.core.variables plugin does support that scenario (I have not look it up yet)

The point of that quick fix is to provide other curious eclipse users with a small project allowing them to experiment with this issue.
*** Bug 164064 has been marked as a duplicate of this bug. ***
*** Bug 182103 has been marked as a duplicate of this bug. ***
(In reply to comment #5)
&gt; The problem with the variable that you need to redefine it when you change
&gt; views of clearcase for example.
&gt; We would like to define a linked folder in the same way as a classpath
&gt; reference to another workspace project can be defined.
The comment Sherif Zaki made was driven by a PMR opened against RSA6 by our company. We still wait for the fix. We have 2 special situations where we need this:
1. We have gui projects where we code views for our own framework (gui elements). To work with them in the visual editor we have change the framework jars in the classpath so that the views can be displayed. So we defined another project named guidesign where we link the source folder of our gui projects and configure the claspath as mentioned above. The problem is that the path is stored as an absolute path. =&gt; All developers are forced to use the same location of the view (e.g. c:\ccstore\myviewforcomponent1.0\...). =&gt; For a following release we have a different view location (e.g. c:\ccstore\myviewforcomponent2.0\...). All design projects have to be changed.
2. We would like to use the clearcase remote client. Having the server process installed on a unix machine the view will have an additional path element named vobs (c:\ccstore\myviewforcomponent1.0\vobs\...). In this scenario it is not possible to work with remote views and local views at the same time in a project. 
These are limitations we would not have if the linked resource would be a relative path in the workspace. 
*** Bug 29023 has been marked as a duplicate of this bug. ***
Hi, is there a plan to implement this enhancement? We had to make a cumbersome workaround to avoid storing the absolute paths in the .project, so it would be very much appreciated. Thanks.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122946" />
    <CreationDate amount="2006-01-06 13:53:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Report Designer" />
    <Version amount="2.0.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Change wording in the dialog prompting for template element instructions</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="4">
        <Lines>
          <Line>1. Change Object Type =&gt; Element Type</Line>
          <Line>2. Change Prompt Text =&gt; Instructions</Line>
          <Line>Fixed by using the string Natasha proposed.</Line>
          <Line>Verified in build 20060110.</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>In the prompt for instructions (converting report element into template element) please change wording:
1. Change Object Type =&gt; Element Type
2. Change Prompt Text =&gt; Instructions
Fixed by using the string Natasha proposed.
Verified in build 20060110.</WithStack>
    <WithOutStack>In the prompt for instructions (converting report element into template element) please change wording:
1. Change Object Type =&gt; Element Type
2. Change Prompt Text =&gt; Instructions
Fixed by using the string Natasha proposed.
Verified in build 20060110.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122947" />
    <CreationDate amount="2006-01-06 13:58:00 -0500" />
    <DupId amount="" />
    <classification amount="WebTools" />
    <Product amount="Web Tools" />
    <component amount="documentation" />
    <Version amount="1.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Formatting added to CSH files causes problems when they appear in browser</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="2">
      <Enumeration lines="2">
        <Lines>
          <Line>1.EditorDTDContexts2.xml</Line>
          <Line>2.EditorDTDContexts.xml</Line>
        </Lines>
      </Enumeration>
      <Enumeration lines="4">
        <Lines>
          <Line>1. EditorXMLContexts2.xml</Line>
          <Line>2. EditorXMLContexts.xml</Line>
          <Line>3. TableTree.xml</Line>
          <Line>4. XMLWizardContexts.xml</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Hi Lawrence - please see our note chain for details. These are the files I need fixed:

org.eclipse.wst.dtd.ui.infopop
1.EditorDTDContexts2.xml
2.EditorDTDContexts.xml 

org.eclipse.wst.xml.ui.infopop

1. EditorXMLContexts2.xml
2. EditorXMLContexts.xml
3. TableTree.xml
4. XMLWizardContexts.xml

There may be others - I'll leave it to Kate to collect a list.
Fix committed and released to the 1.0.1 and 1.5 streams on 20060123. These fixes will be available in WTP builds from the week of 20060123.

Thanks for identifying the problem Ellen.
Great- thx Lawrence.
Thanks for verifying. Closing bug.</WithStack>
    <WithOutStack>Hi Lawrence - please see our note chain for details. These are the files I need fixed:

org.eclipse.wst.dtd.ui.infopop
1.EditorDTDContexts2.xml
2.EditorDTDContexts.xml 

org.eclipse.wst.xml.ui.infopop

1. EditorXMLContexts2.xml
2. EditorXMLContexts.xml
3. TableTree.xml
4. XMLWizardContexts.xml

There may be others - I'll leave it to Kate to collect a list.
Fix committed and released to the 1.0.1 and 1.5 streams on 20060123. These fixes will be available in WTP builds from the week of 20060123.

Thanks for identifying the problem Ellen.
Great- thx Lawrence.
Thanks for verifying. Closing bug.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122948" />
    <CreationDate amount="2006-01-06 13:58:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Report Designer" />
    <Version amount="2.0.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Change wording in step 3 in New Report Wizard</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="7">
        <Lines>
          <Line>1. Change Set Report Property =&gt; Set Template Properties</Line>
          <Line>2. Below add the following line: "These properties will be used if report is saved as template"</Line>
          <Line>Please change the wording of the informational message to:</Line>
          <Line>These properties are used if the report is saved as a template.</Line>
          <Line>Change message string following the proposal of Natasha.</Line>
          <Line>Verified in build 20060110.</Line>
          <Line>verified in build 20060110</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>1. Change Set Report Property =&gt; Set Template Properties
2. Below add the following line: "These properties will be used if report is saved as template"
Please change the wording of the informational message to:
These properties are used if the report is saved as a template.
Change message string following the proposal of Natasha.
Verified in build 20060110.
verified in build 20060110</WithStack>
    <WithOutStack>1. Change Set Report Property =&gt; Set Template Properties
2. Below add the following line: "These properties will be used if report is saved as template"
Please change the wording of the informational message to:
These properties are used if the report is saved as a template.
Change message string following the proposal of Natasha.
Verified in build 20060110.
verified in build 20060110</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122949" />
    <CreationDate amount="2006-01-06 14:13:00 -0500" />
    <DupId amount="" />
    <classification amount="Tools" />
    <Product amount="TPTP Testing" />
    <component amount="Test.UI.URLTest" />
    <Version amount="4.2" />
    <rep_platform amount="All" />
    <op_sys amount="All" />
    <priority amount="P1" />
    <bug_severity amount="enhancement" />
    <Summery>Provide documentation for Bugzilla 4.2 enhancement 74926</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Provide documentation for Bugzilla 4.2 enhancement 74926.  This bugzilla will be used to track the documentation.
Added URL for the description doc.
Initial sizing of 3 weeks with delivery in Iteration 1.  We must allow ID manager to re-evaluate the sizing and modify if necessary.

[sizing = 3 weeks ]

Approved by PMC to be part of 4.2 feature plan (Adding plan keyword)
Change target to 4.2i2.  Still waiting for a documentation person assigned to this.
User doc completed, still need ISV doc. retargeted to i3.
Closing this as documentation has been completed on our (developer's) side and turned in to documentation folks (Melinda) and discussed many times.

There are a few minor changes that may be made and links must be tested to make sure they work.

Bugzilla 141768 is being used to track remaining minor documentation changes.   
ACTION: Please verify/close this defect.
Closing by default since not closed by the originator in the 7+ months since being resolved.  

Please reopen if the issue is still present in the latest TPTP release or the resolution is not correct.</WithStack>
    <WithOutStack>Provide documentation for Bugzilla 4.2 enhancement 74926.  This bugzilla will be used to track the documentation.
Added URL for the description doc.
Initial sizing of 3 weeks with delivery in Iteration 1.  We must allow ID manager to re-evaluate the sizing and modify if necessary.

[sizing = 3 weeks ]

Approved by PMC to be part of 4.2 feature plan (Adding plan keyword)
Change target to 4.2i2.  Still waiting for a documentation person assigned to this.
User doc completed, still need ISV doc. retargeted to i3.
Closing this as documentation has been completed on our (developer's) side and turned in to documentation folks (Melinda) and discussed many times.

There are a few minor changes that may be made and links must be tested to make sure they work.

Bugzilla 141768 is being used to track remaining minor documentation changes.   
ACTION: Please verify/close this defect.
Closing by default since not closed by the originator in the 7+ months since being resolved.  

Please reopen if the issue is still present in the latest TPTP release or the resolution is not correct.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122950" />
    <CreationDate amount="2006-01-06 14:18:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="SWT" />
    <Version amount="3.0.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>TableItem not rendering Arabic correctly</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="INVALID" />
    <WithStack>The following problem for org.eclipse.swt.widgets.TableItem objects is seen when the method setText() is invoked but _not_ when a user directly types text into the control. This might indicate an SWT issue.

TablItem.setText() will take a Hebrew string such as "\u05d0\u05d1\u05d2\u05d3" and render it _correctly_. That is to say the 'logical' ordering of \u05d0, \u05d1, \u05d2, \u05d3, results in the user seeing the 'visual' order of \u05d3, \u05d2, \u05d1, \u05d0, i.e. right-to-left character rendering.

For Arabic, however, this does not occur. So a string such as "\ufe8e\ufe92\ufe9f\ufea9" which is in logical order \ufe8e, \ufe92, \ufe9f, \ufea9 actually gets rendered in that same order, left-to-right. This is incorrect.
The \ufxxx range are the shaped Arabic characters so the Windows GUI rightly doesn't transform them. If the \u06xx range of unshaped Arabic characters is used, they are correctly transformed.</WithStack>
    <WithOutStack>The following problem for org.eclipse.swt.widgets.TableItem objects is seen when the method setText() is invoked but _not_ when a user directly types text into the control. This might indicate an SWT issue.

TablItem.setText() will take a Hebrew string such as "\u05d0\u05d1\u05d2\u05d3" and render it _correctly_. That is to say the 'logical' ordering of \u05d0, \u05d1, \u05d2, \u05d3, results in the user seeing the 'visual' order of \u05d3, \u05d2, \u05d1, \u05d0, i.e. right-to-left character rendering.

For Arabic, however, this does not occur. So a string such as "\ufe8e\ufe92\ufe9f\ufea9" which is in logical order \ufe8e, \ufe92, \ufe9f, \ufea9 actually gets rendered in that same order, left-to-right. This is incorrect.
The \ufxxx range are the shaped Arabic characters so the Windows GUI rightly doesn't transform them. If the \u06xx range of unshaped Arabic characters is used, they are correctly transformed.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122951" />
    <CreationDate amount="2006-01-06 14:29:00 -0500" />
    <DupId amount="122865" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Data Access" />
    <Version amount="2.0.0" />
    <rep_platform amount="All" />
    <op_sys amount="All" />
    <priority amount="P3" />
    <bug_severity amount="enhancement" />
    <Summery>Allow InputStream to be used at runtime as source for data for XML Datasource</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="DUPLICATE" />
    <WithStack>For an XML Datasource, at runtime when executing reports using the ReportEngine.    It would be nice to be able to bind in an InputStream as the source for the XML data instead of using a File path or URL.  You would of course have to use an File or URL at design time to create the datasource and set up the report, but at runtime this would be great.  Currently we have to pull the XML data, write it to a temp file, update the report design to point to the temp file and then run and render the report.  It looks like under the covers the File and URL get turned into an InputStream for the parser, so the plubming is alread there, just need the intermediate step.

Thanks
Doug Porter
dhp@acm.org
This bug will be solved in 2.0

*** This bug has been marked as a duplicate of 122865 ***
verified in build 20060113</WithStack>
    <WithOutStack>For an XML Datasource, at runtime when executing reports using the ReportEngine.    It would be nice to be able to bind in an InputStream as the source for the XML data instead of using a File path or URL.  You would of course have to use an File or URL at design time to create the datasource and set up the report, but at runtime this would be great.  Currently we have to pull the XML data, write it to a temp file, update the report design to point to the temp file and then run and render the report.  It looks like under the covers the File and URL get turned into an InputStream for the parser, so the plubming is alread there, just need the intermediate step.

Thanks
Doug Porter
dhp@acm.org
This bug will be solved in 2.0

*** This bug has been marked as a duplicate of 122865 ***
verified in build 20060113</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122952" />
    <CreationDate amount="2006-01-06 14:33:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="UI" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P5" />
    <bug_severity amount="normal" />
    <Summery>[Dialogs] unnecessary scrollbar in two pane element selector List</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="NEW" />
    <resolution amount="" />
    <WithStack>see attachment. The horizontal scrollbar is not needed and should not be enabled.
Created attachment 32614
dialog
changing prio and status per platform ui bug guidelines
As per http://wiki.eclipse.org/Platform_UI/Bug_Triage_Change_2009</WithStack>
    <WithOutStack>see attachment. The horizontal scrollbar is not needed and should not be enabled.
Created attachment 32614
dialog
changing prio and status per platform ui bug guidelines
As per http://wiki.eclipse.org/Platform_UI/Bug_Triage_Change_2009</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122953" />
    <CreationDate amount="2006-01-06 14:38:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="PDE" />
    <component amount="UI" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>NPE opening plugin-in from feature manifest editor if the plug-in is not in workspace</Summery>
    <Patches amount="0" />
    <Stacktraces amount="1">
      <Stacktrace timestamp="1437330631570">
        <Exception>java.lang.NullPointerException</Exception>
        <Reason />
        <Frames>
          <Frame depth="0">org.eclipse.pde.internal.ui.editor.plugin.ManifestEditor.openPluginEditor(ManifestEditor.java:85)</Frame>
          <Frame depth="1">org.eclipse.pde.internal.ui.editor.plugin.ManifestEditor.openPluginEditor(ManifestEditor.java:81)</Frame>
          <Frame depth="2">org.eclipse.pde.internal.ui.editor.plugin.ManifestEditor.openPluginEditor(ManifestEditor.java:77)</Frame>
          <Frame depth="3">org.eclipse.pde.internal.ui.editor.feature.OpenReferenceAction.run(OpenReferenceAction.java:43)</Frame>
          <Frame depth="4">org.eclipse.pde.internal.ui.editor.feature.PluginSection.handleDoubleClick(PluginSection.java:111)</Frame>
          <Frame depth="5">org.eclipse.pde.internal.ui.editor.TableSection$PartAdapter.handleDoubleClick(TableSection.java:34)</Frame>
          <Frame depth="6">org.eclipse.pde.internal.ui.parts.TablePart$2.doubleClick(TablePart.java:57)</Frame>
          <Frame depth="7">org.eclipse.jface.viewers.StructuredViewer$1.run(StructuredViewer.java:720)</Frame>
          <Frame depth="8">org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:37)</Frame>
          <Frame depth="9">org.eclipse.core.runtime.Platform.run(Platform.java:785)</Frame>
          <Frame depth="10">org.eclipse.ui.internal.JFaceUtil$1.run(JFaceUtil.java:44)</Frame>
          <Frame depth="11">org.eclipse.jface.util.SafeRunnable.run(SafeRunnable.java:148)</Frame>
          <Frame depth="12">org.eclipse.jface.viewers.StructuredViewer.fireDoubleClick(StructuredViewer.java:718)</Frame>
          <Frame depth="13">org.eclipse.jface.viewers.StructuredViewer.handleDoubleSelect(StructuredViewer.java:950)</Frame>
          <Frame depth="14">org.eclipse.jface.viewers.StructuredViewer$4.widgetDefaultSelected(StructuredViewer.java:1057)</Frame>
          <Frame depth="15">org.eclipse.jface.util.OpenStrategy.fireDefaultSelectionEvent(OpenStrategy.java:220)</Frame>
          <Frame depth="16">org.eclipse.jface.util.OpenStrategy.access$0(OpenStrategy.java:217)</Frame>
          <Frame depth="17">org.eclipse.jface.util.OpenStrategy$1.handleEvent(OpenStrategy.java:276)</Frame>
          <Frame depth="18">org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:66)</Frame>
          <Frame depth="19">org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:914)</Frame>
          <Frame depth="20">org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3285)</Frame>
          <Frame depth="21">org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2905)</Frame>
          <Frame depth="22">org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:1762)</Frame>
          <Frame depth="23">org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1726)</Frame>
          <Frame depth="24">org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:397)</Frame>
          <Frame depth="25">org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:143)</Frame>
          <Frame depth="26">org.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:106)</Frame>
          <Frame depth="27">org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:109)</Frame>
          <Frame depth="28">org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:92)</Frame>
          <Frame depth="29">org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:68)</Frame>
          <Frame depth="30">org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:379)</Frame>
          <Frame depth="31">org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:177)</Frame>
          <Frame depth="32">sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</Frame>
          <Frame depth="33">sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)</Frame>
          <Frame depth="34">sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)</Frame>
          <Frame depth="35">java.lang.reflect.Method.invoke(Unknown Source)</Frame>
          <Frame depth="36">org.eclipse.core.launcher.Main.invokeFramework(Main.java:338)</Frame>
          <Frame depth="37">org.eclipse.core.launcher.Main.basicRun(Main.java:282)</Frame>
          <Frame depth="38">org.eclipse.core.launcher.Main.run(Main.java:977)</Frame>
          <Frame depth="39">org.eclipse.core.launcher.Main.main(Main.java:952)</Frame>
        </Frames>
      </Stacktrace>
    </Stacktraces>
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="3">
        <Lines>
          <Line>1) Open feature.xml from CVS repository view or from a feature project in your workspace.</Line>
          <Line>2) Goto "Plug-ins" tab</Line>
          <Line>3) Either double click or "Open" from the context menu on a plugin that is NOT in your workspace.</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>Eclipse R32M4
1) Open feature.xml from CVS repository view or from a feature project in your workspace.
2) Goto "Plug-ins" tab
3) Either double click or "Open" from the context menu on a plugin that is NOT in your workspace.

&gt;&gt; Error will not occur if the plugin project is in workspace.
&gt;&gt; opening a feature from the "Included Features" tab just beeps (no npe) when it is not in the workspace.

Stacktrace for NPE

Error 2006-01-06 14:30:54.836 Problems occurred when invoking code from plug-in: "org.eclipse.jface".
java.lang.NullPointerException
	at org.eclipse.pde.internal.ui.editor.plugin.ManifestEditor.openPluginEditor(ManifestEditor.java:85)
	at org.eclipse.pde.internal.ui.editor.plugin.ManifestEditor.openPluginEditor(ManifestEditor.java:81)
	at org.eclipse.pde.internal.ui.editor.plugin.ManifestEditor.openPluginEditor(ManifestEditor.java:77)
	at org.eclipse.pde.internal.ui.editor.feature.OpenReferenceAction.run(OpenReferenceAction.java:43)
	at org.eclipse.pde.internal.ui.editor.feature.PluginSection.handleDoubleClick(PluginSection.java:111)
	at org.eclipse.pde.internal.ui.editor.TableSection$PartAdapter.handleDoubleClick(TableSection.java:34)
	at org.eclipse.pde.internal.ui.parts.TablePart$2.doubleClick(TablePart.java:57)
	at org.eclipse.jface.viewers.StructuredViewer$1.run(StructuredViewer.java:720)
	at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:37)
	at org.eclipse.core.runtime.Platform.run(Platform.java:785)
	at org.eclipse.ui.internal.JFaceUtil$1.run(JFaceUtil.java:44)
	at org.eclipse.jface.util.SafeRunnable.run(SafeRunnable.java:148)
	at org.eclipse.jface.viewers.StructuredViewer.fireDoubleClick(StructuredViewer.java:718)
	at org.eclipse.jface.viewers.StructuredViewer.handleDoubleSelect(StructuredViewer.java:950)
	at org.eclipse.jface.viewers.StructuredViewer$4.widgetDefaultSelected(StructuredViewer.java:1057)
	at org.eclipse.jface.util.OpenStrategy.fireDefaultSelectionEvent(OpenStrategy.java:220)
	at org.eclipse.jface.util.OpenStrategy.access$0(OpenStrategy.java:217)
	at org.eclipse.jface.util.OpenStrategy$1.handleEvent(OpenStrategy.java:276)
	at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:66)
	at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:914)
	at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3285)
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2905)
	at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:1762)
	at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1726)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:397)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:143)
	at org.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:106)
	at org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:109)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:92)
	at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:68)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:379)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:177)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.eclipse.core.launcher.Main.invokeFramework(Main.java:338)
	at org.eclipse.core.launcher.Main.basicRun(Main.java:282)
	at org.eclipse.core.launcher.Main.run(Main.java:977)
	at org.eclipse.core.launcher.Main.main(Main.java:952)
Fixed.  Thanks for reporting.</WithStack>
    <WithOutStack>Eclipse R32M4
1) Open feature.xml from CVS repository view or from a feature project in your workspace.
2) Goto "Plug-ins" tab
3) Either double click or "Open" from the context menu on a plugin that is NOT in your workspace.

&gt;&gt; Error will not occur if the plugin project is in workspace.
&gt;&gt; opening a feature from the "Included Features" tab just beeps (no npe) when it is not in the workspace.

Stacktrace for NPE

Error 2006-01-06 14:30:54.836 Problems occurred when invoking code from plug-in: "org.eclipse.jface".

Fixed.  Thanks for reporting.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122954" />
    <CreationDate amount="2006-01-06 14:49:00 -0500" />
    <DupId amount="" />
    <classification amount="Tools" />
    <Product amount="TPTP Testing" />
    <component amount="Test.Execution.ManualRunner" />
    <Version amount="4.2" />
    <rep_platform amount="All" />
    <op_sys amount="All" />
    <priority amount="P2" />
    <bug_severity amount="normal" />
    <Summery>Manual Test Runner contains dead code.</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="WONTFIX" />
    <WithStack>Manual Test Runner contains dead code.

The Manual Test Runner (org.eclipse.tptp.test.manual.runner.core.internal.ManualTestRunner.java class) contains several blocks of dead code.  Also, this Manual Test Runner is not intuitive and should be refactored for the new Manual Test Client (https://bugs.eclipse.org/bugs/show_bug.cgi?id=74841) to decrease maintenance.  See the enclosed version of the org.eclipse.tptp.test.manual.runner.core.internal.ManualTestRunner.java class as an example.
Created attachment 32615
ManualTestRunner.java
Not sufficient resources to complete in TPTP V4.2.0 (i1).  Moving to i2.
Cannot contain in TPTP V4.2.0 (i2).
Cannot contain in TPTP V4.2.0 (i3).

Based on priority and available resources, this defect is being considered for deferral from 4.3.
Retargeting to 4.4 as decided in today's AG call (only permitting blocking and critical defects in 4.3 i3).
Targeting to future since cannot be contained in 4.4.
Targeting to future since cannot be contained in 4.4.
As discussed on this week's Test Project call (January 22, 2007), the Test Project will focus on existing P1 - P2/Blocker - Major and P1/Normal and test creation/automation defects (omitting defects dependant on outstanding features) in TPTP 4.4.  All other Test Project defects have been targeted to future.

If this defect has been targeted to future and you/originator feel it should be completed in 4.4, please provide the necessary reason as a reply to this comment or a post to the Test Project mailing list (tptp-test-tooling-dev@eclipse.org).  We will collectively triage and assess our resources to determine a case-by-case decision. 
As discussed on this week's Test Project call (January 22, 2007), the Test Project will focus on existing P1 - P2/Blocker - Major and P1/Normal and test creation/automation defects (omitting defects dependant on outstanding features) in TPTP 4.4.  All other Test Project defects have been targeted to future.

If this defect has been targeted to future and you/originator feel it should be completed in 4.4, please provide the necessary reason as a reply to this comment or a post to the Test Project mailing list (tptp-test-tooling-dev@eclipse.org).  We will collectively triage and assess our resources to determine a case-by-case decision. 
Correction:  The Test Project mailing list is tptp-testing-tools-dev@eclipse.org.
In addition, the org.eclipse.tptp.test.manual.runner.core.internal.ManualTestRunner.java should extend org.eclipse.hyades.test.common.runner.HyadesRunner.java.
(In reply to comment #12)
&gt; In addition, the
&gt; org.eclipse.tptp.test.manual.runner.core.internal.ManualTestRunner.java should
&gt; extend org.eclipse.hyades.test.common.runner.HyadesRunner.java.
&gt; 

Rather, org.eclipse.hyades.test.common.junit.HyadesTestRunner.java.
In TPTP 4.5, the Manual Test type was moved from a General Availability (GA) component to an As-Is component. As-Is components are primarily provided for prior users but imply no support (for example, defects, news group, and mailing lists) or commitment to triage or resolve opened defects. For this defect to be considered, please re-open with an attached patch including code to resolve the symptom and test cases to test the fix.
Closing.</WithStack>
    <WithOutStack>Manual Test Runner contains dead code.

The Manual Test Runner (org.eclipse.tptp.test.manual.runner.core.internal.ManualTestRunner.java class) contains several blocks of dead code.  Also, this Manual Test Runner is not intuitive and should be refactored for the new Manual Test Client (https://bugs.eclipse.org/bugs/show_bug.cgi?id=74841) to decrease maintenance.  See the enclosed version of the org.eclipse.tptp.test.manual.runner.core.internal.ManualTestRunner.java class as an example.
Created attachment 32615
ManualTestRunner.java
Not sufficient resources to complete in TPTP V4.2.0 (i1).  Moving to i2.
Cannot contain in TPTP V4.2.0 (i2).
Cannot contain in TPTP V4.2.0 (i3).

Based on priority and available resources, this defect is being considered for deferral from 4.3.
Retargeting to 4.4 as decided in today's AG call (only permitting blocking and critical defects in 4.3 i3).
Targeting to future since cannot be contained in 4.4.
Targeting to future since cannot be contained in 4.4.
As discussed on this week's Test Project call (January 22, 2007), the Test Project will focus on existing P1 - P2/Blocker - Major and P1/Normal and test creation/automation defects (omitting defects dependant on outstanding features) in TPTP 4.4.  All other Test Project defects have been targeted to future.

If this defect has been targeted to future and you/originator feel it should be completed in 4.4, please provide the necessary reason as a reply to this comment or a post to the Test Project mailing list (tptp-test-tooling-dev@eclipse.org).  We will collectively triage and assess our resources to determine a case-by-case decision. 
As discussed on this week's Test Project call (January 22, 2007), the Test Project will focus on existing P1 - P2/Blocker - Major and P1/Normal and test creation/automation defects (omitting defects dependant on outstanding features) in TPTP 4.4.  All other Test Project defects have been targeted to future.

If this defect has been targeted to future and you/originator feel it should be completed in 4.4, please provide the necessary reason as a reply to this comment or a post to the Test Project mailing list (tptp-test-tooling-dev@eclipse.org).  We will collectively triage and assess our resources to determine a case-by-case decision. 
Correction:  The Test Project mailing list is tptp-testing-tools-dev@eclipse.org.
In addition, the org.eclipse.tptp.test.manual.runner.core.internal.ManualTestRunner.java should extend org.eclipse.hyades.test.common.runner.HyadesRunner.java.
(In reply to comment #12)
&gt; In addition, the
&gt; org.eclipse.tptp.test.manual.runner.core.internal.ManualTestRunner.java should
&gt; extend org.eclipse.hyades.test.common.runner.HyadesRunner.java.
&gt; 

Rather, org.eclipse.hyades.test.common.junit.HyadesTestRunner.java.
In TPTP 4.5, the Manual Test type was moved from a General Availability (GA) component to an As-Is component. As-Is components are primarily provided for prior users but imply no support (for example, defects, news group, and mailing lists) or commitment to triage or resolve opened defects. For this defect to be considered, please re-open with an attached patch including code to resolve the symptom and test cases to test the fix.
Closing.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122955" />
    <CreationDate amount="2006-01-06 14:52:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Report Designer" />
    <Version amount="2.0.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>No distinction of used and unused libraries in Library Explorer</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="WONTFIX" />
    <WithStack>There is no indication in Library Explorer that a particular library is included in a report. All the icons look the same.
The library Icon with the link should appear in teh Library explorer if a library is included in the report.

There can be several libraries in the Library explorer. Once the user double clicks the library icon in outline view, the Library explorer should jump to that library name to allow the user to use the library elements
Library exploer only show lib list in file system. We can't know if the library is included or not for we don't plan to assiciate library explorer to a opening file. This is by design.
If there is no way a user can know the included libraries for a particular report it becomes an issue. There might be many libraries in a project. To look for a particular library to use elements from it becomes a big hassle.

Suggestion: 1. Have a different icon for included libraries and available libraries. 
2. If the user clicks on the included library from the outline view, that particular library elements should expand in library explorer.

This will make the use of the libraries much easier for the user. If this enhancement is not possible for the current release, move it to the next. But it sure is a "must have".
No, that's not the case.
Please assume like this.
You have a library file, which is c:\a.rptlibrary. And you have another file name as d:\c.rptdesign include that library. When you try to open the c:\a.rptlibrary, you have no way to know it is included by d:\c.rptdesign for there're no info in c:\a.rptlibrary ot let you know this.
The library explorer is a stand alone view that show all libraries in current worksapce and user favorite libraries. That's the same case we can know if a library is included or not.
If you still think this is an issue, please discuss with Wenbin.
This bug is reopened.

For the first Suggestion by Aashima. The Library Explorer seems to be a global container, it has no knowledge of the design that uses its libraries. Seems UI has difficults to show different icon for an in-using library. 

While, we should provide the second enhancement, that is, when user select/double click the library icon in outline view, the focus should jump to the one in the library explorer.

The number of libraries in the Library Explorere might be huge(as it is global), in current UI, it gonna be quite a big effort to locate the in-using library. 
I don't think we can fix this with current structure.
For the library opened by including handle by report design. The library opened by library explorer handle by sessionhandle. That two "same" libary has different instance. How can GUI know their the same?
A alternate solution is ask model to rewrite the equals method to compare "same" library hanld between different instance. But I believe the implementation is difficult to find. 
Any way, if QA still want to repoen this bug. I'll file another item to ask model to rewrite equals method.</WithStack>
    <WithOutStack>There is no indication in Library Explorer that a particular library is included in a report. All the icons look the same.
The library Icon with the link should appear in teh Library explorer if a library is included in the report.

There can be several libraries in the Library explorer. Once the user double clicks the library icon in outline view, the Library explorer should jump to that library name to allow the user to use the library elements
Library exploer only show lib list in file system. We can't know if the library is included or not for we don't plan to assiciate library explorer to a opening file. This is by design.
If there is no way a user can know the included libraries for a particular report it becomes an issue. There might be many libraries in a project. To look for a particular library to use elements from it becomes a big hassle.

Suggestion: 1. Have a different icon for included libraries and available libraries. 
2. If the user clicks on the included library from the outline view, that particular library elements should expand in library explorer.

This will make the use of the libraries much easier for the user. If this enhancement is not possible for the current release, move it to the next. But it sure is a "must have".
No, that's not the case.
Please assume like this.
You have a library file, which is c:\a.rptlibrary. And you have another file name as d:\c.rptdesign include that library. When you try to open the c:\a.rptlibrary, you have no way to know it is included by d:\c.rptdesign for there're no info in c:\a.rptlibrary ot let you know this.
The library explorer is a stand alone view that show all libraries in current worksapce and user favorite libraries. That's the same case we can know if a library is included or not.
If you still think this is an issue, please discuss with Wenbin.
This bug is reopened.

For the first Suggestion by Aashima. The Library Explorer seems to be a global container, it has no knowledge of the design that uses its libraries. Seems UI has difficults to show different icon for an in-using library. 

While, we should provide the second enhancement, that is, when user select/double click the library icon in outline view, the focus should jump to the one in the library explorer.

The number of libraries in the Library Explorere might be huge(as it is global), in current UI, it gonna be quite a big effort to locate the in-using library. 
I don't think we can fix this with current structure.
For the library opened by including handle by report design. The library opened by library explorer handle by sessionhandle. That two "same" libary has different instance. How can GUI know their the same?
A alternate solution is ask model to rewrite the equals method to compare "same" library hanld between different instance. But I believe the implementation is difficult to find. 
Any way, if QA still want to repoen this bug. I'll file another item to ask model to rewrite equals method.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122956" />
    <CreationDate amount="2006-01-06 15:00:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="PDE" />
    <component amount="UI" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>[export] Different Export options between the Plugin and Product</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="2">
        <Lines>
          <Line>1. Package plug-ins as individual JAR archives</Line>
          <Line>2. Save as Ant script,</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="RESOLVED" />
    <resolution amount="WONTFIX" />
    <WithStack>I am using 3.2 M3, Build id: I20051102-1600

What I noticed is the Export Wizard option that comes up from 
Plugin.xml-&gt;Overview Tab-&gt;Exporting-&gt;#2 Exporting Wizard
is different from
.product-&gt;Exporting-&gt;Eclipse Product export wizard

When the export dialog box comes up, the last option:
EXPORT_OPTIONS, misses 2 items
1. Package plug-ins as individual JAR archives
2. Save as Ant script,

when invoked from the .product

As a result, when a product is built, the plug-ins generated always are in a JAR form. The plug-ins with 3rd party jars needs to to be manually unjarred, to make the application work.
Created attachment 32617
Attachment, showning the Plug-in export option
Created attachment 32618
Attachment, showing the Product export option
Pascal/Andrew, are you interested in exposing the new product export task in the product export wizard?

That was one our goal while completing the product export. However, note that it is not an ant task but a script that invokes multiple tasks. 
I can see two paths for integration:
 1) complete integration: PDE UI changes to only rely on the product export script from PDE Build. In the product export PDE UI role is one of script and build.properties generation. That requires some work for both PDE Build and UI.

 2) low modification. PDE UI still works as it does today, and when "save as ant script" is selected generates the proper parameters to the product build script.

Be aware that we are currently pretty busy and integrating that at this stage may require more work than we are prepared for.
No one has shown interest in fixing this for several years.  Closing as WONTFIX.  Please reopen if you are interested in contributing a fix.
.</WithStack>
    <WithOutStack>I am using 3.2 M3, Build id: I20051102-1600

What I noticed is the Export Wizard option that comes up from 
Plugin.xml-&gt;Overview Tab-&gt;Exporting-&gt;#2 Exporting Wizard
is different from
.product-&gt;Exporting-&gt;Eclipse Product export wizard

When the export dialog box comes up, the last option:
EXPORT_OPTIONS, misses 2 items
1. Package plug-ins as individual JAR archives
2. Save as Ant script,

when invoked from the .product

As a result, when a product is built, the plug-ins generated always are in a JAR form. The plug-ins with 3rd party jars needs to to be manually unjarred, to make the application work.
Created attachment 32617
Attachment, showning the Plug-in export option
Created attachment 32618
Attachment, showing the Product export option
Pascal/Andrew, are you interested in exposing the new product export task in the product export wizard?

That was one our goal while completing the product export. However, note that it is not an ant task but a script that invokes multiple tasks. 
I can see two paths for integration:
 1) complete integration: PDE UI changes to only rely on the product export script from PDE Build. In the product export PDE UI role is one of script and build.properties generation. That requires some work for both PDE Build and UI.

 2) low modification. PDE UI still works as it does today, and when "save as ant script" is selected generates the proper parameters to the product build script.

Be aware that we are currently pretty busy and integrating that at this stage may require more work than we are prepared for.
No one has shown interest in fixing this for several years.  Closing as WONTFIX.  Please reopen if you are interested in contributing a fix.
.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122957" />
    <CreationDate amount="2006-01-06 15:01:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="UI" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>NPE in PatternFilter.match</Summery>
    <Patches amount="0" />
    <Stacktraces amount="1">
      <Stacktrace timestamp="1437330631585">
        <Exception>java.lang.NullPointerException</Exception>
        <Reason />
        <Frames>
          <Frame depth="0">org.eclipse.ui.internal.dialogs.PatternFilter.match(PatternFilter.java:104)</Frame>
          <Frame depth="1">org.eclipse.ui.internal.dialogs.PatternItemFilter.wordMatches(PatternItemFilter.java:47)</Frame>
          <Frame depth="2">org.eclipse.ui.internal.dialogs.WizardPatternFilter.isElementMatch(WizardPatternFilter.java:100)</Frame>
          <Frame depth="3">org.eclipse.ui.internal.dialogs.FilteredTree.getFirstHighlightedItem(FilteredTree.java:238)</Frame>
          <Frame depth="4">org.eclipse.ui.internal.dialogs.FilteredTree.access$3(FilteredTree.java:236)</Frame>
          <Frame depth="5">org.eclipse.ui.internal.dialogs.FilteredTree$3.keyTraversed(FilteredTree.java:205)</Frame>
          <Frame depth="6">org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:222)</Frame>
          <Frame depth="7">org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:66)</Frame>
          <Frame depth="8">org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:914)</Frame>
          <Frame depth="9">org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:938)</Frame>
          <Frame depth="10">org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:923)</Frame>
          <Frame depth="11">org.eclipse.swt.widgets.Control.traverse(Control.java:2948)</Frame>
          <Frame depth="12">org.eclipse.swt.widgets.Control.translateTraversal(Control.java:2929)</Frame>
          <Frame depth="13">org.eclipse.swt.widgets.Display.translateTraversal(Display.java:3810)</Frame>
          <Frame depth="14">org.eclipse.swt.widgets.Display.filterMessage(Display.java:992)</Frame>
          <Frame depth="15">org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2903)</Frame>
          <Frame depth="16">org.eclipse.jface.window.Window.runEventLoop(Window.java:808)</Frame>
          <Frame depth="17">org.eclipse.jface.window.Window.open(Window.java:786)</Frame>
          <Frame depth="18">org.eclipse.ui.actions.NewProjectAction.run(NewProjectAction.java:114)</Frame>
          <Frame depth="19">org.eclipse.jface.action.Action.runWithEvent(Action.java:492)</Frame>
          <Frame depth="20">org.eclipse.jface.action.ActionContributionItem.handleWidgetSelection(ActionContributionItem.java:530)</Frame>
          <Frame depth="21">org.eclipse.jface.action.ActionContributionItem.access$2(ActionContributionItem.java:480)</Frame>
          <Frame depth="22">org.eclipse.jface.action.ActionContributionItem$5.handleEvent(ActionContributionItem.java:392)</Frame>
          <Frame depth="23">org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:66)</Frame>
          <Frame depth="24">org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:914)</Frame>
          <Frame depth="25">org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3287)</Frame>
          <Frame depth="26">org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2907)</Frame>
          <Frame depth="27">org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:1790)</Frame>
          <Frame depth="28">org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1754)</Frame>
          <Frame depth="29">org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:403)</Frame>
          <Frame depth="30">org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:143)</Frame>
          <Frame depth="31">org.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:106)</Frame>
          <Frame depth="32">org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:109)</Frame>
          <Frame depth="33">org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:92)</Frame>
          <Frame depth="34">org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:68)</Frame>
          <Frame depth="35">org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:381)</Frame>
          <Frame depth="36">org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)</Frame>
          <Frame depth="37">sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</Frame>
          <Frame depth="38">sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:85)</Frame>
          <Frame depth="39">sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:58)</Frame>
          <Frame depth="40">sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:60)</Frame>
          <Frame depth="41">java.lang.reflect.Method.invoke(Method.java:391)</Frame>
          <Frame depth="42">org.eclipse.core.launcher.Main.invokeFramework(Main.java:338)</Frame>
          <Frame depth="43">org.eclipse.core.launcher.Main.basicRun(Main.java:282)</Frame>
          <Frame depth="44">org.eclipse.core.launcher.Main.run(Main.java:977)</Frame>
          <Frame depth="45">org.eclipse.core.launcher.Main.main(Main.java:952)</Frame>
        </Frames>
      </Stacktrace>
    </Stacktraces>
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="VERIFIED" />
    <resolution amount="FIXED" />
    <WithStack>I20060105-0800

I found this NPE in my log today.  I don't know how it was caused, but from a quick look at the code it's possible for the "matcher" field to be null and it is not checked...

java.lang.NullPointerException
at org.eclipse.ui.internal.dialogs.PatternFilter.match(PatternFilter.java:104)
at org.eclipse.ui.internal.dialogs.PatternItemFilter.wordMatches(PatternItemFilter.java:47)
at org.eclipse.ui.internal.dialogs.WizardPatternFilter.isElementMatch(WizardPatternFilter.java:100)
at org.eclipse.ui.internal.dialogs.FilteredTree.getFirstHighlightedItem(FilteredTree.java:238)
at org.eclipse.ui.internal.dialogs.FilteredTree.access$3(FilteredTree.java:236)
at org.eclipse.ui.internal.dialogs.FilteredTree$3.keyTraversed(FilteredTree.java:205)
at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:222)
at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:66)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:914)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:938)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:923)
at org.eclipse.swt.widgets.Control.traverse(Control.java:2948)
at org.eclipse.swt.widgets.Control.translateTraversal(Control.java:2929)
at org.eclipse.swt.widgets.Display.translateTraversal(Display.java:3810)
at org.eclipse.swt.widgets.Display.filterMessage(Display.java:992)
at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2903)
at org.eclipse.jface.window.Window.runEventLoop(Window.java:808)
at org.eclipse.jface.window.Window.open(Window.java:786)
at org.eclipse.ui.actions.NewProjectAction.run(NewProjectAction.java:114)
at org.eclipse.jface.action.Action.runWithEvent(Action.java:492)
at org.eclipse.jface.action.ActionContributionItem.handleWidgetSelection(ActionContributionItem.java:530)
at org.eclipse.jface.action.ActionContributionItem.access$2(ActionContributionItem.java:480)
at org.eclipse.jface.action.ActionContributionItem$5.handleEvent(ActionContributionItem.java:392)
at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:66)
at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:914)
at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3287)
at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:2907)
at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:1790)
at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1754)
at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:403)
at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:143)
at org.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:106)
at org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:109)
at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:92)
at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:68)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:381)
at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:85)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:58)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:60)
at java.lang.reflect.Method.invoke(Method.java:391)
at org.eclipse.core.launcher.Main.invokeFramework(Main.java:338)
at org.eclipse.core.launcher.Main.basicRun(Main.java:282)
at org.eclipse.core.launcher.Main.run(Main.java:977)
at org.eclipse.core.launcher.Main.main(Main.java:952)
I was able to replicate by clearing all the text in the filter field then hitting Enter.  
just released the fix
Verified in I20060214-0800
(In reply to comment #1)
&gt; I was able to replicate by clearing all the text in the filter field then
&gt; hitting Enter.  

Hi, 

I could not find any FilteredTree example on the internet. Can you please provide with a sample code for this. 

Thanks
Vikas</WithStack>
    <WithOutStack>I20060105-0800

I found this NPE in my log today.  I don't know how it was caused, but from a quick look at the code it's possible for the "matcher" field to be null and it is not checked...


I was able to replicate by clearing all the text in the filter field then hitting Enter.  
just released the fix
Verified in I20060214-0800
(In reply to comment #1)
&gt; I was able to replicate by clearing all the text in the filter field then
&gt; hitting Enter.  

Hi, 

I could not find any FilteredTree example on the internet. Can you please provide with a sample code for this. 

Thanks
Vikas</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122958" />
    <CreationDate amount="2006-01-06 15:07:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Report Engine" />
    <Version amount="2.0.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="major" />
    <Summery>Event methods in IScriptedDataSetEventHandler/IScriptedDataSourceEventHandler don't have IReportContext parameter</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="INVALID" />
    <WithStack>IScriptedDataSourceEventHandler.open/close and 
IScriptedDataSetEventHandler.open/close/fetch/describe need to get IReportContext as a parameter (like every other script event handler). Without this, these methods are very hard to use.
We can probably not add IReportContext since it will not work in preview. Probably have to change the execution so that the same instance of the handler is used in all the events. This way, private class variables can be used to store information between open, fetch and close.
Actually, the current implementation uses the same instance when executing the event methods. So it is valid to use class member variables. So I think the original bug is invalid.
Verify this bug. 
Please verify and close it.</WithStack>
    <WithOutStack>IScriptedDataSourceEventHandler.open/close and 
IScriptedDataSetEventHandler.open/close/fetch/describe need to get IReportContext as a parameter (like every other script event handler). Without this, these methods are very hard to use.
We can probably not add IReportContext since it will not work in preview. Probably have to change the execution so that the same instance of the handler is used in all the events. This way, private class variables can be used to store information between open, fetch and close.
Actually, the current implementation uses the same instance when executing the event methods. So it is valid to use class member variables. So I think the original bug is invalid.
Verify this bug. 
Please verify and close it.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122959" />
    <CreationDate amount="2006-01-06 15:11:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Report Designer" />
    <Version amount="2.0.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Theme styles from the library are not seen on right click</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="INVALID" />
    <WithStack>When we include a library to a report, the themes defined in the library should be available to use in the report. When we include the library and want to apply a particular style from that library to report design, the list of styles is not available on right click.
You need apply the theme in library to the design file at first.
Verified in build 20060110.</WithStack>
    <WithOutStack>When we include a library to a report, the themes defined in the library should be available to use in the report. When we include the library and want to apply a particular style from that library to report design, the list of styles is not available on right click.
You need apply the theme in library to the design file at first.
Verified in build 20060110.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122960" />
    <CreationDate amount="2006-01-06 15:14:00 -0500" />
    <DupId amount="" />
    <classification amount="WebTools" />
    <Product amount="WTP Common Tools" />
    <component amount="wst.validation" />
    <Version amount="1.0" />
    <rep_platform amount="All" />
    <op_sys amount="All" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>[validation] Invalid error message from org.eclipse.wst.validation.internal.FilterUtil.getFileDelta()</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="5">
      <source_code type="multicomment">
        <location start="919" end="2671" />
        <code>/**
	 * Return the name of the resource, without the project-specific information in front.
	 * 
	 * This method is used by ValidationOperation to calculate the non-environment specific names of
	 * the files. Only the IWorkbenchContext implementation knows how much information to strip off
	 * of the IResource name. For example, if there is an EJB Project named "MyEJBProject", and it
	 * uses the default names for the source and output folders, "source" and "ejbModule",
	 * respectively, then the current implementation of EJB Helper knows how much of that structure
	 * is eclipse-specific.
	 * 
	 * Since the "source" folder contains Java source files, a portable name would be the
	 * fully-qualified name of the Java class, without the eclipse-specific project and folder names
	 * in front of the file name. The EJBHelper knows that everything up to the "source" folder, for
	 * example, can be removed, because, according to the definition of the EJB Project, everything
	 * contained in the source folder is java source code. So if there is an IResource in an EJB
	 * Project named "/MyEJBProject/source/com/ibm/myclasses/MyJavaFile.java", this method would
	 * make this name portable by stripping off the "/MyEJBProject/source", and returning
	 * "com/ibm/myclasses/MyJavaFile.java".
	 * 
	 * The output of this method is used by the ValidationOperation, when it is calculating the list
	 * of added/changed/deleted file names for incremental validation. If getPortableName(IResource)
	 * returns null, that means that the IWorkbenchContext's implementation does not support that
	 * particular type of resource, and the resource should not be included in the array of
	 * IFileDelta objects in the IValidator's "validate" method.
	 */</code>
      </source_code>
      <source_code type="functioncall">
        <location start="2672" end="2723" />
        <code>public String getPortableName(IResource resource);</code>
      </source_code>
      <source_code type="multicomment">
        <location start="2724" end="4475" />
        <code>/**
	 * Return the name of the resource, without the project-specific information in front.
	 * 
	 * This method is used by ValidationOperation to calculate the non-environment specific names of
	 * the files. Only the IWorkbenchContext implementation knows how much information to strip off
	 * of the IResource name. For example, if there is an EJB Project named "MyEJBProject", and it
	 * uses the default names for the source and output folders, "source" and "ejbModule",
	 * respectively, then the current implementation of EJB Helper knows how much of that structure
	 * is eclipse-specific.
	 * 
	 * Since the "source" folder contains Java source files, a portable name would be the
	 * fully-qualified name of the Java class, without the eclipse-specific project and folder names
	 * in front of the file name. The EJBHelper knows that everything up to the "source" folder, for
	 * example, can be removed, because, according to the definition of the EJB Project, everything
	 * contained in the source folder is java source code. So if there is an IResource in an EJB
	 * Project named "/MyEJBProject/source/com/ibm/myclasses/MyJavaFile.java", this method would
	 * make this name portable by stripping off the "/MyEJBProject/source", and returning
	 * "com/ibm/myclasses/MyJavaFile.java".
	 * 
	 * The output of this method is used by the ValidationOperation, when it is calculating the list
	 * of added/changed/deleted file names for incremental validation. If getPortableName(IResource)
	 * returns null, that means that the IWorkbenchContext's implementation does not support that
	 * particular type of resource, and the resource should not be included in the array of
	 * IFileDelta objects in the IValidator's "validate" method.
	 */</code>
      </source_code>
      <source_code type="functioncall">
        <location start="4476" end="4527" />
        <code>public String getPortableName(IResource resource);</code>
      </source_code>
      <source_code type="functiondef">
        <location start="5649" end="5821" />
        <code>IWAE0011E Resource {0} cannot be added to file list because IWorkbenchContext.getPortableName() returns null. This resource will not be validated by the validator named {1}</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>If an implementation of org.eclipse.wst.validation.internal.operations.IWorkbenchContext.getPortableName(IResource) returns null when called from org.eclipse.wst.validation.internal.FilterUtil.getFileDelta(org.eclipse.wst.validation.internal.operations.IWorkbenchContext, org.eclipse.wst.validation.internal.ValidatorMetaData, org.eclipse.core.resources.IResource, int), line 294, an error message like the following is logged to the console:

!ENTRY org.eclipse.wst.validation 4 0 2006-01-06 10:03:31.332
!MESSAGE 
*** ERROR ***: Fri Jan 06 10:03:31 EST 2006    IWAE0011E Resource &lt;foo&gt; cannot be added to file list because IHelper.getPortableName() returns null. This resource will not be validated by the validator named &lt;bar&gt;.

However, the javadoc for IWorkbenchContext.getPortableName(IResource) clearly states that null is a valid possible return value.  So, no error message should be logged when that happens.

	/**
	 * Return the name of the resource, without the project-specific information in front.
	 * 
	 * This method is used by ValidationOperation to calculate the non-environment specific names of
	 * the files. Only the IWorkbenchContext implementation knows how much information to strip off
	 * of the IResource name. For example, if there is an EJB Project named "MyEJBProject", and it
	 * uses the default names for the source and output folders, "source" and "ejbModule",
	 * respectively, then the current implementation of EJB Helper knows how much of that structure
	 * is eclipse-specific.
	 * 
	 * Since the "source" folder contains Java source files, a portable name would be the
	 * fully-qualified name of the Java class, without the eclipse-specific project and folder names
	 * in front of the file name. The EJBHelper knows that everything up to the "source" folder, for
	 * example, can be removed, because, according to the definition of the EJB Project, everything
	 * contained in the source folder is java source code. So if there is an IResource in an EJB
	 * Project named "/MyEJBProject/source/com/ibm/myclasses/MyJavaFile.java", this method would
	 * make this name portable by stripping off the "/MyEJBProject/source", and returning
	 * "com/ibm/myclasses/MyJavaFile.java".
	 * 
	 * The output of this method is used by the ValidationOperation, when it is calculating the list
	 * of added/changed/deleted file names for incremental validation. If getPortableName(IResource)
	 * returns null, that means that the IWorkbenchContext's implementation does not support that
	 * particular type of resource, and the resource should not be included in the array of
	 * IFileDelta objects in the IValidator's "validate" method.
	 */
	public String getPortableName(IResource resource);
	/**
	 * Return the name of the resource, without the project-specific information in front.
	 * 
	 * This method is used by ValidationOperation to calculate the non-environment specific names of
	 * the files. Only the IWorkbenchContext implementation knows how much information to strip off
	 * of the IResource name. For example, if there is an EJB Project named "MyEJBProject", and it
	 * uses the default names for the source and output folders, "source" and "ejbModule",
	 * respectively, then the current implementation of EJB Helper knows how much of that structure
	 * is eclipse-specific.
	 * 
	 * Since the "source" folder contains Java source files, a portable name would be the
	 * fully-qualified name of the Java class, without the eclipse-specific project and folder names
	 * in front of the file name. The EJBHelper knows that everything up to the "source" folder, for
	 * example, can be removed, because, according to the definition of the EJB Project, everything
	 * contained in the source folder is java source code. So if there is an IResource in an EJB
	 * Project named "/MyEJBProject/source/com/ibm/myclasses/MyJavaFile.java", this method would
	 * make this name portable by stripping off the "/MyEJBProject/source", and returning
	 * "com/ibm/myclasses/MyJavaFile.java".
	 * 
	 * The output of this method is used by the ValidationOperation, when it is calculating the list
	 * of added/changed/deleted file names for incremental validation. If getPortableName(IResource)
	 * returns null, that means that the IWorkbenchContext's implementation does not support that
	 * particular type of resource, and the resource should not be included in the array of
	 * IFileDelta objects in the IValidator's "validate" method.
	 */
	public String getPortableName(IResource resource);
dropped to HEAD
I am in the process of cleaning up the Validation Framework defects. Could you please close this Bugzilla. If I don't hear back within 7 days,
I will assume that everything is OK, and will close it.

Whoops. I dropped this to HEAD at the end of April, but I never released it. Now I need approval to release it, so I will prepare a patch. 
Created attachment 99388
patch
Chuck, Could you review this please. The fix is simply to comment out the logging of the error, and then removing the unused error message. 
Patch looks good - submitting to PMC
I am a little bit anxious on removing the VBF_EXC_SYNTAX_NULL_NAME message
property. Is this really necessary? I have some cases in my experience as a
committer where removing message property resulted in bugs reporting adopter
breakage. 

(In reply to comment #7)
&gt; I am a little bit anxious on removing the VBF_EXC_SYNTAX_NULL_NAME message
&gt; property. Is this really necessary? I have some cases in my experience as a
&gt; committer where removing message property resulted in bugs reporting adopter
&gt; breakage. 
&gt; 
Looking at the content of the message: 

IWAE0011E Resource {0} cannot be added to file list because IWorkbenchContext.getPortableName() returns null. This resource will not be validated by the validator named {1}.

I can't imagine anyone else ever being able to reuse this particular message. I think it is important to remove bloat, otherwise the code simply becomes less and less maintainable. 

I wanted just to mention it. I have been thought the same thoughts when I removed message properties. And then Carl reported me some bugs :-)

I approve with the assumption that you and Chuck have a good awareness of the adopters of the validation framework. 
released
It's not released. This patch wasn't in my workspace when I released my changes on the 14th. Since it's approved, I've committed (but not released) it today.
released
verified the code is in the builds.
closing</WithStack>
    <WithOutStack>If an implementation of org.eclipse.wst.validation.internal.operations.IWorkbenchContext.getPortableName(IResource) returns null when called from org.eclipse.wst.validation.internal.FilterUtil.getFileDelta(org.eclipse.wst.validation.internal.operations.IWorkbenchContext, org.eclipse.wst.validation.internal.ValidatorMetaData, org.eclipse.core.resources.IResource, int), line 294, an error message like the following is logged to the console:

!ENTRY org.eclipse.wst.validation 4 0 2006-01-06 10:03:31.332
!MESSAGE 
*** ERROR ***: Fri Jan 06 10:03:31 EST 2006    IWAE0011E Resource &lt;foo&gt; cannot be added to file list because IHelper.getPortableName() returns null. This resource will not be validated by the validator named &lt;bar&gt;.

However, the javadoc for IWorkbenchContext.getPortableName(IResource) clearly states that null is a valid possible return value.  So, no error message should be logged when that happens.

	/**
	 * Return the name of the resource, without the project-specific information in front.
	 * 
	 * This method is used by ValidationOperation to calculate the non-environment specific names of
	 * the files. Only the IWorkbenchContext implementation knows how much information to strip off
	 * of the IResource name. For example, if there is an EJB Project named "MyEJBProject", and it
	 * uses the default names for the source and output folders, "source" and "ejbModule",
	 * respectively, then the current implementation of EJB Helper knows how much of that structure
	 * is eclipse-specific.
	 * 
	 * Since the "source" folder contains Java source files, a portable name would be the
	 * fully-qualified name of the Java class, without the eclipse-specific project and folder names
	 * in front of the file name. The EJBHelper knows that everything up to the "source" folder, for
	 * example, can be removed, because, according to the definition of the EJB Project, everything
	 * contained in the source folder is java source code. So if there is an IResource in an EJB
	 * Project named "/MyEJBProject/source/com/ibm/myclasses/MyJavaFile.java", this method would
	 * make this name portable by stripping off the "/MyEJBProject/source", and returning
	 * "com/ibm/myclasses/MyJavaFile.java".
	 * 
	 * The output of this method is used by the ValidationOperation, when it is calculating the list
	 * of added/changed/deleted file names for incremental validation. If getPortableName(IResource)
	 * returns null, that means that the IWorkbenchContext's implementation does not support that
	 * particular type of resource, and the resource should not be included in the array of
	 * IFileDelta objects in the IValidator's "validate" method.
	 */
	public String getPortableName(IResource resource);
	/**
	 * Return the name of the resource, without the project-specific information in front.
	 * 
	 * This method is used by ValidationOperation to calculate the non-environment specific names of
	 * the files. Only the IWorkbenchContext implementation knows how much information to strip off
	 * of the IResource name. For example, if there is an EJB Project named "MyEJBProject", and it
	 * uses the default names for the source and output folders, "source" and "ejbModule",
	 * respectively, then the current implementation of EJB Helper knows how much of that structure
	 * is eclipse-specific.
	 * 
	 * Since the "source" folder contains Java source files, a portable name would be the
	 * fully-qualified name of the Java class, without the eclipse-specific project and folder names
	 * in front of the file name. The EJBHelper knows that everything up to the "source" folder, for
	 * example, can be removed, because, according to the definition of the EJB Project, everything
	 * contained in the source folder is java source code. So if there is an IResource in an EJB
	 * Project named "/MyEJBProject/source/com/ibm/myclasses/MyJavaFile.java", this method would
	 * make this name portable by stripping off the "/MyEJBProject/source", and returning
	 * "com/ibm/myclasses/MyJavaFile.java".
	 * 
	 * The output of this method is used by the ValidationOperation, when it is calculating the list
	 * of added/changed/deleted file names for incremental validation. If getPortableName(IResource)
	 * returns null, that means that the IWorkbenchContext's implementation does not support that
	 * particular type of resource, and the resource should not be included in the array of
	 * IFileDelta objects in the IValidator's "validate" method.
	 */
	public String getPortableName(IResource resource);
dropped to HEAD
I am in the process of cleaning up the Validation Framework defects. Could you please close this Bugzilla. If I don't hear back within 7 days,
I will assume that everything is OK, and will close it.

Whoops. I dropped this to HEAD at the end of April, but I never released it. Now I need approval to release it, so I will prepare a patch. 
Created attachment 99388
patch
Chuck, Could you review this please. The fix is simply to comment out the logging of the error, and then removing the unused error message. 
Patch looks good - submitting to PMC
I am a little bit anxious on removing the VBF_EXC_SYNTAX_NULL_NAME message
property. Is this really necessary? I have some cases in my experience as a
committer where removing message property resulted in bugs reporting adopter
breakage. 

(In reply to comment #7)
&gt; I am a little bit anxious on removing the VBF_EXC_SYNTAX_NULL_NAME message
&gt; property. Is this really necessary? I have some cases in my experience as a
&gt; committer where removing message property resulted in bugs reporting adopter
&gt; breakage. 
&gt; 
Looking at the content of the message: 

IWAE0011E Resource {0} cannot be added to file list because IWorkbenchContext.getPortableName() returns null. This resource will not be validated by the validator named {1}.

I can't imagine anyone else ever being able to reuse this particular message. I think it is important to remove bloat, otherwise the code simply becomes less and less maintainable. 

I wanted just to mention it. I have been thought the same thoughts when I removed message properties. And then Carl reported me some bugs :-)

I approve with the assumption that you and Chuck have a good awareness of the adopters of the validation framework. 
released
It's not released. This patch wasn't in my workspace when I released my changes on the 14th. Since it's approved, I've committed (but not released) it today.
released
verified the code is in the builds.
closing</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122961" />
    <CreationDate amount="2006-01-06 15:15:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse Foundation" />
    <Product amount="z_Archived" />
    <component amount="VE" />
    <Version amount="unspecified" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Setting JSlider majorTickSpacing causes NPE</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Drop a JSlider onto JPanel.
Set the paintLabels and paintTicks to true.
Set the majorTickSpacing to 20.
An info icon shows on the JSlider with the info message about a NullPointerException on majorTickSpacing.

This problem is a result a another bug fix related to JSlider... bug 111745
We don't have the LabelTable property to set because of but 111745 so we need to reset the labelTable property using the set method directly. This is done in JSliderProxyAdapter.

Fixed and released to HEAD for 1.2
Closing</WithStack>
    <WithOutStack>Drop a JSlider onto JPanel.
Set the paintLabels and paintTicks to true.
Set the majorTickSpacing to 20.
An info icon shows on the JSlider with the info message about a NullPointerException on majorTickSpacing.

This problem is a result a another bug fix related to JSlider... bug 111745
We don't have the LabelTable property to set because of but 111745 so we need to reset the labelTable property using the set method directly. This is done in JSliderProxyAdapter.

Fixed and released to HEAD for 1.2
Closing</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122962" />
    <CreationDate amount="2006-01-06 15:25:00 -0500" />
    <DupId amount="" />
    <classification amount="WebTools" />
    <Product amount="WTP Java EE Tools" />
    <component amount="jst.j2ee" />
    <Version amount="1.0.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="major" />
    <Summery>Adding a utility project to a module does not add manifest entry</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Create a java project.
Create a web or an ejb project in an ear.
Try and add the java project as a utility from the project properties.
The manifest.mf is not updated with an entry.  The .classpath is updated.
Dropped changes to 1/9 build
Verified on 1/25 WTP 1.0.1 M build.</WithStack>
    <WithOutStack>Create a java project.
Create a web or an ejb project in an ear.
Try and add the java project as a utility from the project properties.
The manifest.mf is not updated with an entry.  The .classpath is updated.
Dropped changes to 1/9 build
Verified on 1/25 WTP 1.0.1 M build.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122963" />
    <CreationDate amount="2006-01-06 15:26:00 -0500" />
    <DupId amount="" />
    <classification amount="WebTools" />
    <Product amount="WTP Java EE Tools" />
    <component amount="jst.j2ee" />
    <Version amount="1.0.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="major" />
    <Summery>[project explorer] Ear utility jars do not show in J2EE project explorer.</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="INVALID" />
    <WithStack>If you have valid utility jars in your ear referenced by contained modules such as ejb or web utiliy jars, they do not show in the meta node for the EAR in the j2ee view.
This is by design.  The web lib modules are not ear modules so they do not show.
OK</WithStack>
    <WithOutStack>If you have valid utility jars in your ear referenced by contained modules such as ejb or web utiliy jars, they do not show in the meta node for the EAR in the j2ee view.
This is by design.  The web lib modules are not ear modules so they do not show.
OK</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122964" />
    <CreationDate amount="2006-01-06 15:29:00 -0500" />
    <DupId amount="87299" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="SWT" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Linux" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Large String variables (and expressions) are not handled well</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="DUPLICATE" />
    <WithStack>This could be Linux/gtk-specific. When displaying large Strings (say 10,000 chars long) on the "variables" or "expressions" view, the tree view is mangled (open/close arrows disappear, etc).
Long strings on linux appear to display with new lines, etc, right in the tree items (i.e. across multiple lines). The open/close arrows, etc, appear centered vertically for the item, rather than at the top of the tree item. Moving to SWT for comment.


*** This bug has been marked as a duplicate of bug 87299 ***</WithStack>
    <WithOutStack>This could be Linux/gtk-specific. When displaying large Strings (say 10,000 chars long) on the "variables" or "expressions" view, the tree view is mangled (open/close arrows disappear, etc).
Long strings on linux appear to display with new lines, etc, right in the tree items (i.e. across multiple lines). The open/close arrows, etc, appear centered vertically for the item, rather than at the top of the tree item. Moving to SWT for comment.


*** This bug has been marked as a duplicate of bug 87299 ***</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122965" />
    <CreationDate amount="2006-01-06 15:32:00 -0500" />
    <DupId amount="" />
    <classification amount="Tools" />
    <Product amount="TPTP Release Engineering" />
    <component amount="TPTP.Testing" />
    <Version amount="4.2" />
    <rep_platform amount="PC" />
    <op_sys amount="All" />
    <priority amount="P3" />
    <bug_severity amount="enhancement" />
    <Summery>test automation enhancement, config item for RAC executable.</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Navid asked me to add this enhancement request.

I need the ability to use his test automation framework using the new agent controller and not the RAC. I proposed adding a way for the framework to tailor what server to use.
Tyler, can you please reassign this bug to me
New feature implemented in HEAD.
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithStack>
    <WithOutStack>Navid asked me to add this enhancement request.

I need the ability to use his test automation framework using the new agent controller and not the RAC. I proposed adding a way for the framework to tailor what server to use.
Tyler, can you please reassign this bug to me
New feature implemented in HEAD.
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122966" />
    <CreationDate amount="2006-01-06 15:32:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="APT" />
    <Version amount="3.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="major" />
    <Summery>IFactoryPath needs to include getEnabledContainers and getAllContainers</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="WONTFIX" />
    <WithStack>The IFactoryPath interface needs to expose getEnabledContainers and getAllContainers methods available on the FactoryPath class. I am currently forced to use internal class FactoryPath and FactoryContainer in order to read the factory path.
I'm fine with that (and it's definitely preferable to using the internal APIs), but what's the reason you need to read the factory path?  That is, what's the use case?
I need to scan the project for all the classpath variables that are used. This means I need to scan the classpath and the factorypath.
Would it work to use the set of all classpath variables, rather than worrying about which ones are actually in use in a given project?

The issue is that if I expose getXxxContainers() I need to also expose (and thus repackage) FactoryContainer, which is at present not part of the API; or at least I need to create an IFactoryContainer.  Not an impossibility, just somewhat inconvenient.
I don't want to use all classpath variables because that would create too much noise. I am retrieving this information in order to generate a file of absolute paths for ant scripts to use in a team environment. The more absolute paths go into this file, the more the admin has to contend with setting up and updating. 

But regardless of this usecase, this seams like a major API outage. It should be possible for plugins to not only add to the factorypath, but also to list it. A good check to see that you got enough exposed as API is to make sure that the ui plugin does not reference any internal code in the core plugin. 
I do agree with doing this UI change, but because of the structure of the FactoryContainer classes I can't just add new API without changing a bunch of existing stuff, and it's too late in the game for that.  Conversely, I'm not quite ready to just expose all the existing classes as public API.  So I'm going to sit on this for a version or two, to learn more about what API we really need as clients for it continue to emerge.
As of now 'LATER' and 'REMIND' resolutions are no longer supported.
Please reopen this bug if it is still valid for you.</WithStack>
    <WithOutStack>The IFactoryPath interface needs to expose getEnabledContainers and getAllContainers methods available on the FactoryPath class. I am currently forced to use internal class FactoryPath and FactoryContainer in order to read the factory path.
I'm fine with that (and it's definitely preferable to using the internal APIs), but what's the reason you need to read the factory path?  That is, what's the use case?
I need to scan the project for all the classpath variables that are used. This means I need to scan the classpath and the factorypath.
Would it work to use the set of all classpath variables, rather than worrying about which ones are actually in use in a given project?

The issue is that if I expose getXxxContainers() I need to also expose (and thus repackage) FactoryContainer, which is at present not part of the API; or at least I need to create an IFactoryContainer.  Not an impossibility, just somewhat inconvenient.
I don't want to use all classpath variables because that would create too much noise. I am retrieving this information in order to generate a file of absolute paths for ant scripts to use in a team environment. The more absolute paths go into this file, the more the admin has to contend with setting up and updating. 

But regardless of this usecase, this seams like a major API outage. It should be possible for plugins to not only add to the factorypath, but also to list it. A good check to see that you got enough exposed as API is to make sure that the ui plugin does not reference any internal code in the core plugin. 
I do agree with doing this UI change, but because of the structure of the FactoryContainer classes I can't just add new API without changing a bunch of existing stuff, and it's too late in the game for that.  Conversely, I'm not quite ready to just expose all the existing classes as public API.  So I'm going to sit on this for a version or two, to learn more about what API we really need as clients for it continue to emerge.
As of now 'LATER' and 'REMIND' resolutions are no longer supported.
Please reopen this bug if it is still valid for you.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122967" />
    <CreationDate amount="2006-01-06 15:38:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="User Assistance" />
    <Version amount="3.2" />
    <rep_platform amount="All" />
    <op_sys amount="All" />
    <priority amount="P2" />
    <bug_severity amount="enhancement" />
    <Summery>[Help] Remote help system</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="2">
      <Enumeration lines="17">
        <Lines>
          <Line>1. Pre-configured out of the box - In the plugin_customization.ini you can change these parameters (with defaults):</Line>
          <Line />
          <Line>org.eclipse.help.base/remoteHelpOn=false</Line>
          <Line>org.eclipse.help.base/remoteHelpHost=</Line>
          <Line>org.eclipse.help.base/remoteHelpPath=/help</Line>
          <Line>org.eclipse.help.base/remoteHelpUseDefaultPort=true</Line>
          <Line>org.eclipse.help.base/remoteHelpPort=80</Line>
          <Line />
          <Line>If not on, then all others ignored. Also if default port is used, port number is ignored. So, for example, if you have an infocenter that you can access at http://myinfocenter.mydomain.com:8081/help/index.jsp, you would use these settings:</Line>
          <Line />
          <Line>org.eclipse.help.base/remoteHelpOn=true</Line>
          <Line>org.eclipse.help.base/remoteHelpHost=myinfocenter.mydomain.com</Line>
          <Line>org.eclipse.help.base/remoteHelpPath=/help</Line>
          <Line>org.eclipse.help.base/remoteHelpUseDefaultPort=false</Line>
          <Line>org.eclipse.help.base/remoteHelpPort=8081</Line>
          <Line />
          <Line>2. Preference page under Help -&gt; Content. You can specify the exact same info as the fields above.</Line>
        </Lines>
      </Enumeration>
      <Enumeration lines="2">
        <Lines>
          <Line>- Progress monitoring is difficult for remote content since we don't use RPC. We  could implement this in the servlets by sending special progress data regularly, but I'd have to dig into this a little more.</Line>
          <Line>- Searching dynamic content on the remote server is complicated. We have to first get the "raw" remote results that are unfiltered, but with contributions resolved, then filter the results locally. Currently this is not even done in the local case - i.e. you will get false positives if you search for dynamic content that should only show up on, say, linux, but you're running in windows. Searching remotely also puts a potentially large burden on the infocenter, so I need to investigate whether it's possible to transfer some of this load to the client.</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>Allow documentation content to be installed on one (central) machine, and accessed by multiple Eclipse Workbench clients (on other machines). 

This requirement is based on the need for users to reduce the footprint of what's installed on their development machine; docs can get quite big. Also, documentation updates could be handled centrally, too.

Would need a preference indicating the location of the central docs. Local doc plugins would be ignored (this situation to be covered in another feature request) and so could be not installed.
Note: links from local UA (and other) elements that would normally launch the local help system must now launch the remote help system instead.
*** Bug 122969 has been marked as a duplicate of this bug. ***
Also included in this enhancement:

As a follow-up to enh 122967, allow a user to not only access a centralized
remote help server directly from their workbench, but also to install help
content (doc) plug-ins locally, and have those integrated into the same Help
System view as the remote content.

The scenario is this: developer works for big company who has centralized the
product docs for their developers on a remote server (developers still access
it via Help &gt; Help Contents or links from context help or Welcome). Then the
developer installs a new Eclipse-based tool (and docs) that the other users
aren't using -- wants to see help, but his Eclipse is pointed at the remote
help server.
Deferring to next release due to resource shortage. I will attach the current state of the work as an attachment to this bug. Some notes about the current state of things:

The remote documents are provided by flowing the data through the local help server. The client always requests from the local server (which must be running even if all content is remote), and if the local server does not have the content it consults the remote server. If the remote server has the content, the local server downloads it, filters it, and sends it to the client. Thus, the client workbench does not even know that the content was remote. Another reason for always needing a local help server is that there may be local content, pushing the work of presenting the data and filtering to the client rather than putting a burden on the server, and for the links tab, bookmarks, and scope. These last 3 must be on a per-user basis, and there is currently no support for a single server to deliver these per user. This is why they are disabled in an infocenter. The remote help server is run as a normal infocenter; you do not need to do anything special to make it a remote help server.

Table of contents information is retrieved by consulting the TocServlet of the local server rather than going directly through code. The TocServlet first looks locally, then consults the remote server's TocServlet for additional table of contents entries. The results are then merged by the local server and sent to the client. Supporting tocs contributed by a means other than plugin extensions required the addition of new API - the toc support is in org.eclipse.help and we  cannot have this plugin make assumptions about what happens for remote content for our particular help implementation, so the notion of a new source of tocs, or a tocProvider was added here, and org.eclipse.help.base contributes a provider that gets tocs from the remote help server. This can be thought of as an extra level of indirection and we could even implement the plugin extension toc loader as one of these.

To search, the workbench consults the SearchServlet of the local help server. The servlet then performs two searches in parallel - it searches the local content as would normally happen, and it consults the remote SearchServlet to do the same. Once both sets of results are in, the local SearchServlet sorts them by score and sends them to the client. Thus, again the client does not know whether a result is local or remote, this is handled transparently by the local server.

Index is currently not yet implemented. One way to do this would be to add an IndexServlet and have the local help server find all the local and remote indices and merge them, then present to the user.

The preference page was reworked, but is still not quite right. I favor the simple approach for this - first ask the user whether they have a remote help server. If yes, then enter the hostname and optionally the port. Currently there is a preference page for the local help server, which is used for troubleshooting. If we have to present both of these, it makes the preferences a bit complicated. We need to revisit the exact use cases for needing to configure the local help server - i.e. what can go wrong that we need to use these? Do we really need a preference page for this rare case, or can we use JVM args or some other less-UI-intrusive way?

A few problems have arisen during the investigation of this feature:

- Progress monitoring is difficult for remote content since we don't use RPC. We  could implement this in the servlets by sending special progress data regularly, but I'd have to dig into this a little more.
- Searching dynamic content on the remote server is complicated. We have to first get the "raw" remote results that are unfiltered, but with contributions resolved, then filter the results locally. Currently this is not even done in the local case - i.e. you will get false positives if you search for dynamic content that should only show up on, say, linux, but you're running in windows. Searching remotely also puts a potentially large burden on the infocenter, so I need to investigate whether it's possible to transfer some of this load to the client.

Created attachment 33218
current state of work

The zip contains a patch with all the changes, as well as the source for the affected plugins, since the patch will probably be stale when we revisit this.
Sending back to inbox as it was deferred for 3.2.
*** Bug 146766 has been marked as a duplicate of this bug. ***
*** Bug 41335 has been marked as a duplicate of this bug. ***
A question about requirements for Kari, etc. Would it be an acceptable restriction to not allow a book's content to be split up between the local and remote machine? That is, for any given book, its complete contents (all topics and subtopics) must either be all local or all remote, not mixed local &amp; remote.

I ask because this would affect the complexity of the new API for toc providers. If the requirement is not there then I would rather keep the API clean and simple.
&gt;Would it be an acceptable
&gt;restriction to not allow a book's content to be split up between the local and
&gt;remote machine?

Hmmm. No, that doesn't sound like an acceptable restriction to me. A "Book" (a top-level node, and all its children) can be built from many many contributions from many many plug-ins, owned my many many owners on different projects, and installed potentially at different times. And a book can be re-wired by another doc plug-in's TOC to no longer be on the bookshelf.

This restriction would place incredible restrictions on the installer .. it would have to parse the nav tree before it knew what plug-ins had to be put in the same place. And what if something a user installed later, locally, wired in (with a "link") something that was already installed remotely ... the remote doc plug-in would have to be moved down to the local machine? That doesn't make sense.

Unless I've completely misunderstood what you're saying. If so, sorry, and please re-ask.
I think you understood correctly, I just underestimated how intertwined things can get with large sets of documents. I won't add this restriction.
I'm declaring this one completed for M2. The functionality is now there and working. Any further work (performance, responsiveness, documentation) will be tracked in other bugs and this is now in maintenance mode.

Since there are no docs yet, I'll explain how to set this up.

There are two ways to configure this:

1. Pre-configured out of the box - In the plugin_customization.ini you can change these parameters (with defaults):

org.eclipse.help.base/remoteHelpOn=false
org.eclipse.help.base/remoteHelpHost=
org.eclipse.help.base/remoteHelpPath=/help
org.eclipse.help.base/remoteHelpUseDefaultPort=true
org.eclipse.help.base/remoteHelpPort=80

If not on, then all others ignored. Also if default port is used, port number is ignored. So, for example, if you have an infocenter that you can access at http://myinfocenter.mydomain.com:8081/help/index.jsp, you would use these settings:

org.eclipse.help.base/remoteHelpOn=true
org.eclipse.help.base/remoteHelpHost=myinfocenter.mydomain.com
org.eclipse.help.base/remoteHelpPath=/help
org.eclipse.help.base/remoteHelpUseDefaultPort=false
org.eclipse.help.base/remoteHelpPort=8081

2. Preference page under Help -&gt; Content. You can specify the exact same info as the fields above.

----

On the server side, all you need to do is set up an infocenter as usual. Put whatever docs you want to access remotely on it. That's all you need to do. The infocenter has new servlets that offer web service-style XML content and the client knows how to talk to them. So the infocenter now serves a dual purpose, remote help and infocenter.

Note that you cannot use an old infocenter here, it must be a 3.3 infocenter. Backward compatibility will be maintained so that you will be able to use, say, a 3.4 (or 4.0) workbench with a 3.3 infocenter. You just may not get any of the new features that are available in 3.4 or 4.0.

As far as coverage, it will serve toc, keyword index, content, and context-sensitive help. I have tested NL to ensure that it fetches the content in the correct language from the infocenter, and an infocenter can serve many languages for remote help. Dynamic content should also work; filters, anchor contributions, and includes are processed on the client side and it will request included or contributed content from the remote server when needed. Toc nesting can also work across local/remote, so you can have a local book that wraps a remote toc that wraps yet another local toc.

What I plan to do during M3 is see if we can apply this solution to the eclipse SDK, which would give us much more thorough testing, and we would benefit from the space savings. I am also working on improving the responsiveness of the UI if the remote infocenter or network connection is slow, i.e. show progress instead of being frozen.</WithStack>
    <WithOutStack>Allow documentation content to be installed on one (central) machine, and accessed by multiple Eclipse Workbench clients (on other machines). 

This requirement is based on the need for users to reduce the footprint of what's installed on their development machine; docs can get quite big. Also, documentation updates could be handled centrally, too.

Would need a preference indicating the location of the central docs. Local doc plugins would be ignored (this situation to be covered in another feature request) and so could be not installed.
Note: links from local UA (and other) elements that would normally launch the local help system must now launch the remote help system instead.
*** Bug 122969 has been marked as a duplicate of this bug. ***
Also included in this enhancement:

As a follow-up to enh 122967, allow a user to not only access a centralized
remote help server directly from their workbench, but also to install help
content (doc) plug-ins locally, and have those integrated into the same Help
System view as the remote content.

The scenario is this: developer works for big company who has centralized the
product docs for their developers on a remote server (developers still access
it via Help &gt; Help Contents or links from context help or Welcome). Then the
developer installs a new Eclipse-based tool (and docs) that the other users
aren't using -- wants to see help, but his Eclipse is pointed at the remote
help server.
Deferring to next release due to resource shortage. I will attach the current state of the work as an attachment to this bug. Some notes about the current state of things:

The remote documents are provided by flowing the data through the local help server. The client always requests from the local server (which must be running even if all content is remote), and if the local server does not have the content it consults the remote server. If the remote server has the content, the local server downloads it, filters it, and sends it to the client. Thus, the client workbench does not even know that the content was remote. Another reason for always needing a local help server is that there may be local content, pushing the work of presenting the data and filtering to the client rather than putting a burden on the server, and for the links tab, bookmarks, and scope. These last 3 must be on a per-user basis, and there is currently no support for a single server to deliver these per user. This is why they are disabled in an infocenter. The remote help server is run as a normal infocenter; you do not need to do anything special to make it a remote help server.

Table of contents information is retrieved by consulting the TocServlet of the local server rather than going directly through code. The TocServlet first looks locally, then consults the remote server's TocServlet for additional table of contents entries. The results are then merged by the local server and sent to the client. Supporting tocs contributed by a means other than plugin extensions required the addition of new API - the toc support is in org.eclipse.help and we  cannot have this plugin make assumptions about what happens for remote content for our particular help implementation, so the notion of a new source of tocs, or a tocProvider was added here, and org.eclipse.help.base contributes a provider that gets tocs from the remote help server. This can be thought of as an extra level of indirection and we could even implement the plugin extension toc loader as one of these.

To search, the workbench consults the SearchServlet of the local help server. The servlet then performs two searches in parallel - it searches the local content as would normally happen, and it consults the remote SearchServlet to do the same. Once both sets of results are in, the local SearchServlet sorts them by score and sends them to the client. Thus, again the client does not know whether a result is local or remote, this is handled transparently by the local server.

Index is currently not yet implemented. One way to do this would be to add an IndexServlet and have the local help server find all the local and remote indices and merge them, then present to the user.

The preference page was reworked, but is still not quite right. I favor the simple approach for this - first ask the user whether they have a remote help server. If yes, then enter the hostname and optionally the port. Currently there is a preference page for the local help server, which is used for troubleshooting. If we have to present both of these, it makes the preferences a bit complicated. We need to revisit the exact use cases for needing to configure the local help server - i.e. what can go wrong that we need to use these? Do we really need a preference page for this rare case, or can we use JVM args or some other less-UI-intrusive way?

A few problems have arisen during the investigation of this feature:

- Progress monitoring is difficult for remote content since we don't use RPC. We  could implement this in the servlets by sending special progress data regularly, but I'd have to dig into this a little more.
- Searching dynamic content on the remote server is complicated. We have to first get the "raw" remote results that are unfiltered, but with contributions resolved, then filter the results locally. Currently this is not even done in the local case - i.e. you will get false positives if you search for dynamic content that should only show up on, say, linux, but you're running in windows. Searching remotely also puts a potentially large burden on the infocenter, so I need to investigate whether it's possible to transfer some of this load to the client.

Created attachment 33218
current state of work

The zip contains a patch with all the changes, as well as the source for the affected plugins, since the patch will probably be stale when we revisit this.
Sending back to inbox as it was deferred for 3.2.
*** Bug 146766 has been marked as a duplicate of this bug. ***
*** Bug 41335 has been marked as a duplicate of this bug. ***
A question about requirements for Kari, etc. Would it be an acceptable restriction to not allow a book's content to be split up between the local and remote machine? That is, for any given book, its complete contents (all topics and subtopics) must either be all local or all remote, not mixed local &amp; remote.

I ask because this would affect the complexity of the new API for toc providers. If the requirement is not there then I would rather keep the API clean and simple.
&gt;Would it be an acceptable
&gt;restriction to not allow a book's content to be split up between the local and
&gt;remote machine?

Hmmm. No, that doesn't sound like an acceptable restriction to me. A "Book" (a top-level node, and all its children) can be built from many many contributions from many many plug-ins, owned my many many owners on different projects, and installed potentially at different times. And a book can be re-wired by another doc plug-in's TOC to no longer be on the bookshelf.

This restriction would place incredible restrictions on the installer .. it would have to parse the nav tree before it knew what plug-ins had to be put in the same place. And what if something a user installed later, locally, wired in (with a "link") something that was already installed remotely ... the remote doc plug-in would have to be moved down to the local machine? That doesn't make sense.

Unless I've completely misunderstood what you're saying. If so, sorry, and please re-ask.
I think you understood correctly, I just underestimated how intertwined things can get with large sets of documents. I won't add this restriction.
I'm declaring this one completed for M2. The functionality is now there and working. Any further work (performance, responsiveness, documentation) will be tracked in other bugs and this is now in maintenance mode.

Since there are no docs yet, I'll explain how to set this up.

There are two ways to configure this:

1. Pre-configured out of the box - In the plugin_customization.ini you can change these parameters (with defaults):

org.eclipse.help.base/remoteHelpOn=false
org.eclipse.help.base/remoteHelpHost=
org.eclipse.help.base/remoteHelpPath=/help
org.eclipse.help.base/remoteHelpUseDefaultPort=true
org.eclipse.help.base/remoteHelpPort=80

If not on, then all others ignored. Also if default port is used, port number is ignored. So, for example, if you have an infocenter that you can access at http://myinfocenter.mydomain.com:8081/help/index.jsp, you would use these settings:

org.eclipse.help.base/remoteHelpOn=true
org.eclipse.help.base/remoteHelpHost=myinfocenter.mydomain.com
org.eclipse.help.base/remoteHelpPath=/help
org.eclipse.help.base/remoteHelpUseDefaultPort=false
org.eclipse.help.base/remoteHelpPort=8081

2. Preference page under Help -&gt; Content. You can specify the exact same info as the fields above.

----

On the server side, all you need to do is set up an infocenter as usual. Put whatever docs you want to access remotely on it. That's all you need to do. The infocenter has new servlets that offer web service-style XML content and the client knows how to talk to them. So the infocenter now serves a dual purpose, remote help and infocenter.

Note that you cannot use an old infocenter here, it must be a 3.3 infocenter. Backward compatibility will be maintained so that you will be able to use, say, a 3.4 (or 4.0) workbench with a 3.3 infocenter. You just may not get any of the new features that are available in 3.4 or 4.0.

As far as coverage, it will serve toc, keyword index, content, and context-sensitive help. I have tested NL to ensure that it fetches the content in the correct language from the infocenter, and an infocenter can serve many languages for remote help. Dynamic content should also work; filters, anchor contributions, and includes are processed on the client side and it will request included or contributed content from the remote server when needed. Toc nesting can also work across local/remote, so you can have a local book that wraps a remote toc that wraps yet another local toc.

What I plan to do during M3 is see if we can apply this solution to the eclipse SDK, which would give us much more thorough testing, and we would benefit from the space savings. I am also working on improving the responsiveness of the UI if the remote infocenter or network connection is slow, i.e. show progress instead of being frozen.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122968" />
    <CreationDate amount="2006-01-06 15:41:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="UI" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="trivial" />
    <Summery>[DnD] Rendering problems with new trim on top of window</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="4">
        <Lines>
          <Line>1. Coolbar icons are truncated by perspective switcher (this may not be related to the trim).</Line>
          <Line>2. The white line at the top of the perspective switcher is thicker than the white line at the top of the trim, so it goes (from the left) narrow, thick, then narrow again.</Line>
          <Line>3. There's an extra vertical line about an inch tall drawn next to the progress area.</Line>
          <Line>4. The progress area text doesn't line up with the progress bar and icon.</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="NEW" />
    <resolution amount="" />
    <WithStack>3.2M4
If you move some of the trim up to the top of the workbench window you'll notice some small problems with the way it's rendered. I'll attach a screenshot.
Created attachment 32619
Screenshot of top trim problems.

This is on Windows XP SP2 with a manifest. Problems are labeled as follows in the screenshot:
1. Coolbar icons are truncated by perspective switcher (this may not be related to the trim).
2. The white line at the top of the perspective switcher is thicker than the white line at the top of the trim, so it goes (from the left) narrow, thick, then narrow again.
3. There's an extra vertical line about an inch tall drawn next to the progress area.
4. The progress area text doesn't line up with the progress bar and icon.

Thanks Ed, I'll keep this screenshot around to refer to. The top trim area is currently being reviewed by our Design folks to determine what we should do about it but this gives me something tangible to look out for during the implementation. More on this after I've met with them...

BTW, item #1 is indeed part of the CBanner layout, not the trim (but it's still something that'll have to be addressed in any refactoring...;-).



Most of these issues have been 'solved' by allowing ragged trim (i.e. not forcing all trim to the maximum height...).</WithStack>
    <WithOutStack>3.2M4
If you move some of the trim up to the top of the workbench window you'll notice some small problems with the way it's rendered. I'll attach a screenshot.
Created attachment 32619
Screenshot of top trim problems.

This is on Windows XP SP2 with a manifest. Problems are labeled as follows in the screenshot:
1. Coolbar icons are truncated by perspective switcher (this may not be related to the trim).
2. The white line at the top of the perspective switcher is thicker than the white line at the top of the trim, so it goes (from the left) narrow, thick, then narrow again.
3. There's an extra vertical line about an inch tall drawn next to the progress area.
4. The progress area text doesn't line up with the progress bar and icon.

Thanks Ed, I'll keep this screenshot around to refer to. The top trim area is currently being reviewed by our Design folks to determine what we should do about it but this gives me something tangible to look out for during the implementation. More on this after I've met with them...

BTW, item #1 is indeed part of the CBanner layout, not the trim (but it's still something that'll have to be addressed in any refactoring...;-).



Most of these issues have been 'solved' by allowing ragged trim (i.e. not forcing all trim to the maximum height...).</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122969" />
    <CreationDate amount="2006-01-06 15:42:00 -0500" />
    <DupId amount="122967" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="User Assistance" />
    <Version amount="3.2" />
    <rep_platform amount="All" />
    <op_sys amount="All" />
    <priority amount="P3" />
    <bug_severity amount="enhancement" />
    <Summery>[Help] Mixed remote/local help system contents</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="DUPLICATE" />
    <WithStack>As a follow-up to enh 122967, allow a user to not only access a centralized remote help server directly from their workbench, but also to install help content (doc) plug-ins locally, and have those integrated into the same Help System view as the remote content.

The scenario is this: developer works for big company who has centralized the product docs for their developers on a remote server (developers still access it via Help &gt; Help Contents or links from context help or Welcome). Then the developer installs a new Eclipse-based tool (and docs) that the other users aren't using -- wants to see help, but his Eclipse is pointed at the remote help server.
If the local installation and the remote help server both contain a given help resource (could be different versions), which one should take precedence?
UA team has decided that we will not deliver remote help without this mixed enhancement with it. So rather than have two enhancements, I will combine them into one for easier tracking.

*** This bug has been marked as a duplicate of 122967 ***</WithStack>
    <WithOutStack>As a follow-up to enh 122967, allow a user to not only access a centralized remote help server directly from their workbench, but also to install help content (doc) plug-ins locally, and have those integrated into the same Help System view as the remote content.

The scenario is this: developer works for big company who has centralized the product docs for their developers on a remote server (developers still access it via Help &gt; Help Contents or links from context help or Welcome). Then the developer installs a new Eclipse-based tool (and docs) that the other users aren't using -- wants to see help, but his Eclipse is pointed at the remote help server.
If the local installation and the remote help server both contain a given help resource (could be different versions), which one should take precedence?
UA team has decided that we will not deliver remote help without this mixed enhancement with it. So rather than have two enhancements, I will combine them into one for easier tracking.

*** This bug has been marked as a duplicate of 122967 ***</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122970" />
    <CreationDate amount="2006-01-06 15:43:00 -0500" />
    <DupId amount="" />
    <classification amount="Modeling" />
    <Product amount="GMF-Runtime" />
    <component amount="General" />
    <Version amount="1.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Typo in diagram.ui.properties plugin.xml section ID</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>&lt;propertySection tab="property.tab.RulerGridPropertySection" 
filter="org.eclipse.gmf.runtime.diagram.ui.properties.filters.EditPartPropertySectionFilter" 
class="org.eclipse.gmf.runtime.diagram.ui.properties.sections.grid.RulerGridPropertySection" 
id="property.section.DiagramColorsAndFontsPropertySection"&gt;

The last line should be:

id="property.section.RulerGridPropertySection"&gt;
Created attachment 32620
patch for Diagram UI properties incorrect section ID
Committed changes
[GMF Restructure] Bug 319140 : product GMF and component
Runtime Diagram was the original product and component for this bug</WithStack>
    <WithOutStack>&lt;propertySection tab="property.tab.RulerGridPropertySection" 
filter="org.eclipse.gmf.runtime.diagram.ui.properties.filters.EditPartPropertySectionFilter" 
class="org.eclipse.gmf.runtime.diagram.ui.properties.sections.grid.RulerGridPropertySection" 
id="property.section.DiagramColorsAndFontsPropertySection"&gt;

The last line should be:

id="property.section.RulerGridPropertySection"&gt;
Created attachment 32620
patch for Diagram UI properties incorrect section ID
Committed changes
[GMF Restructure] Bug 319140 : product GMF and component
Runtime Diagram was the original product and component for this bug</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122971" />
    <CreationDate amount="2006-01-06 15:44:00 -0500" />
    <DupId amount="" />
    <classification amount="Tools" />
    <Product amount="TPTP Release Engineering" />
    <component amount="TPTP.Testing" />
    <Version amount="4.2" />
    <rep_platform amount="PC" />
    <op_sys amount="All" />
    <priority amount="P3" />
    <bug_severity amount="enhancement" />
    <Summery>test automation enhancement , do not restart RAC if config item is set.</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Navid asked me to add this enhancement request.

I would like the test automation framework to not try to start a server if this is what the user would like.

Working in this manner we could be debugging the RAC or new agent controller and the automation framework would be communicating with the server we were debugging.

In the current model the test automation framework depends on the RAC not running when a test is started.
Please reassign this bug to me. thanks.
Fixed in HEAD
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithStack>
    <WithOutStack>Navid asked me to add this enhancement request.

I would like the test automation framework to not try to start a server if this is what the user would like.

Working in this manner we could be debugging the RAC or new agent controller and the automation framework would be communicating with the server we were debugging.

In the current model the test automation framework depends on the RAC not running when a test is started.
Please reassign this bug to me. thanks.
Fixed in HEAD
As of TPTP 4.6.0, TPTP is in maintenance mode and focusing on improving quality by resolving relevant enhancements/defects and increasing test coverage through test creation, automation, Build Verification Tests (BVTs), and expanded run-time execution. As part of the TPTP Bugzilla housecleaning process (see http://wiki.eclipse.org/Bugzilla_Housecleaning_Processes), this enhancement/defect is verified/closed by the Project Lead since this enhancement/defect has been resolved and unverified for more than 1 year and considered to be fixed. If this enhancement/defect is still unresolved and reproducible in the latest TPTP release (http://www.eclipse.org/tptp/home/downloads/), please re-open.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122972" />
    <CreationDate amount="2006-01-06 15:51:00 -0500" />
    <DupId amount="" />
    <classification amount="WebTools" />
    <Product amount="WTP Source Editing" />
    <component amount="wst.html" />
    <Version amount="unspecified" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="enhancement" />
    <Summery>[content model] Properties View: allow addition of custom properties</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="WONTFIX" />
    <WithStack>It would be nice if in the Properties view you could add a custom property (and value) to the selected resource.  This may not make as much sense for all resources, but when editing a file in the editor, it would be very useful.  Currently, if you add a custom attribute to a specific tag in an HTML file (for example), it will show in the Properties View, but it would be nice to be able to do this in the properties view directly.
Kirk, did you have a specific place for this to be added?  Your citing of HTML wouldn't be very helpful as all of the valid attributes should already be shown to you at all times.
Isn't it common to use custom attributes for known or custom tags?  Maybe this is moreso in JSP than HTML, but I think it's pretty common.  
reassigning to inbox
It is with JSPs, but the TLD being used would say what those attributes would be.
Vote to resolve as will not impliment, bug has gone idle and as per the conversation in the comments the utility of this does not seem prevalent.  At the very least this would be an enhancement request.
If people find themselves using a certain set of attributes consistently, they can always add them through model query extensions.
No plans to implement.</WithStack>
    <WithOutStack>It would be nice if in the Properties view you could add a custom property (and value) to the selected resource.  This may not make as much sense for all resources, but when editing a file in the editor, it would be very useful.  Currently, if you add a custom attribute to a specific tag in an HTML file (for example), it will show in the Properties View, but it would be nice to be able to do this in the properties view directly.
Kirk, did you have a specific place for this to be added?  Your citing of HTML wouldn't be very helpful as all of the valid attributes should already be shown to you at all times.
Isn't it common to use custom attributes for known or custom tags?  Maybe this is moreso in JSP than HTML, but I think it's pretty common.  
reassigning to inbox
It is with JSPs, but the TLD being used would say what those attributes would be.
Vote to resolve as will not impliment, bug has gone idle and as per the conversation in the comments the utility of this does not seem prevalent.  At the very least this would be an enhancement request.
If people find themselves using a certain set of attributes consistently, they can always add them through model query extensions.
No plans to implement.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122973" />
    <CreationDate amount="2006-01-06 15:55:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="PDE" />
    <component amount="UI" />
    <Version amount="3.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>PDE editors insert SPACE chars for indentation, does not use existing tabs</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="NEW" />
    <resolution amount="" />
    <WithStack>My plugin.xml file uses the TAB character for intendation. If I create a new key under an extension point, the PDE editor inserts 2 space characters for TABs, and even considering this it uses the wrong indentation levels.

For example, under:
/t&lt;extension point = '....&gt;
/t/t&lt;key existing keybinding definition/&gt;
/t&lt;/extension&gt;

It inserts:
  &lt;key
        attributes/&gt;

Key should be indented twice because its parent is indented once. The source manipulation should use probing to preserve the existing document formatting, or it should be a UI preference.
*** Bug 278960 has been marked as a duplicate of this bug. ***</WithStack>
    <WithOutStack>My plugin.xml file uses the TAB character for intendation. If I create a new key under an extension point, the PDE editor inserts 2 space characters for TABs, and even considering this it uses the wrong indentation levels.

For example, under:
/t&lt;extension point = '....&gt;
/t/t&lt;key existing keybinding definition/&gt;
/t&lt;/extension&gt;

It inserts:
  &lt;key
        attributes/&gt;

Key should be indented twice because its parent is indented once. The source manipulation should use probing to preserve the existing document formatting, or it should be a UI preference.
*** Bug 278960 has been marked as a duplicate of this bug. ***</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122974" />
    <CreationDate amount="2006-01-06 16:10:00 -0500" />
    <DupId amount="" />
    <classification amount="WebTools" />
    <Product amount="WTP Java EE Tools" />
    <component amount="jst.j2ee" />
    <Version amount="1.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P2" />
    <bug_severity amount="critical" />
    <Summery>ProjectModule on a web utility module does not return the classes as member</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="2">
      <source_code type="assignment">
        <location start="356" end="451" />
        <code>ProjectModule projModule = (ProjectModule)utilityModule.loadAdapter(ProjectModule.class, null);</code>
      </source_code>
      <source_code type="assignment">
        <location start="452" end="505" />
        <code>IModuleResources[] members = projectModule.members();</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>For a given IModule that represents a utility jar in a Web module (i.e. the IModule[] that returns from the IWebModule.getModules()), the ProjectModule failed to return the containing classes when the ProjectModule.members() method is called.

e.g. if "utilityModule" is an instance of IModule that gets returns from IWebModule.getModules(), then, I call:
ProjectModule projModule = (ProjectModule)utilityModule.loadAdapter(ProjectModule.class, null);
IModuleResources[] members = projectModule.members();

None of the classes that are stored in the web utility module are returned as the "members".

This causes any utility jar publish to fail for servers that supports web utility jars.
Added to 1.0.1 Hot List at the request of Elson. Set priority to P2.
Fixed in 1/9 build
Closing.</WithStack>
    <WithOutStack>For a given IModule that represents a utility jar in a Web module (i.e. the IModule[] that returns from the IWebModule.getModules()), the ProjectModule failed to return the containing classes when the ProjectModule.members() method is called.

e.g. if "utilityModule" is an instance of IModule that gets returns from IWebModule.getModules(), then, I call:
ProjectModule projModule = (ProjectModule)utilityModule.loadAdapter(ProjectModule.class, null);
IModuleResources[] members = projectModule.members();

None of the classes that are stored in the web utility module are returned as the "members".

This causes any utility jar publish to fail for servers that supports web utility jars.
Added to 1.0.1 Hot List at the request of Elson. Set priority to P2.
Fixed in 1/9 build
Closing.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122975" />
    <CreationDate amount="2006-01-06 16:16:00 -0500" />
    <DupId amount="121444" />
    <classification amount="WebTools" />
    <Product amount="WTP Java EE Tools" />
    <component amount="jst.j2ee" />
    <Version amount="1.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="critical" />
    <Summery>The files wich hold same name as subfolder are not published  when deploying</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="DUPLICATE" />
    <WithStack>If a folder contains a file and a subfolder with same name the file is not copied to the deployment target.

Example:
file 'foo.js'
folder 'foo'
Looks like a duplicate.
This is fixed by defect 121444 for WTP 1.0.1 builds.

*** This bug has been marked as a duplicate of 121444 ***
verified 20060925
Closing.</WithStack>
    <WithOutStack>If a folder contains a file and a subfolder with same name the file is not copied to the deployment target.

Example:
file 'foo.js'
folder 'foo'
Looks like a duplicate.
This is fixed by defect 121444 for WTP 1.0.1 builds.

*** This bug has been marked as a duplicate of 121444 ***
verified 20060925
Closing.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122976" />
    <CreationDate amount="2006-01-06 16:16:00 -0500" />
    <DupId amount="121761" />
    <classification amount="DataTools" />
    <Product amount="Data Tools" />
    <component amount="Connectivity" />
    <Version amount="0.7" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>SQLModelContentExtension listener  sends request to Non-DB Connection Profiles</Summery>
    <Patches amount="0" />
    <Stacktraces amount="1">
      <Stacktrace timestamp="1437330631601">
        <Exception>java.lang.NullPointerException</Exception>
        <Reason>atorg.eclipse.datatools.connectivity.internal.ConnectionProfile.createConnection(ConnectionProfile.java:298)</Reason>
        <Frames>
          <Frame depth="0">org.eclipse.datatools.connectivity.ui.ContentExtensionFactoryBase.openConnection(ContentExtensionFactoryBase.java:42)</Frame>
          <Frame depth="1">org.eclipse.datatools.connectivity.db.generic.SQLModelContentExtension.openConnection(SQLModelContentExtension.java:36)</Frame>
          <Frame depth="2">org.eclipse.datatools.connectivity.ui.ContentExtensionBase$1.openConnection(ContentExtensionBase.java:37)</Frame>
          <Frame depth="3">org.eclipse.datatools.connectivity.internal.ConnectionProfile$ConnectJob.run(ConnectionProfile.java:545)</Frame>
          <Frame depth="4">org.eclipse.core.internal.jobs.Worker.run(Worker.java:76)</Frame>
        </Frames>
      </Stacktrace>
    </Stacktraces>
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="DUPLICATE" />
    <WithStack>The SQLModelContentExtension listener seems to be requesting a non-DB connection profile (e.g. the ODA Connection Profile) to create connection for "java.sql.Connection".
This leads to a NPE since the ODA connection profile does not provide a factory for java.sql.Connection.  See error log below.

This happens when using the M2 DSE, creates an ODA CVS FlatFile profile, and selects "Connect" on the profile's context menu.

It could be due to the filter used for the SQL model content extension is not
filtering out non-DB connection profiles.


!MESSAGE An internal error occurred during: "Creating connections to myOdaFFProfile.".
!STACK 0
java.lang.NullPointerException
atorg.eclipse.datatools.connectivity.internal.ConnectionProfile.createConnection(ConnectionProfile.java:298)
             at
org.eclipse.datatools.connectivity.ui.ContentExtensionFactoryBase.openConnection(ContentExtensionFactoryBase.java:42)
             at
org.eclipse.datatools.connectivity.db.generic.SQLModelContentExtension.openConnection(SQLModelContentExtension.java:36)
             at
org.eclipse.datatools.connectivity.ui.ContentExtensionBase$1.openConnection(ContentExtensionBase.java:37)
             at
org.eclipse.datatools.connectivity.internal.ConnectionProfile$ConnectJob.run(ConnectionProfile.java:545)
             at org.eclipse.core.internal.jobs.Worker.run(Worker.java:76)
Looks like a duplicate of 121761
Linda, this should be fixed by my changes to fix 121761. Can you give it a shot and see if the ODA problem is fixed?
Yes, it works now with the latest source.  There is no longer a NPE when "Connect" is selected on an ODA connection profile instance. 
Thanks.

I'll mark this resolved as a duplicate of 121761.

*** This bug has been marked as a duplicate of 121761 ***
Verified.</WithStack>
    <WithOutStack>The SQLModelContentExtension listener seems to be requesting a non-DB connection profile (e.g. the ODA Connection Profile) to create connection for "java.sql.Connection".
This leads to a NPE since the ODA connection profile does not provide a factory for java.sql.Connection.  See error log below.

This happens when using the M2 DSE, creates an ODA CVS FlatFile profile, and selects "Connect" on the profile's context menu.

It could be due to the filter used for the SQL model content extension is not
filtering out non-DB connection profiles.


!MESSAGE An internal error occurred during: "Creating connections to myOdaFFProfile.".
!STACK 0

Looks like a duplicate of 121761
Linda, this should be fixed by my changes to fix 121761. Can you give it a shot and see if the ODA problem is fixed?
Yes, it works now with the latest source.  There is no longer a NPE when "Connect" is selected on an ODA connection profile instance. 
Thanks.

I'll mark this resolved as a duplicate of 121761.

*** This bug has been marked as a duplicate of 121761 ***
Verified.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122977" />
    <CreationDate amount="2006-01-06 16:21:00 -0500" />
    <DupId amount="" />
    <classification amount="Modeling" />
    <Product amount="EMF" />
    <component amount="XML/XMI" />
    <Version amount="2.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Missing Schema for a Root EObject Causes NPE in XMLHandler</Summery>
    <Patches amount="0" />
    <Stacktraces amount="1">
      <Stacktrace timestamp="1437330631601">
        <Exception>java.lang.NullPointerException</Exception>
        <Reason />
        <Frames>
          <Frame depth="0">org.eclipse.emf.ecore.xmi.impl.XMLHandler.processTopObject(XMLHandler.java:816)</Frame>
          <Frame depth="1">org.eclipse.emf.ecore.xmi.impl.XMLHandler.createObjectByType(XMLHandler.java:747)</Frame>
          <Frame depth="2">org.eclipse.emf.ecore.xmi.impl.XMLHandler.createTopObject(XMLHandler.java:779)</Frame>
          <Frame depth="3">org.eclipse.emf.ecore.xmi.impl.XMLHandler.processElement(XMLHandler.java:462)</Frame>
          <Frame depth="4">org.eclipse.emf.ecore.xmi.impl.XMIHandler.processElement(XMIHandler.java:65)</Frame>
          <Frame depth="5">org.eclipse.emf.ecore.xmi.impl.XMLHandler.startElement(XMLHandler.java:449)</Frame>
          <Frame depth="6">org.eclipse.emf.ecore.xmi.impl.SAXWrapper.startElement(SAXWrapper.java:73)</Frame>
          <Frame depth="7">org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)</Frame>
          <Frame depth="8">org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanStartElement(Unknown Source)</Frame>
          <Frame depth="9">org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)</Frame>
          <Frame depth="10">org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)</Frame>
          <Frame depth="11">org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)</Frame>
          <Frame depth="12">org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)</Frame>
          <Frame depth="13">org.apache.xerces.parsers.XMLParser.parse(Unknown Source)</Frame>
          <Frame depth="14">org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)</Frame>
          <Frame depth="15">javax.xml.parsers.SAXParser.parse(Unknown Source)</Frame>
          <Frame depth="16">org.eclipse.emf.ecore.xmi.impl.XMLLoadImpl.load(XMLLoadImpl.java:140)</Frame>
          <Frame depth="17">org.eclipse.emf.ecore.xmi.impl.XMLResourceImpl.doLoad(XMLResourceImpl.java:169)</Frame>
          <Frame depth="18">org.eclipse.emf.ecore.resource.impl.ResourceImpl.load(ResourceImpl.java:988)</Frame>
          <Frame depth="19">org.eclipse.emf.ecore.resource.impl.ResourceImpl.load(ResourceImpl.java:832)</Frame>
          <Frame depth="20">org.eclipse.emf.examples.extlibrary.presentation.EXTLibraryEditor.createModel(EXTLibraryEditor.java:744)</Frame>
          <Frame depth="21">org.eclipse.emf.examples.extlibrary.presentation.EXTLibraryEditor.createPages(EXTLibraryEditor.java:760)</Frame>
          <Frame depth="22">org.eclipse.ui.part.MultiPageEditorPart.createPartControl(MultiPageEditorPart.java:241)</Frame>
          <Frame depth="23">org.eclipse.ui.internal.EditorReference.createPartHelper(EditorReference.java:609)</Frame>
          <Frame depth="24">org.eclipse.ui.internal.EditorReference.createPart(EditorReference.java:384)</Frame>
          <Frame depth="25">org.eclipse.ui.internal.WorkbenchPartReference.getPart(WorkbenchPartReference.java(Compiled Code))</Frame>
          <Frame depth="26">org.eclipse.ui.internal.PartPane.setVisible(PartPane.java:283)</Frame>
          <Frame depth="27">org.eclipse.ui.internal.presentations.PresentablePart.setVisible(PresentablePart.java:126)</Frame>
          <Frame depth="28">org.eclipse.ui.internal.presentations.util.PresentablePartFolder.select(PresentablePartFolder.java:268)</Frame>
          <Frame depth="29">org.eclipse.ui.internal.presentations.util.LeftToRightTabOrder.select(LeftToRightTabOrder.java:65)</Frame>
          <Frame depth="30">org.eclipse.ui.internal.presentations.util.TabbedStackPresentation.selectPart(TabbedStackPresentation.java:391)</Frame>
          <Frame depth="31">org.eclipse.ui.internal.PartStack.refreshPresentationSelection(PartStack.java:1102)</Frame>
          <Frame depth="32">org.eclipse.ui.internal.PartStack.setSelection(PartStack.java:1051)</Frame>
          <Frame depth="33">org.eclipse.ui.internal.PartStack.showPart(PartStack.java:1256)</Frame>
          <Frame depth="34">org.eclipse.ui.internal.PartStack.add(PartStack.java:442)</Frame>
          <Frame depth="35">org.eclipse.ui.internal.EditorStack.add(EditorStack.java:109)</Frame>
          <Frame depth="36">org.eclipse.ui.internal.EditorSashContainer.addEditor(EditorSashContainer.java:60)</Frame>
          <Frame depth="37">org.eclipse.ui.internal.EditorAreaHelper.addToLayout(EditorAreaHelper.java:212)</Frame>
          <Frame depth="38">org.eclipse.ui.internal.EditorAreaHelper.addEditor(EditorAreaHelper.java:202)</Frame>
          <Frame depth="39">org.eclipse.ui.internal.EditorManager.createEditorTab(EditorManager.java:758)</Frame>
          <Frame depth="40">org.eclipse.ui.internal.EditorManager.openEditorFromDescriptor(EditorManager.java:665)</Frame>
          <Frame depth="41">org.eclipse.ui.internal.EditorManager.openEditor(EditorManager.java:628)</Frame>
          <Frame depth="42">org.eclipse.ui.internal.WorkbenchPage.busyOpenEditorBatched(WorkbenchPage.java:2360)</Frame>
          <Frame depth="43">org.eclipse.ui.internal.WorkbenchPage.busyOpenEditor(WorkbenchPage.java:2295)</Frame>
          <Frame depth="44">org.eclipse.ui.internal.WorkbenchPage.access$9(WorkbenchPage.java:2287)</Frame>
          <Frame depth="45">org.eclipse.ui.internal.WorkbenchPage$9.run(WorkbenchPage.java:2273)</Frame>
          <Frame depth="46">org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:69)</Frame>
          <Frame depth="47">org.eclipse.ui.internal.WorkbenchPage.openEditor(WorkbenchPage.java:2268)</Frame>
          <Frame depth="48">org.eclipse.ui.actions.OpenWithMenu.openEditor(OpenWithMenu.java:279)</Frame>
          <Frame depth="49">org.eclipse.ui.actions.OpenWithMenu.access$0(OpenWithMenu.java:271)</Frame>
          <Frame depth="50">org.eclipse.ui.actions.OpenWithMenu$2.handleEvent(OpenWithMenu.java:178)</Frame>
          <Frame depth="51">org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java(Compiled Code))</Frame>
          <Frame depth="52">org.eclipse.swt.widgets.Widget.sendEvent(Widget.java(Inlined Compiled Code))</Frame>
          <Frame depth="53">org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java(Compiled Code))</Frame>
          <Frame depth="54">org.eclipse.swt.widgets.Display.readAndDispatch(Display.java(Compiled Code))</Frame>
          <Frame depth="55">org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java(Compiled Code))</Frame>
          <Frame depth="56">org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1663)</Frame>
          <Frame depth="57">org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:367)</Frame>
          <Frame depth="58">org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:143)</Frame>
          <Frame depth="59">org.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:103)</Frame>
          <Frame depth="60">org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:226)</Frame>
          <Frame depth="61">org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:376)</Frame>
          <Frame depth="62">org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:163)</Frame>
          <Frame depth="63">sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</Frame>
          <Frame depth="64">sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:85)</Frame>
          <Frame depth="65">sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:58)</Frame>
          <Frame depth="66">sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:60)</Frame>
          <Frame depth="67">java.lang.reflect.Method.invoke(Method.java:391)</Frame>
          <Frame depth="68">org.eclipse.core.launcher.Main.invokeFramework(Main.java:334)</Frame>
          <Frame depth="69">org.eclipse.core.launcher.Main.basicRun(Main.java:278)</Frame>
          <Frame depth="70">org.eclipse.core.launcher.Main.run(Main.java:973)</Frame>
          <Frame depth="71">org.eclipse.core.launcher.Main.main(Main.java:948)</Frame>
        </Frames>
      </Stacktrace>
    </Stacktraces>
    <SourceCodeRegions amount="1">
      <source_code type="functiondef">
        <location start="60" end="156" />
        <code>resource = new XMIResourceImpl(uri) {
     protected boolean useUUIDs() {
	return true;
     }
}</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="INVALID" />
    <WithStack>I am using a simple subclass of XMIResourceImpl as follows:
resource = new XMIResourceImpl(uri) {
     protected boolean useUUIDs() {
	return true;
     }
};

Instances of the subclass are constructed in a resource factory registered against the "extlibrary" extension. The default load options of the resource are appending with "XMLResource.OPTION_RECORD_UNKNOWN_FEATURE, Boolean.TRUE" to preserve unrecognized content when making changes to the resource.

Attached to this bugzilla is the xml file that I am trying to load. It contains two roots from two different metamodels. The second root belongs to a metamodel schema that is not available.

After attempting to load the file in the EXTLibrary example editor produces an NPE while attempting to load:

java.lang.NullPointerException
	at org.eclipse.emf.ecore.xmi.impl.XMLHandler.processTopObject(XMLHandler.java:816)
	at org.eclipse.emf.ecore.xmi.impl.XMLHandler.createObjectByType(XMLHandler.java:747)
	at org.eclipse.emf.ecore.xmi.impl.XMLHandler.createTopObject(XMLHandler.java:779)
	at org.eclipse.emf.ecore.xmi.impl.XMLHandler.processElement(XMLHandler.java:462)
	at org.eclipse.emf.ecore.xmi.impl.XMIHandler.processElement(XMIHandler.java:65)
	at org.eclipse.emf.ecore.xmi.impl.XMLHandler.startElement(XMLHandler.java:449)
	at org.eclipse.emf.ecore.xmi.impl.SAXWrapper.startElement(SAXWrapper.java:73)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at javax.xml.parsers.SAXParser.parse(Unknown Source)
	at org.eclipse.emf.ecore.xmi.impl.XMLLoadImpl.load(XMLLoadImpl.java:140)
	at org.eclipse.emf.ecore.xmi.impl.XMLResourceImpl.doLoad(XMLResourceImpl.java:169)
	at org.eclipse.emf.ecore.resource.impl.ResourceImpl.load(ResourceImpl.java:988)
	at org.eclipse.emf.ecore.resource.impl.ResourceImpl.load(ResourceImpl.java:832)
	at org.eclipse.emf.examples.extlibrary.presentation.EXTLibraryEditor.createModel(EXTLibraryEditor.java:744)
	at org.eclipse.emf.examples.extlibrary.presentation.EXTLibraryEditor.createPages(EXTLibraryEditor.java:760)
	at org.eclipse.ui.part.MultiPageEditorPart.createPartControl(MultiPageEditorPart.java:241)
	at org.eclipse.ui.internal.EditorReference.createPartHelper(EditorReference.java:609)
	at org.eclipse.ui.internal.EditorReference.createPart(EditorReference.java:384)
	at org.eclipse.ui.internal.WorkbenchPartReference.getPart(WorkbenchPartReference.java(Compiled Code))
	at org.eclipse.ui.internal.PartPane.setVisible(PartPane.java:283)
	at org.eclipse.ui.internal.presentations.PresentablePart.setVisible(PresentablePart.java:126)
	at org.eclipse.ui.internal.presentations.util.PresentablePartFolder.select(PresentablePartFolder.java:268)
	at org.eclipse.ui.internal.presentations.util.LeftToRightTabOrder.select(LeftToRightTabOrder.java:65)
	at org.eclipse.ui.internal.presentations.util.TabbedStackPresentation.selectPart(TabbedStackPresentation.java:391)
	at org.eclipse.ui.internal.PartStack.refreshPresentationSelection(PartStack.java:1102)
	at org.eclipse.ui.internal.PartStack.setSelection(PartStack.java:1051)
	at org.eclipse.ui.internal.PartStack.showPart(PartStack.java:1256)
	at org.eclipse.ui.internal.PartStack.add(PartStack.java:442)
	at org.eclipse.ui.internal.EditorStack.add(EditorStack.java:109)
	at org.eclipse.ui.internal.EditorSashContainer.addEditor(EditorSashContainer.java:60)
	at org.eclipse.ui.internal.EditorAreaHelper.addToLayout(EditorAreaHelper.java:212)
	at org.eclipse.ui.internal.EditorAreaHelper.addEditor(EditorAreaHelper.java:202)
	at org.eclipse.ui.internal.EditorManager.createEditorTab(EditorManager.java:758)
	at org.eclipse.ui.internal.EditorManager.openEditorFromDescriptor(EditorManager.java:665)
	at org.eclipse.ui.internal.EditorManager.openEditor(EditorManager.java:628)
	at org.eclipse.ui.internal.WorkbenchPage.busyOpenEditorBatched(WorkbenchPage.java:2360)
	at org.eclipse.ui.internal.WorkbenchPage.busyOpenEditor(WorkbenchPage.java:2295)
	at org.eclipse.ui.internal.WorkbenchPage.access$9(WorkbenchPage.java:2287)
	at org.eclipse.ui.internal.WorkbenchPage$9.run(WorkbenchPage.java:2273)
	at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:69)
	at org.eclipse.ui.internal.WorkbenchPage.openEditor(WorkbenchPage.java:2268)
	at org.eclipse.ui.actions.OpenWithMenu.openEditor(OpenWithMenu.java:279)
	at org.eclipse.ui.actions.OpenWithMenu.access$0(OpenWithMenu.java:271)
	at org.eclipse.ui.actions.OpenWithMenu$2.handleEvent(OpenWithMenu.java:178)
	at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java(Compiled Code))
	at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java(Inlined Compiled Code))
	at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java(Compiled Code))
	at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java(Compiled Code))
	at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java(Compiled Code))
	at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:1663)
	at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:367)
	at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:143)
	at org.eclipse.ui.internal.ide.IDEApplication.run(IDEApplication.java:103)
	at org.eclipse.core.internal.runtime.PlatformActivator$1.run(PlatformActivator.java:226)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:376)
	at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:163)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:58)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:60)
	at java.lang.reflect.Method.invoke(Method.java:391)
	at org.eclipse.core.launcher.Main.invokeFramework(Main.java:334)
	at org.eclipse.core.launcher.Main.basicRun(Main.java:278)
	at org.eclipse.core.launcher.Main.run(Main.java:973)
	at org.eclipse.core.launcher.Main.main(Main.java:948)

Expected Result:
The resource loads with no exceptions and the extension map is populated so that all of the extra data can be serialized whenever the resource is saved.
Created attachment 32622
Artifact that produces the NPE
Created attachment 32623
Fixed up the attachment.
I can't reproduce this bug in 2.2 nor in 2.1.2. Since these are concequent releases I am marking this bug is invalid. 
Thank you.</WithStack>
    <WithOutStack>I am using a simple subclass of XMIResourceImpl as follows:
resource = new XMIResourceImpl(uri) {
     protected boolean useUUIDs() {
	return true;
     }
};

Instances of the subclass are constructed in a resource factory registered against the "extlibrary" extension. The default load options of the resource are appending with "XMLResource.OPTION_RECORD_UNKNOWN_FEATURE, Boolean.TRUE" to preserve unrecognized content when making changes to the resource.

Attached to this bugzilla is the xml file that I am trying to load. It contains two roots from two different metamodels. The second root belongs to a metamodel schema that is not available.

After attempting to load the file in the EXTLibrary example editor produces an NPE while attempting to load:



Expected Result:
The resource loads with no exceptions and the extension map is populated so that all of the extra data can be serialized whenever the resource is saved.
Created attachment 32622
Artifact that produces the NPE
Created attachment 32623
Fixed up the attachment.
I can't reproduce this bug in 2.2 nor in 2.1.2. Since these are concequent releases I am marking this bug is invalid. 
Thank you.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122978" />
    <CreationDate amount="2006-01-06 16:32:00 -0500" />
    <DupId amount="" />
    <classification amount="Modeling" />
    <Product amount="EMF" />
    <component amount="XML/XMI" />
    <Version amount="2.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="enhancement" />
    <Summery>XMIResourceImpl Loses the NameSpace Prefix While Preserving Unrecognized Features</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="1">
      <source_code type="functiondef">
        <location start="60" end="163" />
        <code>resource = new XMIResourceImpl(uri) {
     protected boolean useUUIDs() {
        return true;
     }
}</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="WONTFIX" />
    <WithStack>I am using a simple subclass of XMIResourceImpl as follows:
resource = new XMIResourceImpl(uri) {
     protected boolean useUUIDs() {
        return true;
     }
};

Instances of the subclass are constructed in a resource factory registered
against the "extlibrary" extension. The default load options of the resource
are appending with "XMLResource.OPTION_RECORD_UNKNOWN_FEATURE, Boolean.TRUE" to
preserve unrecognized content when making changes to the resource.

Attached to this bugzilla is the xml file that I am trying to save. I make some simple modifications to the resource and resave it. All of the unrecognized data seems to be preserved except all of the namespace prefixes are changed from "ecore:" to "_:"

Although this does not seem to prevent the resource from loading (because the namespace prefix is used consistently throughout the xml) it is an unwanted change and does not reflect the nsPrefix defined in the EPackage.
Created attachment 32624
Artifact that caused the problem
In general, prefixes are not guaranteed to be preserved in a namespace aware application, so it is not a bug but an enchancement request. Since older point releases can only include critical bug fixes, this behavior will remain the same in 2.1.x stream.

Therefore, for now I am changing the target release and severity from normal to enchancement.
Please provide a test case that demostrates the problem - i.e. Java main/JUnit that shows the modifications you make to the file. After I evaluate the test case I will be able to tell you if behavior of EMF can be improved to preserve prefixes or not.



I'm going to return this because the particular example works if you use the proper Ecore namespace, i.e., "http://www.eclipse.org/emf/2002/Ecore", rather than "http://www.eclipse.org/emf/2002/Ecore2" as in the example.

Since prefixes are not recorded anywhere, you can't generally expect prefixes themselves to be preserved.</WithStack>
    <WithOutStack>I am using a simple subclass of XMIResourceImpl as follows:
resource = new XMIResourceImpl(uri) {
     protected boolean useUUIDs() {
        return true;
     }
};

Instances of the subclass are constructed in a resource factory registered
against the "extlibrary" extension. The default load options of the resource
are appending with "XMLResource.OPTION_RECORD_UNKNOWN_FEATURE, Boolean.TRUE" to
preserve unrecognized content when making changes to the resource.

Attached to this bugzilla is the xml file that I am trying to save. I make some simple modifications to the resource and resave it. All of the unrecognized data seems to be preserved except all of the namespace prefixes are changed from "ecore:" to "_:"

Although this does not seem to prevent the resource from loading (because the namespace prefix is used consistently throughout the xml) it is an unwanted change and does not reflect the nsPrefix defined in the EPackage.
Created attachment 32624
Artifact that caused the problem
In general, prefixes are not guaranteed to be preserved in a namespace aware application, so it is not a bug but an enchancement request. Since older point releases can only include critical bug fixes, this behavior will remain the same in 2.1.x stream.

Therefore, for now I am changing the target release and severity from normal to enchancement.
Please provide a test case that demostrates the problem - i.e. Java main/JUnit that shows the modifications you make to the file. After I evaluate the test case I will be able to tell you if behavior of EMF can be improved to preserve prefixes or not.



I'm going to return this because the particular example works if you use the proper Ecore namespace, i.e., "http://www.eclipse.org/emf/2002/Ecore", rather than "http://www.eclipse.org/emf/2002/Ecore2" as in the example.

Since prefixes are not recorded anywhere, you can't generally expect prefixes themselves to be preserved.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122979" />
    <CreationDate amount="2006-01-06 16:42:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="User Assistance" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>[Help] Remove access restrictions on lucene packages</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="5">
        <Lines>
          <Line>1) We own both PDE and the internal package we are talking about, therefore we can safely call the method knowing that we will not shoot ourselves in the foot.</Line>
          <Line />
          <Line>2) We don't want to open up that package to the world because we don't want everybody and his dog start making dependencies on our own copy of the demo code that we tweaked.</Line>
          <Line />
          <Line>3) We don't want to see the warning but we don't want to promote PDE to help's friend because it crosses feature boundaries.</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>The lucene packages shouldn't be marked as internal.  All lucene packages should be visible to all plug-ins so that they may make use of them.
All Lucene packages except 'demo.html' are visible. The demo package is marked as internal with help.base plug-in being the only 'friend'. 

There must be a reason for this (perhaps this package is not API and help.base is using it as-is. I would rather add pde as another friend than make it API. This way we could treat possible problems in the demo package easier.
what's the status on this request for 3.2?

PDE/UI is a pretty big API offender according to the build logs, and we would like to restore our good name.
From what I read, there are a set of demos provided by lucene to demonstrate some sample usage. Help uses the html demo because it provides html indexing, but I'm not sure if exposing this package is the right way to go, because it seems to imply API, which it is not. For all we know, the demo may be completely reworked in the next lucene version and anyone using it would be broken. I think this is why it was kept internal.. can you confirm Konrad?
The reason why we are using this package in the first place is because PDE is graciously providing tooling for UA.

What do we get in return?  Access violations.

I am going on a hunger strike until this issue is resolved.


This is hard to solve.

1) We own both PDE and the internal package we are talking about, therefore we can safely call the method knowing that we will not shoot ourselves in the foot.

2) We don't want to open up that package to the world because we don't want everybody and his dog start making dependencies on our own copy of the demo code that we tweaked.

3) We don't want to see the warning but we don't want to promote PDE to help's friend because it crosses feature boundaries.

This is hard to solve. Either we add the friend statement or live with the warning knowing that it is a false alarm. Removing the conversion tool is not an option. Pick your poison.
I pick poison 3 - add PDE/UI as a friend.
although I am not sure poison 2 is realistically much of an issue.
I'm not sure if this is true or not, but I though I heard that Lucene updated its code to fix the defects that we had addressed ourselves. If this is the case we could update our lucence code with the official version and poision #2 wouldn't be a poision anymore.
Any objections from anyone about making PDE a friend? Going once, going twice..
I suggest that we add PDE as a temporary friend but mark somewhere that we test if we can move to the official 'demo' package and open it up to the world. I am hesitant to upgrade Lucene at this point.
org.eclipse.pde.ui is now a friend for package org.apache.lucene.demo.html. Added a note to bug 130345 to remove friend and expose the official demo package after we upgrade to the latest lucene, assuming the fixes we added were added to lucene.
Forgot to mark as fixed.
(In reply to comment #4)
&gt; I am going on a hunger strike until this issue is resolved.
&gt; 

I'm relieved to see this was resolved just in time for lunch.  :-)</WithStack>
    <WithOutStack>The lucene packages shouldn't be marked as internal.  All lucene packages should be visible to all plug-ins so that they may make use of them.
All Lucene packages except 'demo.html' are visible. The demo package is marked as internal with help.base plug-in being the only 'friend'. 

There must be a reason for this (perhaps this package is not API and help.base is using it as-is. I would rather add pde as another friend than make it API. This way we could treat possible problems in the demo package easier.
what's the status on this request for 3.2?

PDE/UI is a pretty big API offender according to the build logs, and we would like to restore our good name.
From what I read, there are a set of demos provided by lucene to demonstrate some sample usage. Help uses the html demo because it provides html indexing, but I'm not sure if exposing this package is the right way to go, because it seems to imply API, which it is not. For all we know, the demo may be completely reworked in the next lucene version and anyone using it would be broken. I think this is why it was kept internal.. can you confirm Konrad?
The reason why we are using this package in the first place is because PDE is graciously providing tooling for UA.

What do we get in return?  Access violations.

I am going on a hunger strike until this issue is resolved.


This is hard to solve.

1) We own both PDE and the internal package we are talking about, therefore we can safely call the method knowing that we will not shoot ourselves in the foot.

2) We don't want to open up that package to the world because we don't want everybody and his dog start making dependencies on our own copy of the demo code that we tweaked.

3) We don't want to see the warning but we don't want to promote PDE to help's friend because it crosses feature boundaries.

This is hard to solve. Either we add the friend statement or live with the warning knowing that it is a false alarm. Removing the conversion tool is not an option. Pick your poison.
I pick poison 3 - add PDE/UI as a friend.
although I am not sure poison 2 is realistically much of an issue.
I'm not sure if this is true or not, but I though I heard that Lucene updated its code to fix the defects that we had addressed ourselves. If this is the case we could update our lucence code with the official version and poision #2 wouldn't be a poision anymore.
Any objections from anyone about making PDE a friend? Going once, going twice..
I suggest that we add PDE as a temporary friend but mark somewhere that we test if we can move to the official 'demo' package and open it up to the world. I am hesitant to upgrade Lucene at this point.
org.eclipse.pde.ui is now a friend for package org.apache.lucene.demo.html. Added a note to bug 130345 to remove friend and expose the official demo package after we upgrade to the latest lucene, assuming the fixes we added were added to lucene.
Forgot to mark as fixed.
(In reply to comment #4)
&gt; I am going on a hunger strike until this issue is resolved.
&gt; 

I'm relieved to see this was resolved just in time for lunch.  :-)</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122980" />
    <CreationDate amount="2006-01-06 16:53:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="UI" />
    <Version amount="3.2" />
    <rep_platform amount="All" />
    <op_sys amount="All" />
    <priority amount="P4" />
    <bug_severity amount="normal" />
    <Summery>[KeyBindings] preference page: Experimental page "Restore Defaults" not working properly</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="1">
      <Enumeration lines="5">
        <Lines>
          <Line>- step 1: Open Window-&gt;Preferences-&gt;General-&gt;Key (Experimental)</Line>
          <Line>- step 2: Choose a command</Line>
          <Line>- step 3: Change Binding and Apply</Line>
          <Line>- step 4: Click 'Restore Defaults'</Line>
          <Line>- step 5: Click cancel</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="RESOLVED" />
    <resolution amount="INVALID" />
    <WithStack>Eclipse 3.2 M4

- step 1: Open Window-&gt;Preferences-&gt;General-&gt;Key (Experimental)
- step 2: Choose a command
- step 3: Change Binding and Apply
- step 4: Click 'Restore Defaults'
- step 5: Click cancel

You will see that defaults are restored eventhough cancel is chosen
Moving Dougs bugs
Restore defaults is applied when the warning dialog is OKed.

PW</WithStack>
    <WithOutStack>Eclipse 3.2 M4

- step 1: Open Window-&gt;Preferences-&gt;General-&gt;Key (Experimental)
- step 2: Choose a command
- step 3: Change Binding and Apply
- step 4: Click 'Restore Defaults'
- step 5: Click cancel

You will see that defaults are restored eventhough cancel is chosen
Moving Dougs bugs
Restore defaults is applied when the warning dialog is OKed.

PW</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122981" />
    <CreationDate amount="2006-01-06 16:58:00 -0500" />
    <DupId amount="66457" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="UI" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>[convert local] Comments Eaten When Field Created</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="1">
      <source_code type="multicomment">
        <location start="163" end="179" />
        <code>/**
* Comment
*/</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="DUPLICATE" />
    <WithStack>Eclipse 3.2 M4

When refactoring a local variable to a field, comments above seem to be eaten.

Procedure:
-Create Local variable with a block comment above

i.e 
/**
* Comment
*/

ResourceManager resource = ...

-Select and right-click
-Refactor -&gt; Convert Local Variable to Field
-Block Comment should dissapear
In the example you give, the comment is not associated with the local (empty line in between) and will not be touched. So no problem there.
But without empty line you're right. The created field should get the comment that was associated with the VariableDeclarationFragment before.

This could be solved with a trick to simply move the VariableDeclarationFragment (instead of creating a FielDeclaration)


*** This bug has been marked as a duplicate of bug 66457 ***</WithStack>
    <WithOutStack>Eclipse 3.2 M4

When refactoring a local variable to a field, comments above seem to be eaten.

Procedure:
-Create Local variable with a block comment above

i.e 
/**
* Comment
*/

ResourceManager resource = ...

-Select and right-click
-Refactor -&gt; Convert Local Variable to Field
-Block Comment should dissapear
In the example you give, the comment is not associated with the local (empty line in between) and will not be touched. So no problem there.
But without empty line you're right. The created field should get the comment that was associated with the VariableDeclarationFragment before.

This could be solved with a trick to simply move the VariableDeclarationFragment (instead of creating a FielDeclaration)


*** This bug has been marked as a duplicate of bug 66457 ***</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122982" />
    <CreationDate amount="2006-01-06 17:16:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="UI" />
    <Version amount="3.2" />
    <rep_platform amount="All" />
    <op_sys amount="All" />
    <priority amount="P3" />
    <bug_severity amount="minor" />
    <Summery>[KeyBindings] errors: No warning when creating an invalid keybinding sequence</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="VERIFIED" />
    <resolution amount="FIXED" />
    <WithStack>I tried to map COLUMN_PREVIOUS to ARROW_LEFT in my plug.xml. But I set it to "LEFT" instead. LEFT is unrecognized, yet there was no warning in the .log file indicating that an invalid sequence had been set. I also have debug keybindings enabled in my options file, and it did not spew any complaints either.
Can you attach the snippet of registry XML that you're using?

&lt;key
  commandId="org.eclipse.ui.edit.text.goto.columnPrevious"
  contextId="org.eclipse.gef.contexts.textEditing"
  schemeId="org.eclipse.ui.defaultAcceleratorConfiguration"
  sequence="LEFT"/&gt;

Fixed in CVS.
Verified with an invalid key sequence from the org.eclipse.ui.tests plug-in, I20060214-0800.</WithStack>
    <WithOutStack>I tried to map COLUMN_PREVIOUS to ARROW_LEFT in my plug.xml. But I set it to "LEFT" instead. LEFT is unrecognized, yet there was no warning in the .log file indicating that an invalid sequence had been set. I also have debug keybindings enabled in my options file, and it did not spew any complaints either.
Can you attach the snippet of registry XML that you're using?

&lt;key
  commandId="org.eclipse.ui.edit.text.goto.columnPrevious"
  contextId="org.eclipse.gef.contexts.textEditing"
  schemeId="org.eclipse.ui.defaultAcceleratorConfiguration"
  sequence="LEFT"/&gt;

Fixed in CVS.
Verified with an invalid key sequence from the org.eclipse.ui.tests plug-in, I20060214-0800.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122983" />
    <CreationDate amount="2006-01-06 18:02:00 -0500" />
    <DupId amount="119161" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="Core" />
    <Version amount="3.1.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="major" />
    <Summery>Packages Erroneously Not Found</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="DUPLICATE" />
    <WithStack>I have a project with multiple source folders and complex source include/exclude rules. Among other things, I include something like the following:

Include: com.example.a.b.ClassA;com.example.a.b.ClassB
Exclude: (none)

Now, if I "include com.example.a.b.*" in my other file, I get an underlined _com.example.a_ with a "Package not found." My code shows no errors in Package Explorer, but the source editor shows errors on the include and any attempts to use the class. My Problems view also shows no errors.

Switching to include com.example.a and excluding the unnecessary classes makes the editor happy, but there's no reason it shouldn't properly recognize the included packages.


*** This bug has been marked as a duplicate of 119161 ***</WithStack>
    <WithOutStack>I have a project with multiple source folders and complex source include/exclude rules. Among other things, I include something like the following:

Include: com.example.a.b.ClassA;com.example.a.b.ClassB
Exclude: (none)

Now, if I "include com.example.a.b.*" in my other file, I get an underlined _com.example.a_ with a "Package not found." My code shows no errors in Package Explorer, but the source editor shows errors on the include and any attempts to use the class. My Problems view also shows no errors.

Switching to include com.example.a and excluding the unnecessary classes makes the editor happy, but there's no reason it shouldn't properly recognize the included packages.


*** This bug has been marked as a duplicate of 119161 ***</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122984" />
    <CreationDate amount="2006-01-06 18:09:00 -0500" />
    <DupId amount="89428" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="Update  (deprecated - use RT&gt;Equinox&gt;p2)" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>JDT core plugin version does not match the version referenced in the feature</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="DUPLICATE" />
    <WithStack>I installed Eclipse SDK 3.2M4. 
I clicked help -&gt; software updates -&gt; manage configuration
I expanded c:\eclipse until I saw "Eclipse Java Development Tools 3.2.0.v20051212-0800-05frhQbfqg".
There was an acclaimation symbol with this feature. I checked its property and found its status was as follows:

"Plug-in: "org.eclipse.jdt.core" version: "3.2.0.v-631" referenced by this feature is not included at runtime. Runtime includes plug-in version "3.2.0.v_631" supplied by feature "Eclipse Java Development Tools" version "3.2.0.v20051212-0800-05frhQbfqg"."

Apparently, there was a typo somewhere in Eclipse that the developer confused v-631 and v_631.

I'm not sure this is a severe problem. 

Regards,
Qingfeng
Qingfeng, Community/Bugzilla is for reporting issus with bugs.eclipse.org.

Moving to JDT.
The offending qualifier is computed by Releng scripts.
The version in the feature.xml and the name of the jar is correct on the filesystem.  Just the status references 3.2.0.v-631 instead of the correct 3.2.0.v_631. This is not an releng issue, moving to update.


*** This bug has been marked as a duplicate of 89428 ***</WithStack>
    <WithOutStack>I installed Eclipse SDK 3.2M4. 
I clicked help -&gt; software updates -&gt; manage configuration
I expanded c:\eclipse until I saw "Eclipse Java Development Tools 3.2.0.v20051212-0800-05frhQbfqg".
There was an acclaimation symbol with this feature. I checked its property and found its status was as follows:

"Plug-in: "org.eclipse.jdt.core" version: "3.2.0.v-631" referenced by this feature is not included at runtime. Runtime includes plug-in version "3.2.0.v_631" supplied by feature "Eclipse Java Development Tools" version "3.2.0.v20051212-0800-05frhQbfqg"."

Apparently, there was a typo somewhere in Eclipse that the developer confused v-631 and v_631.

I'm not sure this is a severe problem. 

Regards,
Qingfeng
Qingfeng, Community/Bugzilla is for reporting issus with bugs.eclipse.org.

Moving to JDT.
The offending qualifier is computed by Releng scripts.
The version in the feature.xml and the name of the jar is correct on the filesystem.  Just the status references 3.2.0.v-631 instead of the correct 3.2.0.v_631. This is not an releng issue, moving to update.


*** This bug has been marked as a duplicate of 89428 ***</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122985" />
    <CreationDate amount="2006-01-06 18:34:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="PDE" />
    <component amount="UI" />
    <Version amount="3.1.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>PDE doesn't notice installed bundles which weren't supplied by update configurator</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="INVALID" />
    <WithStack>I'm writing my own configuration plugin which will define/install bundles to the eclipse/OSGi runtime.

I also have some plugins in an extension directory which have dependencies on plugins which are installed by my configurator.  _Every_ time Eclipse starts, I get a new entry in the Error Log about the "missing" dependencies:

text: Problems encountered while PDE was scanning the Target Platform
plugin: org.eclipse.pde.core.

The dependencies are indeed available and can be see in the plugin registry view, by BundleContext.getBundles(), etc.

The warnings are incorrect and look bad -- the dependencies are available and everything resolves.
Closing as I'm not sure what the problem is or if it is even a problem still. A lot has changed in regards to PDE, update and p2.</WithStack>
    <WithOutStack>I'm writing my own configuration plugin which will define/install bundles to the eclipse/OSGi runtime.

I also have some plugins in an extension directory which have dependencies on plugins which are installed by my configurator.  _Every_ time Eclipse starts, I get a new entry in the Error Log about the "missing" dependencies:

text: Problems encountered while PDE was scanning the Target Platform
plugin: org.eclipse.pde.core.

The dependencies are indeed available and can be see in the plugin registry view, by BundleContext.getBundles(), etc.

The warnings are incorrect and look bad -- the dependencies are available and everything resolves.
Closing as I'm not sure what the problem is or if it is even a problem still. A lot has changed in regards to PDE, update and p2.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122986" />
    <CreationDate amount="2006-01-06 18:40:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="Runtime" />
    <Version amount="3.2" />
    <rep_platform amount="All" />
    <op_sys amount="All" />
    <priority amount="P3" />
    <bug_severity amount="enhancement" />
    <Summery>[jobs]  Job should allow cancel() to notify someone a cancel has been requested</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="6">
      <source_code type="class">
        <location start="3611" end="4595" />
        <code>class BlockingJob extends Job {
        private Thread fCurrentThread;
        public BlockingJob() {
            super("Blocking Job");
        }
        protected IStatus run(IProgressMonitor monitor) {
            synchronized(this) {
                fCurrentThread=Thread.currentThread();
            }
            try {
                // the only way to get out is to call 
                // Thread.interrupt();
                Thread.sleep(10000000);
            } catch (InterruptedException e) {
                return Status.CANCEL_STATUS;
            } finally {
                // the job is done and we have don't
                // want to interrupt another job
                synchronized(this) {
                    fCurrentThread=null;
                }
            }
            return Status.OK_STATUS;
        }
        protected synchronized void canceled() {
            if(fCurrentThread!=null)
                fCurrentThread.interrupt();
         }
    }</code>
      </source_code>
      <source_code type="class">
        <location start="5062" end="6466" />
        <code>class InterruptableJob extends Job {
        /**
         * synchronize is not needed because the set 'happens-before' the get. 
         * http://www-128.ibm.com/developerworks/java/library/j-jtp03304/
         */
        private IStatus fStatus; 
        public InterruptableJob() {
            super("Blocking Job");
        }
        protected IStatus run(IProgressMonitor monitor) {
            Thread thread=new Thread("Annoying Polling IMonitor Thread") {
                public void run() {
                    try {
                        // the only way to get out is to call 
                        // Thread.interrupt();
                        Thread.sleep(10000000);
                    } catch (InterruptedException e) {
                        fStatus=Status.CANCEL_STATUS;
                    }
                    fStatus=Status.OK_STATUS;
                }
            };
            thread.start();
            try {
                // a stupid polling loop
                while(thread.isAlive()) {
                    if(monitor.isCanceled()) {
                        thread.interrupt();
                        break;
                    }
                    Thread.sleep(1);
                }
                thread.join();
            } catch (InterruptedException e) {
                return Status.CANCEL_STATUS;
            }
            return fStatus;
        }
    }</code>
      </source_code>
      <source_code type="functioncall">
        <location start="6676" end="6713" />
        <code>myJob.setInterruptOnCancel(true);</code>
      </source_code>
      <source_code type="class">
        <location start="7128" end="7664" />
        <code>class InterruptableJob extends Job {
        public InterruptableJob() {
            super(" Interruptable Job");
            setInterruptOnCancel(true);
        }
        protected IStatus run(IProgressMonitor monitor) {
            try {
                // the only way to get out is to call 
                // Thread.interrupt();
                Thread.sleep(10000000);
            } catch (InterruptedException e) {
                return Status.CANCEL_STATUS;
            }
            return Status.OK_STATUS;
        }
    }</code>
      </source_code>
      <source_code type="functioncall">
        <location start="8377" end="8401" />
        <code>Thread.sleep(1);</code>
      </source_code>
      <source_code type="functiondef">
        <location start="8402" end="8465" />
        <code>} catch (InterruptedException e2) {
        // ignore
    }</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="3">
      <Enumeration lines="2">
        <Lines>
          <Line>1) Being able to call arbitrary code on cancel.</Line>
          <Line>2) Calling Thread.interrupt() to interrupt blocking calls.</Line>
        </Lines>
      </Enumeration>
      <Enumeration lines="3">
        <Lines>
          <Line>1. Job.cancel() is final and therefore not overridable.</Line>
          <Line>2. Job.cancel() essentially calls JobManager.cancel(this). This method is called from other places as well, like JobManager.shutDown(). Even if Job.cancel() would be overridden, it would not get called on JobManager.shutDown(). This is why a hook is needed or direct support for Thread.interrupt.</Line>
          <Line>While I don't want to talk someone out of using interrupt() if they insist, I've found the semantics of it to be fairly muddy.  In my case, why I submitted the bug in the first place, I actually have a controlled way of doing the 'interrupt' with quite clear semantics (I'm blocked on a socket, and want to 'close' it on cancel to get the socket to 'wake up').  I would hope this would suffice for a great number of people.</Line>
        </Lines>
      </Enumeration>
      <Enumeration lines="3">
        <Lines>
          <Line>1) Do the work in separate thread and let the job poll this thread (see comment #12)</Line>
          <Line />
          <Line>2) Have one IProgressMonitor watch thread, that polls periodically the IProgressMonitor.isCanceled() of all active jobs that want a notification when canceling. Once the isCanceled state changes it could call the Job.canceling...</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>I'd like to use runtime.jobs.Job to wrap some processing that includes a long-running blocking i/o operation.  I have some code I can run from another Thread that will unblock the blocking i/o operation, and I'd like to arrange for the Job.cancel() call to be able to call this unblocking code.  

Currently there doesn't seem to be a way to do this.

My suggestion would be to create a new Listener/Event for "cancelRequested".  This event would be fired during the processing of the cancel() method.  I could then hook the event with a listener that called my unblocking code.
I understand the motivation, but I believe a synchronous cancelation notification would be deadlock prone.  If one party called Job.cancel() while holding some lock, and then a cancel event listener tried to obtain another lock, it could very easily deadlock.

The CVS plugin has similar code for cancelling an unresponsive network connection. It essentially does the read in a separate thread, and then the calling thread can be left to check for cancelation and react accordingly.
Will you reconsider this enhancement request? I think that the potential deadlock problem should be documented but the functionnality should still be provided as it would be very useful.  Otherwise, isn't it a bit heavy to force two different threads in the same Job?
I thought I had replied to John's note, but I guess I hadn't.

Like Ricky, I believe the deadlock potential should be documented, but should not be a reason to not implement something like this.  We're big boys and girls, we can deal with loaded guns.  Besides, polling with extra threads is so 1980's ...
Is there or will there be any further discussions about this particular issue for Eclipse 3.3?  Or is this a WONTFIX?
I'm considering the option of adding a hook method on Job that subclasses can override to specialize the cancel behaviour.  This feels a bit safer than allowing an arbitrary listener to hook the cancel behaviour of any job. Even the most careful client could be deadlocked by an unknown third party listener acquiring a lock during a cancellation callback. This would be similar to the shouldSchedule and shouldRun hook methods that occur on schedule() and prior to run().
I'm very much in favor of some kind of mechanism for being notified in some way that a not was canceled by the user.  I have nearly the exact same situation as Patrick does, and this would be very helpful.  I can obviously work around the lack of functionality with a polling Thread, but I just hate the idea of polling.  
I will add the hook method.
I have added a new protected API method - Job#canceling.  This method is called when the job is running and its progress monitor cancel flag has been set to true for the first time.  I.e., a cancelation request has been made, but the job is still running.
Thank you John, I'm looking forward to using your new method! This will help replace the kludge we have right now.

[Did it really just take you 5mn (17:31-17:36) to do this, tests and all? ;-).]
I think I had already decided on the exact solution when I added the comment.  Adding a hook method isn't very complicated ;)  

I later added automated tests in org.eclipse.core.tests.runtime.jobs.JobTest#testCanceling()
*** Bug 162577 has been marked as a duplicate of this bug. ***
You marked bug Bug 162577 as duplicated. Unfortunately, the fix does not solve the problem. When I run the following job in eclipse (with the CVS version of the jobs plugin) and cancel it using the cancel button in the progress bar, the job does not get canceled (canceled does not get called).

    class BlockingJob extends Job {
        private Thread fCurrentThread;
        public BlockingJob() {
            super("Blocking Job");
        }
        protected IStatus run(IProgressMonitor monitor) {
            synchronized(this) {
                fCurrentThread=Thread.currentThread();
            }
            try {
                // the only way to get out is to call 
                // Thread.interrupt();
                Thread.sleep(10000000);
            } catch (InterruptedException e) {
                return Status.CANCEL_STATUS;
            } finally {
                // the job is done and we have don't
                // want to interrupt another job
                synchronized(this) {
                    fCurrentThread=null;
                }
            }
            return Status.OK_STATUS;
        }
        protected synchronized void canceled() {
            if(fCurrentThread!=null)
                fCurrentThread.interrupt();
         }
    }

I don't understand comment #1. How would calling Thread.interrupt() cause a deadlock? Blocking calls and Thread.interrupt() are meant to work together and I don't understand why this basic notification mechanism is not supported by the jobs framework.

Here is a solution using another thread (java 1.4). Creating another thread (or using the java.util.concurrent.Executor) adds more complexity and I agree with the other posters that polling seems pretty stupid.

   class InterruptableJob extends Job {
        /**
         * synchronize is not needed because the set 'happens-before' the get. 
         * http://www-128.ibm.com/developerworks/java/library/j-jtp03304/
         */
        private IStatus fStatus; 
        public InterruptableJob() {
            super("Blocking Job");
        }
        protected IStatus run(IProgressMonitor monitor) {
            Thread thread=new Thread("Annoying Polling IMonitor Thread") {
                public void run() {
                    try {
                        // the only way to get out is to call 
                        // Thread.interrupt();
                        Thread.sleep(10000000);
                    } catch (InterruptedException e) {
                        fStatus=Status.CANCEL_STATUS;
                    }
                    fStatus=Status.OK_STATUS;
                }
            };
            thread.start();
            try {
                // a stupid polling loop
                while(thread.isAlive()) {
                    if(monitor.isCanceled()) {
                        thread.interrupt();
                        break;
                    }
                    Thread.sleep(1);
                }
                thread.join();
            } catch (InterruptedException e) {
                return Status.CANCEL_STATUS;
            }
            return fStatus;
        }
    }

What I really want is that canceling a running job interrupts the thread. What is the problem with that? Ok, for backward compatibility, it should be possible to the a flag on the job to interrupt on cancel:
    myJob.setInterruptOnCancel(true);
And then cancel would interrupt the thread. No callback needed. And I think it would solve all the problems described in the bug.
Created attachment 52904
Patch to optionally call Thread.interrupt() on Job.cancel()

I created a patch that adds an interruptOnCancel attribute to Job. If it is true, then the job is running Thread.interrupt() gets called when the job is canceled.

This code now works as expected:

    class InterruptableJob extends Job {
        public InterruptableJob() {
            super(" Interruptable Job");
            setInterruptOnCancel(true);
        }
        protected IStatus run(IProgressMonitor monitor) {
            try {
                // the only way to get out is to call 
                // Thread.interrupt();
                Thread.sleep(10000000);
            } catch (InterruptedException e) {
                return Status.CANCEL_STATUS;
            }
            return Status.OK_STATUS;
        }
    }

Reading the comments again, I come to the conclusion that there are two separate problems:
1) Being able to call arbitrary code on cancel.
2) Calling Thread.interrupt() to interrupt blocking calls.

Problem 1) probably boils down to call Thread.interrupt(). However some external libraries might have some other methods that set some flags before calling Thread.interrupt(). This has potential deadlock problems.

Problem 2) is easier to solve and less problematic. However, the only potential problem is that one interrupt might not be enough, because there is a lot code swallows interrupts (and because eclipse does not use interrupts most people don't even know why swallowing interrupts is bad):
    try {
        Thread.sleep(1);
    } catch (InterruptedException e2) {
        // ignore
    }
This is really bad practice (see bug 157604 and http://michaelscharf.blogspot.com/2006/09/dont-swallow-interruptedexception-call.html). Therefore a job should be cancelable multiple times or re-interrupt after a timeout, but this is probably another problem....
Why couldn't you just call Thread.currentThread().interrupt() inside your Job's cancelling method?
&gt; Why couldn't you just call Thread.currentThread().interrupt() inside 
&gt; your Job's cancelling method?

No! For two reasons:

1. Job.cancel() is final and therefore not overridable.
2. Job.cancel() essentially calls JobManager.cancel(this). This method is called from other places as well, like JobManager.shutDown(). Even if Job.cancel() would be overridden, it would not get called on JobManager.shutDown(). This is why a hook is needed or direct support for Thread.interrupt.
While I don't want to talk someone out of using interrupt() if they insist, I've found the semantics of it to be fairly muddy.  In my case, why I submitted the bug in the first place, I actually have a controlled way of doing the 'interrupt' with quite clear semantics (I'm blocked on a socket, and want to 'close' it on cancel to get the socket to 'wake up').  I would hope this would suffice for a great number of people.

And so I'm wondering if you can't arrange to make your interrupt() call within the new canceling() method that John added.

And as a generalist comment, I wonder if people won't get confused with an interruptOnCancel setting, thinking they'll get some kind of magical behaviour out of it, when in fact, they might not.  Or they might, in an intermittent fashion (during testing, but not during production, say).  That, combined with my general leeriness of the whole interrupt() thing has my gut telling me adding this API isn't the best thing to do.
I'm talking about the Job#cancelling hook method that was just added.  Of course, you cannot override the Job#cancel method as it is final.  Comment #14 is the same question as comment #16
I tried the new canceling method and it simply does not work as expected (see comment #12). Maybe it needs to be fixed. In that case just forget my proposal, because it allows to solve the Thread.interrupt() problem.

Thread.interrupt() is the only way to get out of blocking calls. Interrupts can be used for anything. But the common case it to use it for canceling. It is cooperative because the caller and the receiver have to agree what it means.

IProgressMonitor.isCanceled() also cooperative . The cancellable operation has to periodically check the cancel state. But it does not provide a way to interrupt a blocking call.

So, we have two cooperative way of canceling. One is build into java and allows interrupting blocking calls. The other cannot deal with blocking calls and it requires state polling. I would find it very natural to extend the eclipse polling mechanism to use Thread.interrupt if desired.

This is fine for code that fully under control of eclipse developer. This is what I wanted to address with the interruptOnCancel.

There is another case, where an existing library has to be integrated into eclipse. In this case polling for IProgressMonitor.isCanceled() is not enough, because the 3rd party library is not prepared for that. Instead some method has to be called to cancel the library call. That's the case where a hook mechanism is needed. In that hook method Thread.interrupt() could be called. However this generic mechanism opens the door for nasty deadlocks. The interruptOnCancel would not have the deadlock problems but it would not solve the general problem.

The reason Job.canceled() does not work in some cases is because it is *not* called when the ProgressMonitor is used to cancel the Job. It is only called when Job.cancel() is called and the IProgressMonitor.isCanceled() returns false (see comment #12). 

John says in comment #8:

&gt; This method is called when the job is running and its progress 
&gt; monitor cancel flag has been set to true for the first time

When the job gets canceled the progress monitor is set to canceled before Job.cancel() is called and therefore Job.canceling gets never called...

John, is this a bug or a feature?

w/r/t comment #18 ... you mention the new canceling() method doesn't work and point to comment #12, but I don't see that the code in the comment using canceling().  

"Thread.interrupt() is the only way to get out of blocking calls."  Ouch.  That's EXACTLY what I was afraid of when I mentioned "magical behaviour".  That method most ASSUREDLY is NOT the only way to get out of blocking calls.  Most importantly, it is not guaranteed to get you out of any blocking call, only things that respond to it (like the new InterruptibleChannel stuff).  

If Sun had forced every call that can 'block' to be interrruptable, that would be one thing.  But they didn't.  While it might have been intended to be a general purpose facility for any blocking behaviour, it currently IS NOT.  It only works for an interesting, but limited # of blocking methods.

As such, I'm not sure it deserves special status with an API of it's own.  I might well ask for an API 'closeOnCancel(InputStream)' that would do a 'close' on the specified InputStream when a cancel was requested.  Where do you stop?
Yikes, I don't know where to weigh in here. Michael, I marked your bug as a duplicate because you wanted additional behaviour when Job.cancel() was called. This has been implemented by the new canceling() hook method. However, as you have since discovered, programmatic cancelation and end-user cancelation have different code paths. In the case of end-user cancelation, the progress widget in the UI directly sets the canceled flag in the IProgressMonitor, and no code is called at all at the core jobs level. 

If you wanted Thread.interrupt() to be called whenever IProgressMonitor#setCanceled was called, this behaviour would need to be added to all progress monitor implementations. Personally I don't think this is good idea, and very unlikely to happen, but you're welcome to enter an enhancement at the UI level. There is nothing unique to the job API here in its use of the general Eclipse IProgressMonitor mechanism.  If you wanted such a behaviour change to how progress monitors operate, any solution should not be specific to jobs, but apply to all IProgressMonitors.
So, we still need to poll to determine when the user requests a cancel?  I thought that was the whole point of adding this hook.
From the beginning, this request has been about adding a hook when Job#cancel() is called, and that is what I have added.  Hooking the behaviour when the UI sets the progress monitor's cancelation flag is a whole other problem... 
I think the implied assumption of this request was that Job.cancel() gets called when the user cancels the request from the UI. This is obviously not true.

IProgressMonitor uses polling to cancel a request. Job.cancel is a direct call which allows a hook like canceling(). 

There are currently two ways to combine the two approaches:
1) Do the work in separate thread and let the job poll this thread (see comment #12)

2) Have one IProgressMonitor watch thread, that polls periodically the IProgressMonitor.isCanceled() of all active jobs that want a notification when canceling. Once the isCanceled state changes it could call the Job.canceling...

Approach 1) adds an additional thread for each cancelable Job.

Approach 2) would add only one more thread. It could be implemented in the jobs plugin.

Oops, I mean:
&gt; 1) Do the work in separate thread and let the job poll this thread
  1) Do the work in separate thread and let the job poll the progress monitor</WithStack>
    <WithOutStack>I'd like to use runtime.jobs.Job to wrap some processing that includes a long-running blocking i/o operation.  I have some code I can run from another Thread that will unblock the blocking i/o operation, and I'd like to arrange for the Job.cancel() call to be able to call this unblocking code.  

Currently there doesn't seem to be a way to do this.

My suggestion would be to create a new Listener/Event for "cancelRequested".  This event would be fired during the processing of the cancel() method.  I could then hook the event with a listener that called my unblocking code.
I understand the motivation, but I believe a synchronous cancelation notification would be deadlock prone.  If one party called Job.cancel() while holding some lock, and then a cancel event listener tried to obtain another lock, it could very easily deadlock.

The CVS plugin has similar code for cancelling an unresponsive network connection. It essentially does the read in a separate thread, and then the calling thread can be left to check for cancelation and react accordingly.
Will you reconsider this enhancement request? I think that the potential deadlock problem should be documented but the functionnality should still be provided as it would be very useful.  Otherwise, isn't it a bit heavy to force two different threads in the same Job?
I thought I had replied to John's note, but I guess I hadn't.

Like Ricky, I believe the deadlock potential should be documented, but should not be a reason to not implement something like this.  We're big boys and girls, we can deal with loaded guns.  Besides, polling with extra threads is so 1980's ...
Is there or will there be any further discussions about this particular issue for Eclipse 3.3?  Or is this a WONTFIX?
I'm considering the option of adding a hook method on Job that subclasses can override to specialize the cancel behaviour.  This feels a bit safer than allowing an arbitrary listener to hook the cancel behaviour of any job. Even the most careful client could be deadlocked by an unknown third party listener acquiring a lock during a cancellation callback. This would be similar to the shouldSchedule and shouldRun hook methods that occur on schedule() and prior to run().
I'm very much in favor of some kind of mechanism for being notified in some way that a not was canceled by the user.  I have nearly the exact same situation as Patrick does, and this would be very helpful.  I can obviously work around the lack of functionality with a polling Thread, but I just hate the idea of polling.  
I will add the hook method.
I have added a new protected API method - Job#canceling.  This method is called when the job is running and its progress monitor cancel flag has been set to true for the first time.  I.e., a cancelation request has been made, but the job is still running.
Thank you John, I'm looking forward to using your new method! This will help replace the kludge we have right now.

[Did it really just take you 5mn (17:31-17:36) to do this, tests and all? ;-).]
I think I had already decided on the exact solution when I added the comment.  Adding a hook method isn't very complicated ;)  

I later added automated tests in org.eclipse.core.tests.runtime.jobs.JobTest#testCanceling()
*** Bug 162577 has been marked as a duplicate of this bug. ***
You marked bug Bug 162577 as duplicated. Unfortunately, the fix does not solve the problem. When I run the following job in eclipse (with the CVS version of the jobs plugin) and cancel it using the cancel button in the progress bar, the job does not get canceled (canceled does not get called).

    class BlockingJob extends Job {
        private Thread fCurrentThread;
        public BlockingJob() {
            super("Blocking Job");
        }
        protected IStatus run(IProgressMonitor monitor) {
            synchronized(this) {
                fCurrentThread=Thread.currentThread();
            }
            try {
                // the only way to get out is to call 
                // Thread.interrupt();
                Thread.sleep(10000000);
            } catch (InterruptedException e) {
                return Status.CANCEL_STATUS;
            } finally {
                // the job is done and we have don't
                // want to interrupt another job
                synchronized(this) {
                    fCurrentThread=null;
                }
            }
            return Status.OK_STATUS;
        }
        protected synchronized void canceled() {
            if(fCurrentThread!=null)
                fCurrentThread.interrupt();
         }
    }

I don't understand comment #1. How would calling Thread.interrupt() cause a deadlock? Blocking calls and Thread.interrupt() are meant to work together and I don't understand why this basic notification mechanism is not supported by the jobs framework.

Here is a solution using another thread (java 1.4). Creating another thread (or using the java.util.concurrent.Executor) adds more complexity and I agree with the other posters that polling seems pretty stupid.

   class InterruptableJob extends Job {
        /**
         * synchronize is not needed because the set 'happens-before' the get. 
         * http://www-128.ibm.com/developerworks/java/library/j-jtp03304/
         */
        private IStatus fStatus; 
        public InterruptableJob() {
            super("Blocking Job");
        }
        protected IStatus run(IProgressMonitor monitor) {
            Thread thread=new Thread("Annoying Polling IMonitor Thread") {
                public void run() {
                    try {
                        // the only way to get out is to call 
                        // Thread.interrupt();
                        Thread.sleep(10000000);
                    } catch (InterruptedException e) {
                        fStatus=Status.CANCEL_STATUS;
                    }
                    fStatus=Status.OK_STATUS;
                }
            };
            thread.start();
            try {
                // a stupid polling loop
                while(thread.isAlive()) {
                    if(monitor.isCanceled()) {
                        thread.interrupt();
                        break;
                    }
                    Thread.sleep(1);
                }
                thread.join();
            } catch (InterruptedException e) {
                return Status.CANCEL_STATUS;
            }
            return fStatus;
        }
    }

What I really want is that canceling a running job interrupts the thread. What is the problem with that? Ok, for backward compatibility, it should be possible to the a flag on the job to interrupt on cancel:
    myJob.setInterruptOnCancel(true);
And then cancel would interrupt the thread. No callback needed. And I think it would solve all the problems described in the bug.
Created attachment 52904
Patch to optionally call Thread.interrupt() on Job.cancel()

I created a patch that adds an interruptOnCancel attribute to Job. If it is true, then the job is running Thread.interrupt() gets called when the job is canceled.

This code now works as expected:

    class InterruptableJob extends Job {
        public InterruptableJob() {
            super(" Interruptable Job");
            setInterruptOnCancel(true);
        }
        protected IStatus run(IProgressMonitor monitor) {
            try {
                // the only way to get out is to call 
                // Thread.interrupt();
                Thread.sleep(10000000);
            } catch (InterruptedException e) {
                return Status.CANCEL_STATUS;
            }
            return Status.OK_STATUS;
        }
    }

Reading the comments again, I come to the conclusion that there are two separate problems:
1) Being able to call arbitrary code on cancel.
2) Calling Thread.interrupt() to interrupt blocking calls.

Problem 1) probably boils down to call Thread.interrupt(). However some external libraries might have some other methods that set some flags before calling Thread.interrupt(). This has potential deadlock problems.

Problem 2) is easier to solve and less problematic. However, the only potential problem is that one interrupt might not be enough, because there is a lot code swallows interrupts (and because eclipse does not use interrupts most people don't even know why swallowing interrupts is bad):
    try {
        Thread.sleep(1);
    } catch (InterruptedException e2) {
        // ignore
    }
This is really bad practice (see bug 157604 and http://michaelscharf.blogspot.com/2006/09/dont-swallow-interruptedexception-call.html). Therefore a job should be cancelable multiple times or re-interrupt after a timeout, but this is probably another problem....
Why couldn't you just call Thread.currentThread().interrupt() inside your Job's cancelling method?
&gt; Why couldn't you just call Thread.currentThread().interrupt() inside 
&gt; your Job's cancelling method?

No! For two reasons:

1. Job.cancel() is final and therefore not overridable.
2. Job.cancel() essentially calls JobManager.cancel(this). This method is called from other places as well, like JobManager.shutDown(). Even if Job.cancel() would be overridden, it would not get called on JobManager.shutDown(). This is why a hook is needed or direct support for Thread.interrupt.
While I don't want to talk someone out of using interrupt() if they insist, I've found the semantics of it to be fairly muddy.  In my case, why I submitted the bug in the first place, I actually have a controlled way of doing the 'interrupt' with quite clear semantics (I'm blocked on a socket, and want to 'close' it on cancel to get the socket to 'wake up').  I would hope this would suffice for a great number of people.

And so I'm wondering if you can't arrange to make your interrupt() call within the new canceling() method that John added.

And as a generalist comment, I wonder if people won't get confused with an interruptOnCancel setting, thinking they'll get some kind of magical behaviour out of it, when in fact, they might not.  Or they might, in an intermittent fashion (during testing, but not during production, say).  That, combined with my general leeriness of the whole interrupt() thing has my gut telling me adding this API isn't the best thing to do.
I'm talking about the Job#cancelling hook method that was just added.  Of course, you cannot override the Job#cancel method as it is final.  Comment #14 is the same question as comment #16
I tried the new canceling method and it simply does not work as expected (see comment #12). Maybe it needs to be fixed. In that case just forget my proposal, because it allows to solve the Thread.interrupt() problem.

Thread.interrupt() is the only way to get out of blocking calls. Interrupts can be used for anything. But the common case it to use it for canceling. It is cooperative because the caller and the receiver have to agree what it means.

IProgressMonitor.isCanceled() also cooperative . The cancellable operation has to periodically check the cancel state. But it does not provide a way to interrupt a blocking call.

So, we have two cooperative way of canceling. One is build into java and allows interrupting blocking calls. The other cannot deal with blocking calls and it requires state polling. I would find it very natural to extend the eclipse polling mechanism to use Thread.interrupt if desired.

This is fine for code that fully under control of eclipse developer. This is what I wanted to address with the interruptOnCancel.

There is another case, where an existing library has to be integrated into eclipse. In this case polling for IProgressMonitor.isCanceled() is not enough, because the 3rd party library is not prepared for that. Instead some method has to be called to cancel the library call. That's the case where a hook mechanism is needed. In that hook method Thread.interrupt() could be called. However this generic mechanism opens the door for nasty deadlocks. The interruptOnCancel would not have the deadlock problems but it would not solve the general problem.

The reason Job.canceled() does not work in some cases is because it is *not* called when the ProgressMonitor is used to cancel the Job. It is only called when Job.cancel() is called and the IProgressMonitor.isCanceled() returns false (see comment #12). 

John says in comment #8:

&gt; This method is called when the job is running and its progress 
&gt; monitor cancel flag has been set to true for the first time

When the job gets canceled the progress monitor is set to canceled before Job.cancel() is called and therefore Job.canceling gets never called...

John, is this a bug or a feature?

w/r/t comment #18 ... you mention the new canceling() method doesn't work and point to comment #12, but I don't see that the code in the comment using canceling().  

"Thread.interrupt() is the only way to get out of blocking calls."  Ouch.  That's EXACTLY what I was afraid of when I mentioned "magical behaviour".  That method most ASSUREDLY is NOT the only way to get out of blocking calls.  Most importantly, it is not guaranteed to get you out of any blocking call, only things that respond to it (like the new InterruptibleChannel stuff).  

If Sun had forced every call that can 'block' to be interrruptable, that would be one thing.  But they didn't.  While it might have been intended to be a general purpose facility for any blocking behaviour, it currently IS NOT.  It only works for an interesting, but limited # of blocking methods.

As such, I'm not sure it deserves special status with an API of it's own.  I might well ask for an API 'closeOnCancel(InputStream)' that would do a 'close' on the specified InputStream when a cancel was requested.  Where do you stop?
Yikes, I don't know where to weigh in here. Michael, I marked your bug as a duplicate because you wanted additional behaviour when Job.cancel() was called. This has been implemented by the new canceling() hook method. However, as you have since discovered, programmatic cancelation and end-user cancelation have different code paths. In the case of end-user cancelation, the progress widget in the UI directly sets the canceled flag in the IProgressMonitor, and no code is called at all at the core jobs level. 

If you wanted Thread.interrupt() to be called whenever IProgressMonitor#setCanceled was called, this behaviour would need to be added to all progress monitor implementations. Personally I don't think this is good idea, and very unlikely to happen, but you're welcome to enter an enhancement at the UI level. There is nothing unique to the job API here in its use of the general Eclipse IProgressMonitor mechanism.  If you wanted such a behaviour change to how progress monitors operate, any solution should not be specific to jobs, but apply to all IProgressMonitors.
So, we still need to poll to determine when the user requests a cancel?  I thought that was the whole point of adding this hook.
From the beginning, this request has been about adding a hook when Job#cancel() is called, and that is what I have added.  Hooking the behaviour when the UI sets the progress monitor's cancelation flag is a whole other problem... 
I think the implied assumption of this request was that Job.cancel() gets called when the user cancels the request from the UI. This is obviously not true.

IProgressMonitor uses polling to cancel a request. Job.cancel is a direct call which allows a hook like canceling(). 

There are currently two ways to combine the two approaches:
1) Do the work in separate thread and let the job poll this thread (see comment #12)

2) Have one IProgressMonitor watch thread, that polls periodically the IProgressMonitor.isCanceled() of all active jobs that want a notification when canceling. Once the isCanceled state changes it could call the Job.canceling...

Approach 1) adds an additional thread for each cancelable Job.

Approach 2) would add only one more thread. It could be implemented in the jobs plugin.

Oops, I mean:
&gt; 1) Do the work in separate thread and let the job poll this thread
  1) Do the work in separate thread and let the job poll the progress monitor</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122987" />
    <CreationDate amount="2006-01-06 19:17:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="Core" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>[1.5][compiler] Boxing conversion should be performed in conditional expression</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="2">
      <source_code type="class">
        <location start="15" end="132" />
        <code>public class Test
{
    public static void main(String[] args)
    {
        Object obj = true ? true : 17.3;
    }
}</code>
      </source_code>
      <source_code type="assignment">
        <location start="926" end="978" />
        <code>Object obj = true ? true : Double.valueOf(17.3);</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="VERIFIED" />
    <resolution amount="FIXED" />
    <WithStack>Eclipse 3.2M3

public class Test
{
    public static void main(String[] args)
    {
        Object obj = true ? true : 17.3;
    }
}

Eclipse says:

Incompatible conditional operand types Boolean and double

JLS says:

Otherwise, the second and third operands are of types S1 and S2 respectively.  Let T1 be the type that results from applying boxing conversion to S1, and let T2 be the type that results from applying boxing conversion to S2.  The type of the conditional expression is the result of applying capture conversion to lub(T1, T2).

As I understand it:

S1 = boolean, S2 = double
T1 = Boolean, T2 = Double
lub(T1, T2) = something assignment compatible with Object
capture applied to lub(T1, T2) = lub(T1, T2)

Therefore, the expression is valid and should yield Boolean.TRUE.  Eclipse seems to have applied boxing conversion to the second argument, but not to the third argument, and thus failed.

Oddly enough:

    Object obj = true ? true : Double.valueOf(17.3);

Eclipse gives the same error.  It converts true to type Boolean by boxing conversion, AND Double.valueOf(17.3) to double by unboxing conversion, and THEN gets stuck.
Good find. Indeed the compiler logic is wrong. It must promote both operands in this situation (bogus 'else' in between to IFs).

Added AutoboxingTest#test117
should backport to 3.1.x
Fixed in 3.2 and 3.1.x streams.
Verified for 3.2 M5 using build I20060215-0010</WithStack>
    <WithOutStack>Eclipse 3.2M3

public class Test
{
    public static void main(String[] args)
    {
        Object obj = true ? true : 17.3;
    }
}

Eclipse says:

Incompatible conditional operand types Boolean and double

JLS says:

Otherwise, the second and third operands are of types S1 and S2 respectively.  Let T1 be the type that results from applying boxing conversion to S1, and let T2 be the type that results from applying boxing conversion to S2.  The type of the conditional expression is the result of applying capture conversion to lub(T1, T2).

As I understand it:

S1 = boolean, S2 = double
T1 = Boolean, T2 = Double
lub(T1, T2) = something assignment compatible with Object
capture applied to lub(T1, T2) = lub(T1, T2)

Therefore, the expression is valid and should yield Boolean.TRUE.  Eclipse seems to have applied boxing conversion to the second argument, but not to the third argument, and thus failed.

Oddly enough:

    Object obj = true ? true : Double.valueOf(17.3);

Eclipse gives the same error.  It converts true to type Boolean by boxing conversion, AND Double.valueOf(17.3) to double by unboxing conversion, and THEN gets stuck.
Good find. Indeed the compiler logic is wrong. It must promote both operands in this situation (bogus 'else' in between to IFs).

Added AutoboxingTest#test117
should backport to 3.1.x
Fixed in 3.2 and 3.1.x streams.
Verified for 3.2 M5 using build I20060215-0010</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122988" />
    <CreationDate amount="2006-01-06 20:07:00 -0500" />
    <DupId amount="67384" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="SWT" />
    <Version amount="3.1.1" />
    <rep_platform amount="Macintosh" />
    <op_sys amount="Mac OS X - Carbon (unsup.)" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>SWT does not work with AWT and Swing</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="26">
      <source_code type="import">
        <location start="501" end="524" />
        <code>import java.awt.Color;</code>
      </source_code>
      <source_code type="import">
        <location start="525" end="546" />
        <code>import java.awt.Font;</code>
      </source_code>
      <source_code type="import">
        <location start="547" end="572" />
        <code>import java.awt.Graphics;</code>
      </source_code>
      <source_code type="import">
        <location start="573" end="609" />
        <code>import java.awt.image.BufferedImage;</code>
      </source_code>
      <source_code type="class">
        <location start="611" end="947" />
        <code>public class Awt  {

	public Awt()  {
		BufferedImage i=new BufferedImage(150,150,BufferedImage.TYPE_INT_RGB);
		Graphics gr=i.getGraphics();
		
		gr.setColor(new Color(100,0,0));
		gr.setFont(new Font("Helvetica",Font.BOLD,40));
		gr.drawString("textstring",30,30);
	}

	public static void main(String[] args) {
		Awt x=new Awt();
	}
}</code>
      </source_code>
      <source_code type="package">
        <location start="2204" end="2231" />
        <code>package de.klinkerjens.swt;</code>
      </source_code>
      <source_code type="import">
        <location start="2232" end="2255" />
        <code>import java.awt.Color;</code>
      </source_code>
      <source_code type="import">
        <location start="2256" end="2277" />
        <code>import java.awt.Font;</code>
      </source_code>
      <source_code type="import">
        <location start="2278" end="2303" />
        <code>import java.awt.Graphics;</code>
      </source_code>
      <source_code type="import">
        <location start="2304" end="2340" />
        <code>import java.awt.image.BufferedImage;</code>
      </source_code>
      <source_code type="import">
        <location start="2341" end="2377" />
        <code>import java.io.ByteArrayInputStream;</code>
      </source_code>
      <source_code type="import">
        <location start="2378" end="2415" />
        <code>import java.io.ByteArrayOutputStream;</code>
      </source_code>
      <source_code type="import">
        <location start="2416" end="2444" />
        <code>import org.eclipse.swt.SWT;</code>
      </source_code>
      <source_code type="import">
        <location start="2445" end="2492" />
        <code>import org.eclipse.swt.events.SelectionAdapter;</code>
      </source_code>
      <source_code type="import">
        <location start="2493" end="2538" />
        <code>import org.eclipse.swt.events.SelectionEvent;</code>
      </source_code>
      <source_code type="import">
        <location start="2539" end="2577" />
        <code>import org.eclipse.swt.graphics.Image;</code>
      </source_code>
      <source_code type="import">
        <location start="2578" end="2619" />
        <code>import org.eclipse.swt.layout.FillLayout;</code>
      </source_code>
      <source_code type="import">
        <location start="2620" end="2658" />
        <code>import org.eclipse.swt.widgets.Button;</code>
      </source_code>
      <source_code type="import">
        <location start="2659" end="2698" />
        <code>import org.eclipse.swt.widgets.Display;</code>
      </source_code>
      <source_code type="import">
        <location start="2699" end="2735" />
        <code>import org.eclipse.swt.widgets.Menu;</code>
      </source_code>
      <source_code type="import">
        <location start="2736" end="2776" />
        <code>import org.eclipse.swt.widgets.MenuItem;</code>
      </source_code>
      <source_code type="import">
        <location start="2777" end="2814" />
        <code>import org.eclipse.swt.widgets.Shell;</code>
      </source_code>
      <source_code type="import">
        <location start="2815" end="2858" />
        <code>import com.sun.image.codec.jpeg.JPEGCodec;</code>
      </source_code>
      <source_code type="import">
        <location start="2859" end="2907" />
        <code>import com.sun.image.codec.jpeg.JPEGEncodeParam;</code>
      </source_code>
      <source_code type="import">
        <location start="2908" end="2957" />
        <code>import com.sun.image.codec.jpeg.JPEGImageEncoder;</code>
      </source_code>
      <source_code type="class">
        <location start="2959" end="4901" />
        <code>public class Swt {
	 private Display display;
	 private Shell shell;

	public Swt() {
	
	SelectionAdapter clickAdapter=new SelectionAdapter(){
		public void widgetSelected (SelectionEvent se){
			
			if (!shell.getText().equals("click")) shell.setText("click"); else shell.setText("unclick");
		}
	 };
		 
	display = new Display();
	shell = new Shell(display);
	shell.setSize(500,500);
	shell.setText("Simple SWT Sample");
	shell.setLayout(new FillLayout());
	Button b=new Button(shell,SWT.NONE);

	BufferedImage i=new BufferedImage(150,150,BufferedImage.TYPE_INT_RGB);
	Graphics gr=i.getGraphics();
	
	gr.setColor(new Color(100,0,0));
	gr.setFont(new Font("Helvetica",Font.BOLD,40));
	gr.drawString("textstring",30,30);
	ByteArrayOutputStream fo=new ByteArrayOutputStream();
	
	JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder (fo) ;

	   JPEGEncodeParam param =
		      encoder.getDefaultJPEGEncodeParam(i);
		   param.setQuality(1.0f,true);
	
	try{
		encoder.encode(i,param) ;
	} catch (Exception e){}
	
	b.setImage(new Image(display,new ByteArrayInputStream(fo.toByteArray())));
	
	b.addSelectionListener(clickAdapter);
	Menu menubar=new Menu(shell,SWT.BAR);
	shell.setMenuBar(menubar);
	
	Menu fileMenu = new Menu(menubar);
	MenuItem fileMenuItem = new MenuItem(menubar,SWT.CASCADE);
	fileMenuItem.setText("File");
	fileMenuItem.setMenu(fileMenu);
	
	MenuItem neu = new MenuItem(fileMenu,SWT.CASCADE);
	neu.setText("neu");
	 	 
	new MenuItem (fileMenu,SWT.SEPARATOR);
	 
	Menu subMenu=new Menu(fileMenu);
	MenuItem subMenuItem=new MenuItem(fileMenu,SWT.CASCADE);
	subMenuItem.setText("submenu");
	subMenuItem.setMenu(subMenu);
	 
	MenuItem neuSubMenu=new MenuItem(subMenu,SWT.CASCADE);
	neuSubMenu.setText("neusub");
	 
	neuSubMenu.addSelectionListener(clickAdapter);

	shell.open();
	while (!shell.isDisposed())
	if (!display.readAndDispatch())
	 display.sleep();
	 }

	public static void main(String[] args) {

		new Swt();
	}

}</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="DUPLICATE" />
    <WithStack>I use Mac OS X 10.3.9, Java 1.4.2, Eclipse IDE 3.0 and SWT 3.1.1 and have the following problem (with Java 1.3.1 everything works. On the command-line it also seem to work with Java 1.4.2 but not when I start it from Eclipse IDE 3.0):

If I add the swt.jar to my classpath, I can´t use the awt.Graphics and the awt.image.BufferedImage classes. I also can´t use the following command in any class: "JFrame x=new JFrame();" (also not if it is the only row in a very little class).

This is my awt-code:

import java.awt.Color;
import java.awt.Font;
import java.awt.Graphics;
import java.awt.image.BufferedImage;

public class Awt  {

	public Awt()  {
		BufferedImage i=new BufferedImage(150,150,BufferedImage.TYPE_INT_RGB);
		Graphics gr=i.getGraphics();
		
		gr.setColor(new Color(100,0,0));
		gr.setFont(new Font("Helvetica",Font.BOLD,40));
		gr.drawString("textstring",30,30);
	}

	public static void main(String[] args) {
		Awt x=new Awt();
	}
}

This is the error in the Eclipse IDE 3.0:

2006-01-07 01:56:28.413 java_swt[500] Apple AWT Java VM was loaded on first thread -- can't start AWT.
Exception in thread "main" java.lang.InternalError: Can't start the AWT because Java was started on the first thread.  Make sure StartOnFirstThread is not specified in your application's Info.plist or on the command line
	at java.lang.ClassLoader$NativeLibrary.load(Native Method)
	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1586)
	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1503)
	at java.lang.Runtime.loadLibrary0(Runtime.java:788)
	at java.lang.System.loadLibrary(System.java:834)
	at sun.security.action.LoadLibraryAction.run(LoadLibraryAction.java:50)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.awt.image.ColorModel.loadLibraries(ColorModel.java:188)
	at java.awt.image.ColorModel.&lt;clinit&gt;(ColorModel.java:196)
	at java.awt.image.BufferedImage.&lt;clinit&gt;(BufferedImage.java:212)
	at Awt.&lt;init&gt;(Awt.java:15)
	at Awt.main(Awt.java:34)
Another problem: The following code returns the same error in Eclipse IDE and creates a not reacting-app when started on the command-line (java -Djava.library.path=/swt -classpath /swt/swt.jar:. de.klinkerjens.swt.Swt):

package de.klinkerjens.swt;

import java.awt.Color;
import java.awt.Font;
import java.awt.Graphics;
import java.awt.image.BufferedImage;
import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;

import org.eclipse.swt.SWT;
import org.eclipse.swt.events.SelectionAdapter;
import org.eclipse.swt.events.SelectionEvent;
import org.eclipse.swt.graphics.Image;
import org.eclipse.swt.layout.FillLayout;
import org.eclipse.swt.widgets.Button;
import org.eclipse.swt.widgets.Display;
import org.eclipse.swt.widgets.Menu;
import org.eclipse.swt.widgets.MenuItem;
import org.eclipse.swt.widgets.Shell;

import com.sun.image.codec.jpeg.JPEGCodec;
import com.sun.image.codec.jpeg.JPEGEncodeParam;
import com.sun.image.codec.jpeg.JPEGImageEncoder;

public class Swt {
	 private Display display;
	 private Shell shell;

	public Swt() {
	
	SelectionAdapter clickAdapter=new SelectionAdapter(){
		public void widgetSelected (SelectionEvent se){
			
			if (!shell.getText().equals("click")) shell.setText("click"); else shell.setText("unclick");
		}
	 };
		 
	display = new Display();
	shell = new Shell(display);
	shell.setSize(500,500);
	shell.setText("Simple SWT Sample");
	shell.setLayout(new FillLayout());
	Button b=new Button(shell,SWT.NONE);

	BufferedImage i=new BufferedImage(150,150,BufferedImage.TYPE_INT_RGB);
	Graphics gr=i.getGraphics();
	
	gr.setColor(new Color(100,0,0));
	gr.setFont(new Font("Helvetica",Font.BOLD,40));
	gr.drawString("textstring",30,30);
	ByteArrayOutputStream fo=new ByteArrayOutputStream();
	
	JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder (fo) ;

	   JPEGEncodeParam param =
		      encoder.getDefaultJPEGEncodeParam(i);
		   param.setQuality(1.0f,true);
	
	try{
		encoder.encode(i,param) ;
	} catch (Exception e){}
	
	b.setImage(new Image(display,new ByteArrayInputStream(fo.toByteArray())));
	
	b.addSelectionListener(clickAdapter);
	Menu menubar=new Menu(shell,SWT.BAR);
	shell.setMenuBar(menubar);
	
	Menu fileMenu = new Menu(menubar);
	MenuItem fileMenuItem = new MenuItem(menubar,SWT.CASCADE);
	fileMenuItem.setText("File");
	fileMenuItem.setMenu(fileMenu);
	
	MenuItem neu = new MenuItem(fileMenu,SWT.CASCADE);
	neu.setText("neu");
	 	 
	new MenuItem (fileMenu,SWT.SEPARATOR);
	 
	Menu subMenu=new Menu(fileMenu);
	MenuItem subMenuItem=new MenuItem(fileMenu,SWT.CASCADE);
	subMenuItem.setText("submenu");
	subMenuItem.setMenu(subMenu);
	 
	MenuItem neuSubMenu=new MenuItem(subMenu,SWT.CASCADE);
	neuSubMenu.setText("neusub");
	 
	neuSubMenu.addSelectionListener(clickAdapter);

	shell.open();
	while (!shell.isDisposed())
	if (!display.readAndDispatch())
	 display.sleep();
	 }

	public static void main(String[] args) {

		new Swt();
	}

}

Jens, it's a duplicate of bug 67384. Vote for it :-)
The non-reacting shell is a dupliate of bug #67384.  The original problem is not.
&gt;Exception in thread "main" java.lang.InternalError: Can't start the AWT &gt;because Java was started on the first thread.  Make sure StartOnFirstThread
&gt;is not specified in your application's Info.plist or on the command line

Did you investigate this?  Due to bug 67384, SWT interop with AWT/Swing does not work, however, just having the SWT jar on the path and not referencing any SWT classes shouldn't be a problem.  I suspect you have StartOnFirstThread (a flag that is necessary to run SWT) turned on somewhere.

I'm marking this as a dup of 67384 because this intent is that both toolkits should work together.


*** This bug has been marked as a duplicate of 67384 ***
the second code-example doesn´t work at all (neither on the shell or on eclipse 3.0). I don´t use the "-XStartOnFirstThread"-option. I´ve wrote already that I use the command "java
-Djava.library.path=/swt -classpath /swt/swt.jar:. de.klinkerjens.swt.Swt"
I was confused because this bug report contains two problems.  The AWT program doesn't work and the SWT program is not reacting. 

Specify -XstartOnFirstThread on the command line for the SWT program and it should work.  Sorry about that.  The FAQ on the SWT page in this ares is way out of date.</WithStack>
    <WithOutStack>I use Mac OS X 10.3.9, Java 1.4.2, Eclipse IDE 3.0 and SWT 3.1.1 and have the following problem (with Java 1.3.1 everything works. On the command-line it also seem to work with Java 1.4.2 but not when I start it from Eclipse IDE 3.0):

If I add the swt.jar to my classpath, I can´t use the awt.Graphics and the awt.image.BufferedImage classes. I also can´t use the following command in any class: "JFrame x=new JFrame();" (also not if it is the only row in a very little class).

This is my awt-code:

import java.awt.Color;
import java.awt.Font;
import java.awt.Graphics;
import java.awt.image.BufferedImage;

public class Awt  {

	public Awt()  {
		BufferedImage i=new BufferedImage(150,150,BufferedImage.TYPE_INT_RGB);
		Graphics gr=i.getGraphics();
		
		gr.setColor(new Color(100,0,0));
		gr.setFont(new Font("Helvetica",Font.BOLD,40));
		gr.drawString("textstring",30,30);
	}

	public static void main(String[] args) {
		Awt x=new Awt();
	}
}

This is the error in the Eclipse IDE 3.0:

2006-01-07 01:56:28.413 java_swt[500] Apple AWT Java VM was loaded on first thread -- can't start AWT.
Exception in thread "main" java.lang.InternalError: Can't start the AWT because Java was started on the first thread.  Make sure StartOnFirstThread is not specified in your application's Info.plist or on the command line
	at java.lang.ClassLoader$NativeLibrary.load(Native Method)
	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1586)
	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1503)
	at java.lang.Runtime.loadLibrary0(Runtime.java:788)
	at java.lang.System.loadLibrary(System.java:834)
	at sun.security.action.LoadLibraryAction.run(LoadLibraryAction.java:50)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.awt.image.ColorModel.loadLibraries(ColorModel.java:188)
	at java.awt.image.ColorModel.&lt;clinit&gt;(ColorModel.java:196)
	at java.awt.image.BufferedImage.&lt;clinit&gt;(BufferedImage.java:212)
	at Awt.&lt;init&gt;(Awt.java:15)
	at Awt.main(Awt.java:34)
Another problem: The following code returns the same error in Eclipse IDE and creates a not reacting-app when started on the command-line (java -Djava.library.path=/swt -classpath /swt/swt.jar:. de.klinkerjens.swt.Swt):

package de.klinkerjens.swt;

import java.awt.Color;
import java.awt.Font;
import java.awt.Graphics;
import java.awt.image.BufferedImage;
import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;

import org.eclipse.swt.SWT;
import org.eclipse.swt.events.SelectionAdapter;
import org.eclipse.swt.events.SelectionEvent;
import org.eclipse.swt.graphics.Image;
import org.eclipse.swt.layout.FillLayout;
import org.eclipse.swt.widgets.Button;
import org.eclipse.swt.widgets.Display;
import org.eclipse.swt.widgets.Menu;
import org.eclipse.swt.widgets.MenuItem;
import org.eclipse.swt.widgets.Shell;

import com.sun.image.codec.jpeg.JPEGCodec;
import com.sun.image.codec.jpeg.JPEGEncodeParam;
import com.sun.image.codec.jpeg.JPEGImageEncoder;

public class Swt {
	 private Display display;
	 private Shell shell;

	public Swt() {
	
	SelectionAdapter clickAdapter=new SelectionAdapter(){
		public void widgetSelected (SelectionEvent se){
			
			if (!shell.getText().equals("click")) shell.setText("click"); else shell.setText("unclick");
		}
	 };
		 
	display = new Display();
	shell = new Shell(display);
	shell.setSize(500,500);
	shell.setText("Simple SWT Sample");
	shell.setLayout(new FillLayout());
	Button b=new Button(shell,SWT.NONE);

	BufferedImage i=new BufferedImage(150,150,BufferedImage.TYPE_INT_RGB);
	Graphics gr=i.getGraphics();
	
	gr.setColor(new Color(100,0,0));
	gr.setFont(new Font("Helvetica",Font.BOLD,40));
	gr.drawString("textstring",30,30);
	ByteArrayOutputStream fo=new ByteArrayOutputStream();
	
	JPEGImageEncoder encoder = JPEGCodec.createJPEGEncoder (fo) ;

	   JPEGEncodeParam param =
		      encoder.getDefaultJPEGEncodeParam(i);
		   param.setQuality(1.0f,true);
	
	try{
		encoder.encode(i,param) ;
	} catch (Exception e){}
	
	b.setImage(new Image(display,new ByteArrayInputStream(fo.toByteArray())));
	
	b.addSelectionListener(clickAdapter);
	Menu menubar=new Menu(shell,SWT.BAR);
	shell.setMenuBar(menubar);
	
	Menu fileMenu = new Menu(menubar);
	MenuItem fileMenuItem = new MenuItem(menubar,SWT.CASCADE);
	fileMenuItem.setText("File");
	fileMenuItem.setMenu(fileMenu);
	
	MenuItem neu = new MenuItem(fileMenu,SWT.CASCADE);
	neu.setText("neu");
	 	 
	new MenuItem (fileMenu,SWT.SEPARATOR);
	 
	Menu subMenu=new Menu(fileMenu);
	MenuItem subMenuItem=new MenuItem(fileMenu,SWT.CASCADE);
	subMenuItem.setText("submenu");
	subMenuItem.setMenu(subMenu);
	 
	MenuItem neuSubMenu=new MenuItem(subMenu,SWT.CASCADE);
	neuSubMenu.setText("neusub");
	 
	neuSubMenu.addSelectionListener(clickAdapter);

	shell.open();
	while (!shell.isDisposed())
	if (!display.readAndDispatch())
	 display.sleep();
	 }

	public static void main(String[] args) {

		new Swt();
	}

}

Jens, it's a duplicate of bug 67384. Vote for it :-)
The non-reacting shell is a dupliate of bug #67384.  The original problem is not.
&gt;Exception in thread "main" java.lang.InternalError: Can't start the AWT &gt;because Java was started on the first thread.  Make sure StartOnFirstThread
&gt;is not specified in your application's Info.plist or on the command line

Did you investigate this?  Due to bug 67384, SWT interop with AWT/Swing does not work, however, just having the SWT jar on the path and not referencing any SWT classes shouldn't be a problem.  I suspect you have StartOnFirstThread (a flag that is necessary to run SWT) turned on somewhere.

I'm marking this as a dup of 67384 because this intent is that both toolkits should work together.


*** This bug has been marked as a duplicate of 67384 ***
the second code-example doesn´t work at all (neither on the shell or on eclipse 3.0). I don´t use the "-XStartOnFirstThread"-option. I´ve wrote already that I use the command "java
-Djava.library.path=/swt -classpath /swt/swt.jar:. de.klinkerjens.swt.Swt"
I was confused because this bug report contains two problems.  The AWT program doesn't work and the SWT program is not reacting. 

Specify -XstartOnFirstThread on the command line for the SWT program and it should work.  Sorry about that.  The FAQ on the SWT page in this ares is way out of date.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122989" />
    <CreationDate amount="2006-01-06 20:27:00 -0500" />
    <DupId amount="" />
    <classification amount="Modeling" />
    <Product amount="EMF" />
    <component amount="Core" />
    <Version amount="2.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>ChangeRecorder throws NPE with EReference.upperbounds &gt;1</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="4">
      <source_code type="assignment">
        <location start="143" end="189" />
        <code>EStructuralFeature feature = getFeature();</code>
      </source_code>
      <source_code type="ifstatement">
        <location start="190" end="234" />
        <code>if (feature.getUpperBound() &lt; 0)
      {</code>
      </source_code>
      <source_code type="assignment">
        <location start="305" end="351" />
        <code>EStructuralFeature feature = getFeature();</code>
      </source_code>
      <source_code type="ifstatement">
        <location start="352" end="427" />
        <code>if (feature.getUpperBound() &lt; 0 || feature.getUpperBound() &gt; 1)
      {</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="VERIFIED" />
    <resolution amount="FIXED" />
    <WithStack>In class 
org.eclipse.emf.ecore.change.impl.FeatureChangeImpl
of EMF 2.1.1

the method getValue() is coded like:

public Object getValue()
  {
    EStructuralFeature feature = getFeature();
    if (feature.getUpperBound() &lt; 0)
      {

but should be fixed to something like:

public Object getValue()
  {
    EStructuralFeature feature = getFeature();
    if (feature.getUpperBound() &lt; 0 || feature.getUpperBound() &gt; 1)
      {

This because if cardinality (upperbounds) of a EReference is multiple, eg 2, but not -1 or -2, then ChangeRecorder throws an exception (AFAIR a NullPointerException) when finalizing changes using UML2 ...common.edit.ChangeCommand.
The fix was committed to CVS.  Thanks for reporting the problem and suggesting a fix.
Fixed in 2.2.0 I200601260027
Move to verified as per bug 206558.</WithStack>
    <WithOutStack>In class 
org.eclipse.emf.ecore.change.impl.FeatureChangeImpl
of EMF 2.1.1

the method getValue() is coded like:

public Object getValue()
  {
    EStructuralFeature feature = getFeature();
    if (feature.getUpperBound() &lt; 0)
      {

but should be fixed to something like:

public Object getValue()
  {
    EStructuralFeature feature = getFeature();
    if (feature.getUpperBound() &lt; 0 || feature.getUpperBound() &gt; 1)
      {

This because if cardinality (upperbounds) of a EReference is multiple, eg 2, but not -1 or -2, then ChangeRecorder throws an exception (AFAIR a NullPointerException) when finalizing changes using UML2 ...common.edit.ChangeCommand.
The fix was committed to CVS.  Thanks for reporting the problem and suggesting a fix.
Fixed in 2.2.0 I200601260027
Move to verified as per bug 206558.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122990" />
    <CreationDate amount="2006-01-06 20:44:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="Debug" />
    <Version amount="3.1.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Linux" />
    <priority amount="P3" />
    <bug_severity amount="enhancement" />
    <Summery>Debug Perspective, tooltops over variables, to display values of boxed primative types</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="WORKSFORME" />
    <WithStack>For all non-array Java primitive boxed objects, it would be really nice to display the value in decimal (123) and hexadecimal (0x123) in the tooltip bubble.

The String data type is an excellant example of usefully displaying the value of the object, not some weird id=## value which seems of little use to the developer.

This would cover but not limited to Boolean, Byte, Short, Integer, Long types.
The tooltip displays whatever the variables view is configured to display. See "Java Primitives..." in the variables view drop down menu and select "hexidecimal".</WithStack>
    <WithOutStack>For all non-array Java primitive boxed objects, it would be really nice to display the value in decimal (123) and hexadecimal (0x123) in the tooltip bubble.

The String data type is an excellant example of usefully displaying the value of the object, not some weird id=## value which seems of little use to the developer.

This would cover but not limited to Boolean, Byte, Short, Integer, Long types.
The tooltip displays whatever the variables view is configured to display. See "Java Primitives..." in the variables view drop down menu and select "hexidecimal".</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122991" />
    <CreationDate amount="2006-01-06 20:54:00 -0500" />
    <DupId amount="103381" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="Debug" />
    <Version amount="3.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows 2000" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Infinite Recursion Evaluating Self Referencing Object</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="1">
      <source_code type="class">
        <location start="346" end="562" />
        <code>public class Bug {
	static class SelfRef {
		SelfRef ref1 = SelfRef.this; 
		SelfRef ref2 = SelfRef.this; 
	}
	public static void main(String [] args) {
		SelfRef a = new SelfRef();
		System.out.println(a.ref1);
	}
}</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="DUPLICATE" />
    <WithStack>When evaluating an object instance which has more than one field referencing itself, the debugger either hangs or updates the display recursively, scrolling infinitely. I spotted this while implementing a doubly linked list so I would think it's fairly common idiom. Simply step into the following and select 'a' for evaluation after assigment:

public class Bug {
	static class SelfRef {
		SelfRef ref1 = SelfRef.this; 
		SelfRef ref2 = SelfRef.this; 
	}
	public static void main(String [] args) {
		SelfRef a = new SelfRef();
		System.out.println(a.ref1);
	}
}
Fixed in 3.1.1 and later

*** This bug has been marked as a duplicate of 103381 ***</WithStack>
    <WithOutStack>When evaluating an object instance which has more than one field referencing itself, the debugger either hangs or updates the display recursively, scrolling infinitely. I spotted this while implementing a doubly linked list so I would think it's fairly common idiom. Simply step into the following and select 'a' for evaluation after assigment:

public class Bug {
	static class SelfRef {
		SelfRef ref1 = SelfRef.this; 
		SelfRef ref2 = SelfRef.this; 
	}
	public static void main(String [] args) {
		SelfRef a = new SelfRef();
		System.out.println(a.ref1);
	}
}
Fixed in 3.1.1 and later

*** This bug has been marked as a duplicate of 103381 ***</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122992" />
    <CreationDate amount="2006-01-06 21:11:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="Platform" />
    <component amount="Resources" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Bug in ResourceTraversal#contains</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>There is a bug in the ResourceTraversal#contains method. I will attach a patch.
Created attachment 32635
Bug fix

The bug is that containment will match for a child of a resource in the traversal even if the depth of the traversal is zero.
Patch released.</WithStack>
    <WithOutStack>There is a bug in the ResourceTraversal#contains method. I will attach a patch.
Created attachment 32635
Bug fix

The bug is that containment will match for a child of a resource in the traversal even if the depth of the traversal is zero.
Patch released.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122993" />
    <CreationDate amount="2006-01-06 21:30:00 -0500" />
    <DupId amount="" />
    <classification amount="RT" />
    <Product amount="Equinox" />
    <component amount="Compendium" />
    <Version amount="3.2" />
    <rep_platform amount="Macintosh" />
    <op_sys amount="Mac OS X - Carbon (unsup.)" />
    <priority amount="P3" />
    <bug_severity amount="trivial" />
    <Summery>[metatype service] AttributeDefinitionImpl attempts to localize option values</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="2">
      <source_code type="assignment">
        <location start="927" end="970" />
        <code>returnedValues[i] = getLocalized(valueKey);</code>
      </source_code>
      <source_code type="assignment">
        <location start="999" end="1028" />
        <code>returnedValues[i] = valueKey;</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="1">
      <Enumeration lines="2">
        <Lines>
          <Line>1. there is no translation for the value in the resource bundles, but the % as first character will be removed</Line>
          <Line>2. there is a translation for the value in the resource bundle (i.e. the value matches another localized attribute name) and the value will be translated to the localization of that attribute name.</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>The AttributeDefinitionImpl class will attempt to localize the option value if prefixed with a %.
I don't think that the localization mechanism should attempt to localize any attribute value (an option value is basically a possible attribute value), so I think this is a bug.

There are two hypothetic cases in which the implementation will cause troubles, altering the attributes value:
1. there is no translation for the value in the resource bundles, but the % as first character will be removed
2. there is a translation for the value in the resource bundle (i.e. the value matches another localized attribute name) and the value will be translated to the localization of that attribute name.

I agree that the probability is low that a value will be prefixed with a % AND that it matches
some other localized name, but I think that this should be fixed.

The code causing this problem is in the getOptionValues() method: 
returnedValues[i] = getLocalized(valueKey);
which should probably read:
returnedValues[i] = valueKey;

Regards,
Dieter
Dieter, there are no such class in equinox. Could you please give the fully qualified name of the class?
Pascal,

The fully qualified name of this class is:
org.eclipse.equinox.metatype.AttributeDefinitionImpl

Sorry that I did not specify the actual bundle. Probably each bundle implementation should be a component by itself.

Regards,
Dieter
Jennifer please investigate.  If you think a fix should be included in 3.2 please provide a patch for review.
Created attachment 171191
proposed patch

If I read the spec correctly, option values should not be translated.  The proposed patch returns the option values untranslated.
Tom, are there any unit tests for metatype?  I couldn't find any in CVS.
(In reply to comment #5)
&gt; Tom, are there any unit tests for metatype?  I couldn't find any in CVS.

No, we have been using the OSGi CT to test.  We need more tests in Equinox for this.
John, here is another meta-type bug to investigate.
(In reply to comment #7)
&gt; John, here is another meta-type bug to investigate.

Option values should not be localized. These are meant for computer, not human, consumption. Any modification could, and probably would, result in unrecognizable input to the target system.

I don't see any necessary or desired changes to the current patch.
Thanks I will review and release for M3.
Patch released.  This is quite obvious and I am surprised it has not really been much of an issue for folks.

Thanks Brian and John.</WithStack>
    <WithOutStack>The AttributeDefinitionImpl class will attempt to localize the option value if prefixed with a %.
I don't think that the localization mechanism should attempt to localize any attribute value (an option value is basically a possible attribute value), so I think this is a bug.

There are two hypothetic cases in which the implementation will cause troubles, altering the attributes value:
1. there is no translation for the value in the resource bundles, but the % as first character will be removed
2. there is a translation for the value in the resource bundle (i.e. the value matches another localized attribute name) and the value will be translated to the localization of that attribute name.

I agree that the probability is low that a value will be prefixed with a % AND that it matches
some other localized name, but I think that this should be fixed.

The code causing this problem is in the getOptionValues() method: 
returnedValues[i] = getLocalized(valueKey);
which should probably read:
returnedValues[i] = valueKey;

Regards,
Dieter
Dieter, there are no such class in equinox. Could you please give the fully qualified name of the class?
Pascal,

The fully qualified name of this class is:
org.eclipse.equinox.metatype.AttributeDefinitionImpl

Sorry that I did not specify the actual bundle. Probably each bundle implementation should be a component by itself.

Regards,
Dieter
Jennifer please investigate.  If you think a fix should be included in 3.2 please provide a patch for review.
Created attachment 171191
proposed patch

If I read the spec correctly, option values should not be translated.  The proposed patch returns the option values untranslated.
Tom, are there any unit tests for metatype?  I couldn't find any in CVS.
(In reply to comment #5)
&gt; Tom, are there any unit tests for metatype?  I couldn't find any in CVS.

No, we have been using the OSGi CT to test.  We need more tests in Equinox for this.
John, here is another meta-type bug to investigate.
(In reply to comment #7)
&gt; John, here is another meta-type bug to investigate.

Option values should not be localized. These are meant for computer, not human, consumption. Any modification could, and probably would, result in unrecognizable input to the target system.

I don't see any necessary or desired changes to the current patch.
Thanks I will review and release for M3.
Patch released.  This is quite obvious and I am surprised it has not really been much of an issue for folks.

Thanks Brian and John.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122994" />
    <CreationDate amount="2006-01-06 21:32:00 -0500" />
    <DupId amount="" />
    <classification amount="WebTools" />
    <Product amount="WTP ServerTools" />
    <component amount="wst.server" />
    <Version amount="1.0.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Need PUBLISH_CLEAN</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>Currently, the server adapter API supports 3 modes of publishing: incremental, full and clean.

However, from the UI, we can only trigger incremental. Full (or clean) publish is often needed. 

I think we can simply add an UI item on the right-click-menu on the Servers view, such as "Republish".

It would be really great if it can be added to 1.0.1 release.
Technically, I don't think I'm allowed to add new UI in 1.0.1. :)

If incremental publishing is working correctly, then there shouldn't be any need for the Clean option (which is planned for 1.5 via another bug). Is the real problem here that you are hitting problems or bugs with incremental publishing for a specific server type or scenario?
The incremental publish work correctly. However, in some edge case error situations for us, the module might simply be inconsistence on the server. 

Without PUBLISH_CLEAN as an option, user hitting such a scenario will have to remove all modules, republish, and add module back manually. It creates a major pain point for him.
Code ready, waiting for M4 to complete to drop changes.
Change released to 2.0 M5 builds.
Closing.</WithStack>
    <WithOutStack>Currently, the server adapter API supports 3 modes of publishing: incremental, full and clean.

However, from the UI, we can only trigger incremental. Full (or clean) publish is often needed. 

I think we can simply add an UI item on the right-click-menu on the Servers view, such as "Republish".

It would be really great if it can be added to 1.0.1 release.
Technically, I don't think I'm allowed to add new UI in 1.0.1. :)

If incremental publishing is working correctly, then there shouldn't be any need for the Clean option (which is planned for 1.5 via another bug). Is the real problem here that you are hitting problems or bugs with incremental publishing for a specific server type or scenario?
The incremental publish work correctly. However, in some edge case error situations for us, the module might simply be inconsistence on the server. 

Without PUBLISH_CLEAN as an option, user hitting such a scenario will have to remove all modules, republish, and add module back manually. It creates a major pain point for him.
Code ready, waiting for M4 to complete to drop changes.
Change released to 2.0 M5 builds.
Closing.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122995" />
    <CreationDate amount="2006-01-06 22:08:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="Core" />
    <Version amount="3.1.1" />
    <rep_platform amount="PC" />
    <op_sys amount="Linux" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>[1.5][compiler] Access rules don't apply to generic types</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="2">
      <source_code type="import">
        <location start="567" end="587" />
        <code>import java.util.*;</code>
      </source_code>
      <source_code type="class">
        <location start="589" end="724" />
        <code>public class Foo {
	public static void main(String[] args) {
		Date d = new Date();
		HashSet&lt;Integer&gt; s = new HashSet&lt;Integer&gt;();
	}
}</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="1">
      <Enumeration lines="13">
        <Lines>
          <Line>- BatchCompilerTest 39</Line>
          <Line>- AccessRestrictionsTests 6-10.</Line>
          <Line>Verification: see initial post.</Line>
          <Line>Pls backport fix to 3.1 maintenance stream.</Line>
          <Line>Maxime: Also add corresponding entry for legal tracking:</Line>
          <Line>Name: Matt McCutchen</Line>
          <Line>Company:</Line>
          <Line>Email: hashproduct@verizon.net</Line>
          <Line>Business Address:</Line>
          <Line>Business Phone:</Line>
          <Line>Contribution:</Line>
          <Line>provided part of patch for bug https://bugs.eclipse.org/bugs/show_bug.cgi?id=122995 ([1.5][compiler] Access rules don't apply to generic types)</Line>
          <Line>Title/Rights: EPL 1.0</Line>
        </Lines>
      </Enumeration>
    </Enumerations>
    <bug_status amount="VERIFIED" />
    <resolution amount="FIXED" />
    <WithStack>My Eclipse: version 3.1.1, build id M20050929-0840

Library access rules set on a Java project's build bath don't seem to apply to certain uses of generic types.  The access rule checker seems to miss parameterized references to a generic type available as a class file and both parameterized and raw references to a generic type available in a source file.

To reproduce this, make a new Java project.  In its Build Path properties, go to Libraries -&gt; JRE System Library -&gt; Access Rules.  Add a Forbidden rule for java/util/** .  Now, put the following in Foo.java:

import java.util.*;

public class Foo {
	public static void main(String[] args) {
		Date d = new Date();
		HashSet&lt;Integer&gt; s = new HashSet&lt;Integer&gt;();
	}
}

The reference to Date will cause an error as it should, but the reference to HashSet goes unnoticed.

I have no prior experience with the innards of the Eclipse compiler, but I decided to debug Eclipse anyway, and I think I found the problem.  HashSet&lt;Integer&gt; is represented by a ParameterizedTypeBinding, which is correctly flagged as having restricted access (bit 18 in its modifiers).  However, this ParameterizedTypeBinding fails to match the BinaryTypeBinding for HashSet itself, on which the AccessRestriction is registered in the LookupEnvironment's accessRestrictions map.  Thus ASTNode.isTypeUseDeprecated fails to notice the restriction.

In my copy of Eclipse, I changed ASTNode.isTypeUseDeprecated to look up the erasure of the type instead of the type itself.  That seemed to fix the problem, but I don't know if it is the best fix.  I'm including a patch for the CVS version, even though I had trouble running the CVS version my computer.
Created attachment 32636
Patch that fixes the problem by checking restrictions on erased type
Reproduced with v_632, see AccessRestrictionsTests#test006.
Created attachment 32973
New patch includes fields and methods access detection and further tests.

Test cases:
- BatchCompilerTest 39
- AccessRestrictionsTests 6-10.
Verification: see initial post.
Pls backport fix to 3.1 maintenance stream.
Maxime: Also add corresponding entry for legal tracking:
Name: Matt McCutchen
Company:
Email: hashproduct@verizon.net
Business Address:
Business Phone:
Contribution:
        provided part of patch for bug https://bugs.eclipse.org/bugs/show_bug.cgi?id=122995 ([1.5][compiler] Access rules don't apply to generic types)
Title/Rights: EPL 1.0

in R3_1_maintenace version of the contributions file.
Do you really think I would sue for ten bytes?  :)
Backported into branch R3_1_maintenance.
Note that 76266 is not backported, hence only types are involved (neither fields nor methods).
I just remembered a related bug: References to generic types are also overlooked by the Plugin Manifest Editor's "Find unused dependencies" feature, which could lead a user to remove a plugin from the dependency list when a generic type from that plugin is actually being used.  I noticed this together with the access rule bug and just reproduced it using the same Eclipse as before: version 3.1.1, build id M20050929-0840.

Does the existing patch fix this problem?  I am still having trouble running the CVS version of Eclipse, so I have no way to tell.
(In reply to comment #9)
&gt; Does the existing patch fix this problem?  I am still having trouble running
&gt; the CVS version of Eclipse, so I have no way to tell.
No, I could reproduce it with HEAD (as of yesterday night). Please file a separate bug or let me know if you want me to do it.

I filed bug 124489 against the PDE for the misbehavior of "Find unused dependencies".  I thought the problem might be related to an underlying deficiency in Java search for references, in which case I would have filed it against the JDT, but this doesn't seem to be the case.
Verified for 3.2 M5 using build I20060214-0010</WithStack>
    <WithOutStack>My Eclipse: version 3.1.1, build id M20050929-0840

Library access rules set on a Java project's build bath don't seem to apply to certain uses of generic types.  The access rule checker seems to miss parameterized references to a generic type available as a class file and both parameterized and raw references to a generic type available in a source file.

To reproduce this, make a new Java project.  In its Build Path properties, go to Libraries -&gt; JRE System Library -&gt; Access Rules.  Add a Forbidden rule for java/util/** .  Now, put the following in Foo.java:

import java.util.*;

public class Foo {
	public static void main(String[] args) {
		Date d = new Date();
		HashSet&lt;Integer&gt; s = new HashSet&lt;Integer&gt;();
	}
}

The reference to Date will cause an error as it should, but the reference to HashSet goes unnoticed.

I have no prior experience with the innards of the Eclipse compiler, but I decided to debug Eclipse anyway, and I think I found the problem.  HashSet&lt;Integer&gt; is represented by a ParameterizedTypeBinding, which is correctly flagged as having restricted access (bit 18 in its modifiers).  However, this ParameterizedTypeBinding fails to match the BinaryTypeBinding for HashSet itself, on which the AccessRestriction is registered in the LookupEnvironment's accessRestrictions map.  Thus ASTNode.isTypeUseDeprecated fails to notice the restriction.

In my copy of Eclipse, I changed ASTNode.isTypeUseDeprecated to look up the erasure of the type instead of the type itself.  That seemed to fix the problem, but I don't know if it is the best fix.  I'm including a patch for the CVS version, even though I had trouble running the CVS version my computer.
Created attachment 32636
Patch that fixes the problem by checking restrictions on erased type
Reproduced with v_632, see AccessRestrictionsTests#test006.
Created attachment 32973
New patch includes fields and methods access detection and further tests.

Test cases:
- BatchCompilerTest 39
- AccessRestrictionsTests 6-10.
Verification: see initial post.
Pls backport fix to 3.1 maintenance stream.
Maxime: Also add corresponding entry for legal tracking:
Name: Matt McCutchen
Company:
Email: hashproduct@verizon.net
Business Address:
Business Phone:
Contribution:
        provided part of patch for bug https://bugs.eclipse.org/bugs/show_bug.cgi?id=122995 ([1.5][compiler] Access rules don't apply to generic types)
Title/Rights: EPL 1.0

in R3_1_maintenace version of the contributions file.
Do you really think I would sue for ten bytes?  :)
Backported into branch R3_1_maintenance.
Note that 76266 is not backported, hence only types are involved (neither fields nor methods).
I just remembered a related bug: References to generic types are also overlooked by the Plugin Manifest Editor's "Find unused dependencies" feature, which could lead a user to remove a plugin from the dependency list when a generic type from that plugin is actually being used.  I noticed this together with the access rule bug and just reproduced it using the same Eclipse as before: version 3.1.1, build id M20050929-0840.

Does the existing patch fix this problem?  I am still having trouble running the CVS version of Eclipse, so I have no way to tell.
(In reply to comment #9)
&gt; Does the existing patch fix this problem?  I am still having trouble running
&gt; the CVS version of Eclipse, so I have no way to tell.
No, I could reproduce it with HEAD (as of yesterday night). Please file a separate bug or let me know if you want me to do it.

I filed bug 124489 against the PDE for the misbehavior of "Find unused dependencies".  I thought the problem might be related to an underlying deficiency in Java search for references, in which case I would have filed it against the JDT, but this doesn't seem to be the case.
Verified for 3.2 M5 using build I20060214-0010</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122996" />
    <CreationDate amount="2006-01-07 00:01:00 -0500" />
    <DupId amount="" />
    <classification amount="Mylyn" />
    <Product amount="Mylyn" />
    <component amount="Bugzilla" />
    <Version amount="0.4" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Clear task context menu is disabled bugzilla query items</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="FIXED" />
    <WithStack>Clear task context menu is disabled bugzilla query items
*** Bug 107263 has been marked as a duplicate of this bug. ***
This fixed itself with our task list architecture improvements.</WithStack>
    <WithOutStack>Clear task context menu is disabled bugzilla query items
*** Bug 107263 has been marked as a duplicate of this bug. ***
This fixed itself with our task list architecture improvements.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122997" />
    <CreationDate amount="2006-01-07 00:10:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse Foundation" />
    <Product amount="Community" />
    <component amount="Dashboard" />
    <Version amount="unspecified" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows All" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Phoenix-Eclipse package</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="CLOSED" />
    <resolution amount="FIXED" />
    <WithStack>A package should be built of Eclipse for Windows that is setup to do local development of Phoenix under the windows platform.

What we need is a Windows Installer install that sets up:
Eclipse configured to edit PHP files with PHPEclipse
Xampp (whatever that is - I think it's an Apache and PHP installation) configured to server pages from the Eclipse workspace.
Uses unexpected ports so that there isn't a port conflict problem. Say 8866 or something.
This has been built and fixed previously.

- Ken
Closed by OpenMex</WithStack>
    <WithOutStack>A package should be built of Eclipse for Windows that is setup to do local development of Phoenix under the windows platform.

What we need is a Windows Installer install that sets up:
Eclipse configured to edit PHP files with PHPEclipse
Xampp (whatever that is - I think it's an Apache and PHP installation) configured to server pages from the Eclipse workspace.
Uses unexpected ports so that there isn't a port conflict problem. Say 8866 or something.
This has been built and fixed previously.

- Ken
Closed by OpenMex</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122998" />
    <CreationDate amount="2006-01-07 00:14:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Report" />
    <Version amount="2.0.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>can not import lib</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="INVALID" />
    <WithStack>when i create birt lib (create dataset and datasource in lib)
and import to birt report dataset and datasource does not appear in report
Referencing a lib doesn't automatically include the data datasource and dataset into the report.  You will need to drag and drop the data source/data set from the lib into the report outline view.
Verified in build 20060110.
It's a invalid bug.</WithStack>
    <WithOutStack>when i create birt lib (create dataset and datasource in lib)
and import to birt report dataset and datasource does not appear in report
Referencing a lib doesn't automatically include the data datasource and dataset into the report.  You will need to drag and drop the data source/data set from the lib into the report outline view.
Verified in build 20060110.
It's a invalid bug.</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="122999" />
    <CreationDate amount="2006-01-07 02:07:00 -0500" />
    <DupId amount="" />
    <classification amount="Eclipse" />
    <Product amount="JDT" />
    <component amount="Core" />
    <Version amount="3.2" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>Generic compilation - Type referenced and declared as inner class cannot be resolved</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="4">
      <source_code type="import">
        <location start="105" end="133" />
        <code>import java.util.ArrayList;</code>
      </source_code>
      <source_code type="class">
        <location start="135" end="224" />
        <code>public class BeanArrayList extends ArrayList&lt;Bean&gt; {

   public static class Bean {}
	 
}</code>
      </source_code>
      <source_code type="import">
        <location start="814" end="842" />
        <code>import java.util.ArrayList;</code>
      </source_code>
      <source_code type="class">
        <location start="844" end="945" />
        <code>public class BeanArrayList extends ArrayList&lt;BeanArrayList.Bean&gt; {

   public static class Bean {}

}</code>
      </source_code>
    </SourceCodeRegions>
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="INVALID" />
    <WithStack>The code is hopefully self-explanatory.  It will not compile using the internal Eclipse compiler for 5.0

import java.util.ArrayList;

public class BeanArrayList extends ArrayList&lt;Bean&gt; {

   public static class Bean {}
	 
}

even if the class is not static, it cannot resolve the type
the compiler error is "Bean cannot be resolved to a type"

if you move the member type to new file, it compiles fine.
This is the intended behavior; and javac 1.6 agrees with us.
Added GenericTypeTest#test0975
closing
(In reply to comment #2)
&gt; Added GenericTypeTest#test0975
&gt; closing
&gt; 

In the meantime, I had found a workaround that compiles in Eclipse.  Is this invalid as well? If you have the time, I would be interested in knowing what part of the specification or a brief summary of why this is the intended behaviour.

import java.util.ArrayList;

public class BeanArrayList extends ArrayList&lt;BeanArrayList.Bean&gt; {

   public static class Bean {}

}
Bean is not considered to be in scope for resolving type name of type argument. However, BeanArrayList is. Thus the qualified form will allow to find the member type, but not the simple form.

Now, I agree that from reading the spec, it is unclear why the simple name shouldn't work as well; since per essence its scope is intended to be the entire body of BeanArrayList, considering JLS 6.3:

"The scope of a declaration of a member m declared in or inherited by a class
type C is the entire body of C, including any nested type declarations."
Actually, the spec is pretty clear, and I didn't read it well enough (thanks Peter and Tim). The scope only comprises the BeanArrayList body (in between the curly braces).</WithStack>
    <WithOutStack>The code is hopefully self-explanatory.  It will not compile using the internal Eclipse compiler for 5.0

import java.util.ArrayList;

public class BeanArrayList extends ArrayList&lt;Bean&gt; {

   public static class Bean {}
	 
}

even if the class is not static, it cannot resolve the type
the compiler error is "Bean cannot be resolved to a type"

if you move the member type to new file, it compiles fine.
This is the intended behavior; and javac 1.6 agrees with us.
Added GenericTypeTest#test0975
closing
(In reply to comment #2)
&gt; Added GenericTypeTest#test0975
&gt; closing
&gt; 

In the meantime, I had found a workaround that compiles in Eclipse.  Is this invalid as well? If you have the time, I would be interested in knowing what part of the specification or a brief summary of why this is the intended behaviour.

import java.util.ArrayList;

public class BeanArrayList extends ArrayList&lt;BeanArrayList.Bean&gt; {

   public static class Bean {}

}
Bean is not considered to be in scope for resolving type name of type argument. However, BeanArrayList is. Thus the qualified form will allow to find the member type, but not the simple form.

Now, I agree that from reading the spec, it is unclear why the simple name shouldn't work as well; since per essence its scope is intended to be the entire body of BeanArrayList, considering JLS 6.3:

"The scope of a declaration of a member m declared in or inherited by a class
type C is the entire body of C, including any nested type declarations."
Actually, the spec is pretty clear, and I didn't read it well enough (thanks Peter and Tim). The scope only comprises the BeanArrayList body (in between the curly braces).</WithOutStack>
  </Bug>
  <Bug>
    <BugId amount="123000" />
    <CreationDate amount="2006-01-07 03:19:00 -0500" />
    <DupId amount="" />
    <classification amount="BIRT" />
    <Product amount="BIRT" />
    <component amount="Report Viewer" />
    <Version amount="2.0.0" />
    <rep_platform amount="PC" />
    <op_sys amount="Windows XP" />
    <priority amount="P3" />
    <bug_severity amount="normal" />
    <Summery>org.eclipse.birt.report.designer.ui.rcp pdf preview error</Summery>
    <Patches amount="0" />
    <Stacktraces amount="0" />
    <SourceCodeRegions amount="0" />
    <Enumerations amount="0" />
    <bug_status amount="RESOLVED" />
    <resolution amount="INVALID" />
    <WithStack>Hi,

The org.eclipse.birt.report.designer.ui.rcp was dowloaded from CVS repository and it works fine except preview report in pdf action (HTML works well). There is no any error logs, and I gave only an "Error happened while running the report" message when run this action in the pdf report window.

Under Eclipse 3.1.1, Birt 2.0.0RC, GEF 3.1.1, EMF 2.1.1, IText 1.3, prototype.js 1.4.0, jre1.5.0_06

thx
-farkas
Hi,

It is not a bug, sorry.
Verified in build 20060109.</WithStack>
    <WithOutStack>Hi,

The org.eclipse.birt.report.designer.ui.rcp was dowloaded from CVS repository and it works fine except preview report in pdf action (HTML works well). There is no any error logs, and I gave only an "Error happened while running the report" message when run this action in the pdf report window.

Under Eclipse 3.1.1, Birt 2.0.0RC, GEF 3.1.1, EMF 2.1.1, IText 1.3, prototype.js 1.4.0, jre1.5.0_06

thx
-farkas
Hi,

It is not a bug, sorry.
Verified in build 20060109.</WithOutStack>
  </Bug>
</infozilla-output>

